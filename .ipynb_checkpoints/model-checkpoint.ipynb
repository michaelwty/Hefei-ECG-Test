{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import warnings \n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, TimeDistributed\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, CuDNNLSTM\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend.tensorflow_backend as KTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.adapt import MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行配置，每个GPU使用60%上限现存\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # 使用编号为1，2号的GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.8 # 每个GPU现存上届控制在60%以内\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "# 设置session\n",
    "#KTF.set_session(session)\n",
    "#tf.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.txt',\n",
       " '5.txt',\n",
       " '9.txt',\n",
       " '12.txt',\n",
       " '14.txt',\n",
       " '16.txt',\n",
       " '17.txt',\n",
       " '21.txt',\n",
       " '23.txt',\n",
       " '24.txt',\n",
       " '26.txt',\n",
       " '28.txt',\n",
       " '30.txt',\n",
       " '32.txt',\n",
       " '34.txt',\n",
       " '36.txt',\n",
       " '40.txt',\n",
       " '41.txt',\n",
       " '49.txt',\n",
       " '53.txt',\n",
       " '55.txt',\n",
       " '57.txt',\n",
       " '60.txt',\n",
       " '61.txt',\n",
       " '63.txt',\n",
       " '65.txt',\n",
       " '68.txt',\n",
       " '71.txt',\n",
       " '72.txt',\n",
       " '76.txt',\n",
       " '78.txt',\n",
       " '81.txt',\n",
       " '84.txt',\n",
       " '86.txt',\n",
       " '89.txt',\n",
       " '90.txt',\n",
       " '92.txt',\n",
       " '95.txt',\n",
       " '97.txt',\n",
       " '98.txt',\n",
       " '100.txt',\n",
       " '102.txt',\n",
       " '105.txt',\n",
       " '108.txt',\n",
       " '110.txt',\n",
       " '112.txt',\n",
       " '114.txt',\n",
       " '116.txt',\n",
       " '118.txt',\n",
       " '121.txt',\n",
       " '123.txt',\n",
       " '124.txt',\n",
       " '126.txt',\n",
       " '128.txt',\n",
       " '130.txt',\n",
       " '132.txt',\n",
       " '135.txt',\n",
       " '137.txt',\n",
       " '141.txt',\n",
       " '144.txt',\n",
       " '145.txt',\n",
       " '147.txt',\n",
       " '149.txt',\n",
       " '151.txt',\n",
       " '154.txt',\n",
       " '156.txt',\n",
       " '158.txt',\n",
       " '160.txt',\n",
       " '161.txt',\n",
       " '163.txt',\n",
       " '165.txt',\n",
       " '167.txt',\n",
       " '169.txt',\n",
       " '171.txt',\n",
       " '173.txt',\n",
       " '175.txt',\n",
       " '177.txt',\n",
       " '179.txt',\n",
       " '182.txt',\n",
       " '184.txt',\n",
       " '188.txt',\n",
       " '189.txt',\n",
       " '191.txt',\n",
       " '194.txt',\n",
       " '197.txt',\n",
       " '199.txt',\n",
       " '203.txt',\n",
       " '204.txt',\n",
       " '209.txt',\n",
       " '210.txt',\n",
       " '212.txt',\n",
       " '214.txt',\n",
       " '217.txt',\n",
       " '219.txt',\n",
       " '220.txt',\n",
       " '222.txt',\n",
       " '225.txt',\n",
       " '227.txt',\n",
       " '229.txt',\n",
       " '231.txt',\n",
       " '236.txt',\n",
       " '241.txt',\n",
       " '242.txt',\n",
       " '245.txt',\n",
       " '247.txt',\n",
       " '249.txt',\n",
       " '250.txt',\n",
       " '252.txt',\n",
       " '256.txt',\n",
       " '258.txt',\n",
       " '260.txt',\n",
       " '261.txt',\n",
       " '264.txt',\n",
       " '269.txt',\n",
       " '272.txt',\n",
       " '274.txt',\n",
       " '276.txt',\n",
       " '280.txt',\n",
       " '282.txt',\n",
       " '283.txt',\n",
       " '284.txt',\n",
       " '286.txt',\n",
       " '288.txt',\n",
       " '290.txt',\n",
       " '293.txt',\n",
       " '295.txt',\n",
       " '297.txt',\n",
       " '300.txt',\n",
       " '303.txt',\n",
       " '305.txt',\n",
       " '307.txt',\n",
       " '311.txt',\n",
       " '313.txt',\n",
       " '318.txt',\n",
       " '320.txt',\n",
       " '322.txt',\n",
       " '323.txt',\n",
       " '324.txt',\n",
       " '326.txt',\n",
       " '328.txt',\n",
       " '329.txt',\n",
       " '333.txt',\n",
       " '335.txt',\n",
       " '337.txt',\n",
       " '341.txt',\n",
       " '342.txt',\n",
       " '344.txt',\n",
       " '347.txt',\n",
       " '349.txt',\n",
       " '352.txt',\n",
       " '354.txt',\n",
       " '358.txt',\n",
       " '360.txt',\n",
       " '362.txt',\n",
       " '364.txt',\n",
       " '365.txt',\n",
       " '368.txt',\n",
       " '369.txt',\n",
       " '371.txt',\n",
       " '375.txt',\n",
       " '377.txt',\n",
       " '380.txt',\n",
       " '382.txt',\n",
       " '385.txt',\n",
       " '386.txt',\n",
       " '387.txt',\n",
       " '391.txt',\n",
       " '394.txt',\n",
       " '395.txt',\n",
       " '397.txt',\n",
       " '400.txt',\n",
       " '402.txt',\n",
       " '405.txt',\n",
       " '407.txt',\n",
       " '411.txt',\n",
       " '413.txt',\n",
       " '416.txt',\n",
       " '417.txt',\n",
       " '419.txt',\n",
       " '421.txt',\n",
       " '423.txt',\n",
       " '425.txt',\n",
       " '427.txt',\n",
       " '430.txt',\n",
       " '434.txt',\n",
       " '436.txt',\n",
       " '439.txt',\n",
       " '444.txt',\n",
       " '447.txt',\n",
       " '449.txt',\n",
       " '452.txt',\n",
       " '454.txt',\n",
       " '456.txt',\n",
       " '458.txt',\n",
       " '460.txt',\n",
       " '463.txt',\n",
       " '465.txt',\n",
       " '469.txt',\n",
       " '472.txt',\n",
       " '473.txt',\n",
       " '475.txt',\n",
       " '477.txt',\n",
       " '479.txt',\n",
       " '481.txt',\n",
       " '485.txt',\n",
       " '487.txt',\n",
       " '488.txt',\n",
       " '491.txt',\n",
       " '492.txt',\n",
       " '494.txt',\n",
       " '496.txt',\n",
       " '498.txt',\n",
       " '500.txt',\n",
       " '502.txt',\n",
       " '503.txt',\n",
       " '505.txt',\n",
       " '507.txt',\n",
       " '510.txt',\n",
       " '513.txt',\n",
       " '516.txt',\n",
       " '518.txt',\n",
       " '521.txt',\n",
       " '524.txt',\n",
       " '527.txt',\n",
       " '529.txt',\n",
       " '530.txt',\n",
       " '532.txt',\n",
       " '534.txt',\n",
       " '536.txt',\n",
       " '538.txt',\n",
       " '541.txt',\n",
       " '543.txt',\n",
       " '545.txt',\n",
       " '549.txt',\n",
       " '551.txt',\n",
       " '554.txt',\n",
       " '557.txt',\n",
       " '558.txt',\n",
       " '561.txt',\n",
       " '564.txt',\n",
       " '566.txt',\n",
       " '568.txt',\n",
       " '572.txt',\n",
       " '574.txt',\n",
       " '576.txt',\n",
       " '578.txt',\n",
       " '580.txt',\n",
       " '582.txt',\n",
       " '584.txt',\n",
       " '586.txt',\n",
       " '588.txt',\n",
       " '591.txt',\n",
       " '594.txt',\n",
       " '596.txt',\n",
       " '598.txt',\n",
       " '600.txt',\n",
       " '603.txt',\n",
       " '604.txt',\n",
       " '606.txt',\n",
       " '607.txt',\n",
       " '613.txt',\n",
       " '615.txt',\n",
       " '618.txt',\n",
       " '621.txt',\n",
       " '623.txt',\n",
       " '624.txt',\n",
       " '627.txt',\n",
       " '628.txt',\n",
       " '629.txt',\n",
       " '631.txt',\n",
       " '633.txt',\n",
       " '635.txt',\n",
       " '637.txt',\n",
       " '642.txt',\n",
       " '645.txt',\n",
       " '647.txt',\n",
       " '650.txt',\n",
       " '652.txt',\n",
       " '654.txt',\n",
       " '657.txt',\n",
       " '658.txt',\n",
       " '662.txt',\n",
       " '663.txt',\n",
       " '665.txt',\n",
       " '669.txt',\n",
       " '671.txt',\n",
       " '673.txt',\n",
       " '675.txt',\n",
       " '678.txt',\n",
       " '680.txt',\n",
       " '683.txt',\n",
       " '685.txt',\n",
       " '687.txt',\n",
       " '689.txt',\n",
       " '691.txt',\n",
       " '695.txt',\n",
       " '696.txt',\n",
       " '700.txt',\n",
       " '703.txt',\n",
       " '705.txt',\n",
       " '706.txt',\n",
       " '709.txt',\n",
       " '711.txt',\n",
       " '712.txt',\n",
       " '713.txt',\n",
       " '716.txt',\n",
       " '722.txt',\n",
       " '724.txt',\n",
       " '727.txt',\n",
       " '728.txt',\n",
       " '732.txt',\n",
       " '734.txt',\n",
       " '735.txt',\n",
       " '737.txt',\n",
       " '738.txt',\n",
       " '741.txt',\n",
       " '743.txt',\n",
       " '747.txt',\n",
       " '748.txt',\n",
       " '751.txt',\n",
       " '755.txt',\n",
       " '756.txt',\n",
       " '760.txt',\n",
       " '765.txt',\n",
       " '766.txt',\n",
       " '768.txt',\n",
       " '771.txt',\n",
       " '772.txt',\n",
       " '773.txt',\n",
       " '775.txt',\n",
       " '777.txt',\n",
       " '779.txt',\n",
       " '781.txt',\n",
       " '785.txt',\n",
       " '787.txt',\n",
       " '790.txt',\n",
       " '792.txt',\n",
       " '796.txt',\n",
       " '800.txt',\n",
       " '802.txt',\n",
       " '806.txt',\n",
       " '807.txt',\n",
       " '810.txt',\n",
       " '813.txt',\n",
       " '816.txt',\n",
       " '817.txt',\n",
       " '818.txt',\n",
       " '821.txt',\n",
       " '824.txt',\n",
       " '827.txt',\n",
       " '831.txt',\n",
       " '832.txt',\n",
       " '834.txt',\n",
       " '836.txt',\n",
       " '839.txt',\n",
       " '842.txt',\n",
       " '847.txt',\n",
       " '851.txt',\n",
       " '852.txt',\n",
       " '855.txt',\n",
       " '857.txt',\n",
       " '859.txt',\n",
       " '861.txt',\n",
       " '864.txt',\n",
       " '866.txt',\n",
       " '868.txt',\n",
       " '870.txt',\n",
       " '872.txt',\n",
       " '874.txt',\n",
       " '879.txt',\n",
       " '882.txt',\n",
       " '884.txt',\n",
       " '885.txt',\n",
       " '886.txt',\n",
       " '889.txt',\n",
       " '891.txt',\n",
       " '893.txt',\n",
       " '896.txt',\n",
       " '900.txt',\n",
       " '902.txt',\n",
       " '905.txt',\n",
       " '907.txt',\n",
       " '909.txt',\n",
       " '911.txt',\n",
       " '914.txt',\n",
       " '917.txt',\n",
       " '922.txt',\n",
       " '924.txt',\n",
       " '925.txt',\n",
       " '926.txt',\n",
       " '928.txt',\n",
       " '930.txt',\n",
       " '932.txt',\n",
       " '935.txt',\n",
       " '940.txt',\n",
       " '942.txt',\n",
       " '944.txt',\n",
       " '946.txt',\n",
       " '949.txt',\n",
       " '951.txt',\n",
       " '954.txt',\n",
       " '956.txt',\n",
       " '959.txt',\n",
       " '961.txt',\n",
       " '962.txt',\n",
       " '964.txt',\n",
       " '966.txt',\n",
       " '968.txt',\n",
       " '970.txt',\n",
       " '974.txt',\n",
       " '975.txt',\n",
       " '979.txt',\n",
       " '981.txt',\n",
       " '987.txt',\n",
       " '989.txt',\n",
       " '994.txt',\n",
       " '996.txt',\n",
       " '998.txt',\n",
       " '1002.txt',\n",
       " '1005.txt',\n",
       " '1008.txt',\n",
       " '1010.txt',\n",
       " '1013.txt',\n",
       " '1015.txt',\n",
       " '1018.txt',\n",
       " '1020.txt',\n",
       " '1022.txt',\n",
       " '1025.txt',\n",
       " '1027.txt',\n",
       " '1030.txt',\n",
       " '1036.txt',\n",
       " '1041.txt',\n",
       " '1043.txt',\n",
       " '1045.txt',\n",
       " '1046.txt',\n",
       " '1048.txt',\n",
       " '1051.txt',\n",
       " '1054.txt',\n",
       " '1057.txt',\n",
       " '1059.txt',\n",
       " '1060.txt',\n",
       " '1064.txt',\n",
       " '1069.txt',\n",
       " '1071.txt',\n",
       " '1073.txt',\n",
       " '1075.txt',\n",
       " '1076.txt',\n",
       " '1078.txt',\n",
       " '1080.txt',\n",
       " '1082.txt',\n",
       " '1084.txt',\n",
       " '1086.txt',\n",
       " '1088.txt',\n",
       " '1090.txt',\n",
       " '1093.txt',\n",
       " '1094.txt',\n",
       " '1096.txt',\n",
       " '1101.txt',\n",
       " '1105.txt',\n",
       " '1106.txt',\n",
       " '1108.txt',\n",
       " '1109.txt',\n",
       " '1114.txt',\n",
       " '1117.txt',\n",
       " '1118.txt',\n",
       " '1121.txt',\n",
       " '1122.txt',\n",
       " '1124.txt',\n",
       " '1126.txt',\n",
       " '1128.txt',\n",
       " '1130.txt',\n",
       " '1135.txt',\n",
       " '1136.txt',\n",
       " '1137.txt',\n",
       " '1139.txt',\n",
       " '1141.txt',\n",
       " '1143.txt',\n",
       " '1147.txt',\n",
       " '1149.txt',\n",
       " '1151.txt',\n",
       " '1152.txt',\n",
       " '1156.txt',\n",
       " '1158.txt',\n",
       " '1161.txt',\n",
       " '1166.txt',\n",
       " '1168.txt',\n",
       " '1169.txt',\n",
       " '1171.txt',\n",
       " '1175.txt',\n",
       " '1177.txt',\n",
       " '1179.txt',\n",
       " '1183.txt',\n",
       " '1184.txt',\n",
       " '1190.txt',\n",
       " '1192.txt',\n",
       " '1194.txt',\n",
       " '1196.txt',\n",
       " '1197.txt',\n",
       " '1199.txt',\n",
       " '1201.txt',\n",
       " '1203.txt',\n",
       " '1205.txt',\n",
       " '1207.txt',\n",
       " '1211.txt',\n",
       " '1214.txt',\n",
       " '1216.txt',\n",
       " '1217.txt',\n",
       " '1219.txt',\n",
       " '1221.txt',\n",
       " '1225.txt',\n",
       " '1228.txt',\n",
       " '1230.txt',\n",
       " '1234.txt',\n",
       " '1237.txt',\n",
       " '1239.txt',\n",
       " '1241.txt',\n",
       " '1243.txt',\n",
       " '1245.txt',\n",
       " '1249.txt',\n",
       " '1251.txt',\n",
       " '1254.txt',\n",
       " '1255.txt',\n",
       " '1267.txt',\n",
       " '1271.txt',\n",
       " '1274.txt',\n",
       " '1276.txt',\n",
       " '1278.txt',\n",
       " '1280.txt',\n",
       " '1283.txt',\n",
       " '1285.txt',\n",
       " '1287.txt',\n",
       " '1288.txt',\n",
       " '1290.txt',\n",
       " '1292.txt',\n",
       " '1295.txt',\n",
       " '1297.txt',\n",
       " '1300.txt',\n",
       " '1302.txt',\n",
       " '1303.txt',\n",
       " '1305.txt',\n",
       " '1307.txt',\n",
       " '1309.txt',\n",
       " '1311.txt',\n",
       " '1314.txt',\n",
       " '1315.txt',\n",
       " '1317.txt',\n",
       " '1318.txt',\n",
       " '1320.txt',\n",
       " '1323.txt',\n",
       " '1325.txt',\n",
       " '1327.txt',\n",
       " '1329.txt',\n",
       " '1331.txt',\n",
       " '1332.txt',\n",
       " '1335.txt',\n",
       " '1337.txt',\n",
       " '1339.txt',\n",
       " '1341.txt',\n",
       " '1344.txt',\n",
       " '1346.txt',\n",
       " '1348.txt',\n",
       " '1351.txt',\n",
       " '1352.txt',\n",
       " '1354.txt',\n",
       " '1356.txt',\n",
       " '1358.txt',\n",
       " '1360.txt',\n",
       " '1362.txt',\n",
       " '1364.txt',\n",
       " '1367.txt',\n",
       " '1368.txt',\n",
       " '1371.txt',\n",
       " '1372.txt',\n",
       " '1375.txt',\n",
       " '1377.txt',\n",
       " '1379.txt',\n",
       " '1380.txt',\n",
       " '1383.txt',\n",
       " '1389.txt',\n",
       " '1390.txt',\n",
       " '1392.txt',\n",
       " '1395.txt',\n",
       " '1396.txt',\n",
       " '1398.txt',\n",
       " '1400.txt',\n",
       " '1402.txt',\n",
       " '1405.txt',\n",
       " '1407.txt',\n",
       " '1409.txt',\n",
       " '1412.txt',\n",
       " '1416.txt',\n",
       " '1418.txt',\n",
       " '1421.txt',\n",
       " '1422.txt',\n",
       " '1425.txt',\n",
       " '1427.txt',\n",
       " '1429.txt',\n",
       " '1431.txt',\n",
       " '1433.txt',\n",
       " '1434.txt',\n",
       " '1436.txt',\n",
       " '1439.txt',\n",
       " '1441.txt',\n",
       " '1442.txt',\n",
       " '1444.txt',\n",
       " '1446.txt',\n",
       " '1448.txt',\n",
       " '1451.txt',\n",
       " '1453.txt',\n",
       " '1454.txt',\n",
       " '1456.txt',\n",
       " '1458.txt',\n",
       " '1460.txt',\n",
       " '1462.txt',\n",
       " '1465.txt',\n",
       " '1467.txt',\n",
       " '1469.txt',\n",
       " '1470.txt',\n",
       " '1473.txt',\n",
       " '1475.txt',\n",
       " '1477.txt',\n",
       " '1480.txt',\n",
       " '1482.txt',\n",
       " '1484.txt',\n",
       " '1487.txt',\n",
       " '1490.txt',\n",
       " '1491.txt',\n",
       " '1494.txt',\n",
       " '1497.txt',\n",
       " '1499.txt',\n",
       " '1502.txt',\n",
       " '1504.txt',\n",
       " '1505.txt',\n",
       " '1507.txt',\n",
       " '1509.txt',\n",
       " '1511.txt',\n",
       " '1513.txt',\n",
       " '1515.txt',\n",
       " '1518.txt',\n",
       " '1519.txt',\n",
       " '1521.txt',\n",
       " '1523.txt',\n",
       " '1526.txt',\n",
       " '1528.txt',\n",
       " '1529.txt',\n",
       " '1532.txt',\n",
       " '1534.txt',\n",
       " '1536.txt',\n",
       " '1538.txt',\n",
       " '1540.txt',\n",
       " '1543.txt',\n",
       " '1545.txt',\n",
       " '1546.txt',\n",
       " '1548.txt',\n",
       " '1551.txt',\n",
       " '1552.txt',\n",
       " '1556.txt',\n",
       " '1558.txt',\n",
       " '1561.txt',\n",
       " '1563.txt',\n",
       " '1565.txt',\n",
       " '1567.txt',\n",
       " '1570.txt',\n",
       " '1572.txt',\n",
       " '1574.txt',\n",
       " '1581.txt',\n",
       " '1583.txt',\n",
       " '1585.txt',\n",
       " '1587.txt',\n",
       " '1589.txt',\n",
       " '1590.txt',\n",
       " '1594.txt',\n",
       " '1596.txt',\n",
       " '1598.txt',\n",
       " '1600.txt',\n",
       " '1602.txt',\n",
       " '1604.txt',\n",
       " '1605.txt',\n",
       " '1608.txt',\n",
       " '1610.txt',\n",
       " '1612.txt',\n",
       " '1615.txt',\n",
       " '1616.txt',\n",
       " '1618.txt',\n",
       " '1622.txt',\n",
       " '1623.txt',\n",
       " '1626.txt',\n",
       " '1629.txt',\n",
       " '1631.txt',\n",
       " '1632.txt',\n",
       " '1637.txt',\n",
       " '1639.txt',\n",
       " '1641.txt',\n",
       " '1643.txt',\n",
       " '1645.txt',\n",
       " '1647.txt',\n",
       " '1650.txt',\n",
       " '1652.txt',\n",
       " '1654.txt',\n",
       " '1655.txt',\n",
       " '1657.txt',\n",
       " '1660.txt',\n",
       " '1662.txt',\n",
       " '1663.txt',\n",
       " '1666.txt',\n",
       " '1667.txt',\n",
       " '1669.txt',\n",
       " '1671.txt',\n",
       " '1673.txt',\n",
       " '1676.txt',\n",
       " '1677.txt',\n",
       " '1680.txt',\n",
       " '1682.txt',\n",
       " '1684.txt',\n",
       " '1686.txt',\n",
       " '1692.txt',\n",
       " '1694.txt',\n",
       " '1696.txt',\n",
       " '1698.txt',\n",
       " '1699.txt',\n",
       " '1701.txt',\n",
       " '1705.txt',\n",
       " '1707.txt',\n",
       " '1709.txt',\n",
       " '1715.txt',\n",
       " '1717.txt',\n",
       " '1720.txt',\n",
       " '1723.txt',\n",
       " '1725.txt',\n",
       " '1727.txt',\n",
       " '1728.txt',\n",
       " '1732.txt',\n",
       " '1734.txt',\n",
       " '1735.txt',\n",
       " '1737.txt',\n",
       " '1739.txt',\n",
       " '1744.txt',\n",
       " '1745.txt',\n",
       " '1747.txt',\n",
       " '1749.txt',\n",
       " '1751.txt',\n",
       " '1755.txt',\n",
       " '1759.txt',\n",
       " '1762.txt',\n",
       " '1764.txt',\n",
       " '1765.txt',\n",
       " '1769.txt',\n",
       " '1771.txt',\n",
       " '1774.txt',\n",
       " '1775.txt',\n",
       " '1778.txt',\n",
       " '1780.txt',\n",
       " '1783.txt',\n",
       " '1784.txt',\n",
       " '1787.txt',\n",
       " '1789.txt',\n",
       " '1791.txt',\n",
       " '1794.txt',\n",
       " '1798.txt',\n",
       " '1800.txt',\n",
       " '1801.txt',\n",
       " '1803.txt',\n",
       " '1805.txt',\n",
       " '1808.txt',\n",
       " '1810.txt',\n",
       " '1812.txt',\n",
       " '1814.txt',\n",
       " '1816.txt',\n",
       " '1818.txt',\n",
       " '1820.txt',\n",
       " '1824.txt',\n",
       " '1825.txt',\n",
       " '1827.txt',\n",
       " '1830.txt',\n",
       " '1831.txt',\n",
       " '1833.txt',\n",
       " '1836.txt',\n",
       " '1838.txt',\n",
       " '1840.txt',\n",
       " '1842.txt',\n",
       " '1844.txt',\n",
       " '1847.txt',\n",
       " '1850.txt',\n",
       " '1851.txt',\n",
       " '1854.txt',\n",
       " '1855.txt',\n",
       " '1858.txt',\n",
       " '1860.txt',\n",
       " '1861.txt',\n",
       " '1863.txt',\n",
       " '1865.txt',\n",
       " '1867.txt',\n",
       " '1870.txt',\n",
       " '1872.txt',\n",
       " '1874.txt',\n",
       " '1876.txt',\n",
       " '1879.txt',\n",
       " '1880.txt',\n",
       " '1884.txt',\n",
       " '1885.txt',\n",
       " '1887.txt',\n",
       " '1890.txt',\n",
       " '1892.txt',\n",
       " '1894.txt',\n",
       " '1898.txt',\n",
       " '1900.txt',\n",
       " '1901.txt',\n",
       " '1903.txt',\n",
       " '1906.txt',\n",
       " '1908.txt',\n",
       " '1911.txt',\n",
       " '1913.txt',\n",
       " '1914.txt',\n",
       " '1916.txt',\n",
       " '1919.txt',\n",
       " '1921.txt',\n",
       " '1923.txt',\n",
       " '1926.txt',\n",
       " '1928.txt',\n",
       " '1930.txt',\n",
       " '1932.txt',\n",
       " '1934.txt',\n",
       " '1937.txt',\n",
       " '1938.txt',\n",
       " '1941.txt',\n",
       " '1942.txt',\n",
       " '1944.txt',\n",
       " '1947.txt',\n",
       " '1948.txt',\n",
       " '1951.txt',\n",
       " '1952.txt',\n",
       " '1954.txt',\n",
       " '1956.txt',\n",
       " '1959.txt',\n",
       " '1961.txt',\n",
       " '1964.txt',\n",
       " '1965.txt',\n",
       " '1970.txt',\n",
       " '1973.txt',\n",
       " '1974.txt',\n",
       " '1976.txt',\n",
       " '1979.txt',\n",
       " '1981.txt',\n",
       " '1983.txt',\n",
       " '1984.txt',\n",
       " '1986.txt',\n",
       " '1989.txt',\n",
       " '1991.txt',\n",
       " '1992.txt',\n",
       " '1995.txt',\n",
       " '1997.txt',\n",
       " '1999.txt',\n",
       " '2001.txt',\n",
       " '2005.txt',\n",
       " '2007.txt',\n",
       " '2008.txt',\n",
       " '2012.txt',\n",
       " '2015.txt',\n",
       " '2017.txt',\n",
       " '2020.txt',\n",
       " '2022.txt',\n",
       " '2024.txt',\n",
       " '2026.txt',\n",
       " '2029.txt',\n",
       " '2031.txt',\n",
       " '2032.txt',\n",
       " '2034.txt',\n",
       " '2037.txt',\n",
       " '2038.txt',\n",
       " '2040.txt',\n",
       " '2043.txt',\n",
       " '2045.txt',\n",
       " '2049.txt',\n",
       " '2052.txt',\n",
       " '2053.txt',\n",
       " '2055.txt',\n",
       " '2057.txt',\n",
       " '2060.txt',\n",
       " '2062.txt',\n",
       " '2066.txt',\n",
       " '2067.txt',\n",
       " '2069.txt',\n",
       " '2072.txt',\n",
       " '2074.txt',\n",
       " '2078.txt',\n",
       " '2080.txt',\n",
       " '2083.txt',\n",
       " '2085.txt',\n",
       " '2087.txt',\n",
       " '2090.txt',\n",
       " '2092.txt',\n",
       " '2093.txt',\n",
       " '2096.txt',\n",
       " '2098.txt',\n",
       " '2099.txt',\n",
       " '2101.txt',\n",
       " '2103.txt',\n",
       " '2105.txt',\n",
       " '2107.txt',\n",
       " '2110.txt',\n",
       " '2113.txt',\n",
       " '2114.txt',\n",
       " '2117.txt',\n",
       " '2119.txt',\n",
       " '2121.txt',\n",
       " '2122.txt',\n",
       " '2125.txt',\n",
       " '2126.txt',\n",
       " '2129.txt',\n",
       " '2130.txt',\n",
       " '2133.txt',\n",
       " '2135.txt',\n",
       " '2137.txt',\n",
       " '2139.txt',\n",
       " '2141.txt',\n",
       " '2142.txt',\n",
       " '2145.txt',\n",
       " '2147.txt',\n",
       " '2149.txt',\n",
       " '2151.txt',\n",
       " '2153.txt',\n",
       " '2154.txt',\n",
       " '2156.txt',\n",
       " '2160.txt',\n",
       " '2161.txt',\n",
       " '2165.txt',\n",
       " '2166.txt',\n",
       " '2168.txt',\n",
       " '2171.txt',\n",
       " '2173.txt',\n",
       " '2176.txt',\n",
       " '2177.txt',\n",
       " '2179.txt',\n",
       " '2181.txt',\n",
       " '2184.txt',\n",
       " '2186.txt',\n",
       " '2188.txt',\n",
       " '2189.txt',\n",
       " '2191.txt',\n",
       " '2194.txt',\n",
       " '2196.txt',\n",
       " '2200.txt',\n",
       " '2201.txt',\n",
       " '2204.txt',\n",
       " '2206.txt',\n",
       " '2209.txt',\n",
       " '2211.txt',\n",
       " '2213.txt',\n",
       " '2215.txt',\n",
       " '2217.txt',\n",
       " '2219.txt',\n",
       " '2220.txt',\n",
       " '2223.txt',\n",
       " '2225.txt',\n",
       " '2227.txt',\n",
       " '2229.txt',\n",
       " '2231.txt',\n",
       " '2232.txt',\n",
       " '2234.txt',\n",
       " '2237.txt',\n",
       " '2240.txt',\n",
       " '2241.txt',\n",
       " '2244.txt',\n",
       " '2245.txt',\n",
       " '2247.txt',\n",
       " '2249.txt',\n",
       " '2252.txt',\n",
       " '2255.txt',\n",
       " '2257.txt',\n",
       " '2258.txt',\n",
       " '2260.txt',\n",
       " '2263.txt',\n",
       " '2265.txt',\n",
       " '2266.txt',\n",
       " '2268.txt',\n",
       " '2271.txt',\n",
       " '2273.txt',\n",
       " '2275.txt',\n",
       " '2276.txt',\n",
       " '2278.txt',\n",
       " '2280.txt',\n",
       " '2283.txt',\n",
       " '2284.txt',\n",
       " '2286.txt',\n",
       " '2288.txt',\n",
       " '2291.txt',\n",
       " '2292.txt',\n",
       " '2294.txt',\n",
       " '2297.txt',\n",
       " '2300.txt',\n",
       " '2302.txt',\n",
       " '2304.txt',\n",
       " '2306.txt',\n",
       " '2308.txt',\n",
       " '2310.txt',\n",
       " '2312.txt',\n",
       " '2313.txt',\n",
       " '2315.txt',\n",
       " '2318.txt',\n",
       " '2319.txt',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_cases = os.listdir('D:\\\\DeepMind\\\\合肥高新杯心电人机智能大赛\\\\train\\\\')\n",
    "all_train_cases.sort(key=lambda x:int(x[:-4]))\n",
    "all_train_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = np.empty(shape=[24106, 5000, 12], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 24106/24106 [03:19<00:00, 120.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, sample in enumerate(tqdm(all_train_cases)):\n",
    "    data = pd.read_table('train\\\\'+sample,header=0, encoding='utf-8', sep=' ')\n",
    "    i = data['I']\n",
    "    ii = data['II']\n",
    "    data['III'] = ii-i\n",
    "    data['aVR']=-(ii+i)/2\n",
    "    data['aVL']=(i-ii)/2\n",
    "    data['aVF']=(ii-i)/2\n",
    "    x_train[idx] = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5,  1,  9, ...,  2, -3,  3],\n",
       "       [-4,  1,  9, ...,  1, -2,  2],\n",
       "       [-3,  1,  9, ...,  1, -2,  2],\n",
       "       ...,\n",
       "       [ 4,  2, 27, ..., -3,  1, -1],\n",
       "       [ 6,  3, 28, ..., -4,  1, -1],\n",
       "       [ 7,  4, 29, ..., -5,  1, -1]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv('hf_round1_label.txt',sep=\"\\t\",encoding='utf-8',names = list(range(0,12)))\n",
    "label.columns = ['id','age','gender','f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10','f11']\n",
    "arrythmia = pd.read_csv('hf_round1_arrythmia.txt',header=None,sep=\"\\t\",encoding='utf-8')\n",
    "arrythmia.columns = ['ff1']\n",
    "all_dis = list(arrythmia.ff1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 24106/24106 [00:26<00:00, 898.46it/s]\n"
     ]
    }
   ],
   "source": [
    "dis_df = pd.DataFrame(np.zeros([label.shape[0],55]))\n",
    "dis_df.columns = all_dis\n",
    "new_data = pd.concat([label,dis_df],axis =1)\n",
    "for i in tqdm(range (new_data.shape[0])):\n",
    "    dises = list(label.iloc[i,3:11].unique())\n",
    "    dises.remove(dises[-1])\n",
    "    for d in dises:\n",
    "        new_data.loc[i,d]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_cols = [col for col in new_data.columns if col not in ['id','age','gender','f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10','f11']]#最后过滤掉不需要的列new_data= new_data[new_cols]\n",
    "y_train = new_data[new_cols]\n",
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24106, 55)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.txt',\n",
       " '3.txt',\n",
       " '6.txt',\n",
       " '7.txt',\n",
       " '10.txt',\n",
       " '13.txt',\n",
       " '15.txt',\n",
       " '20.txt',\n",
       " '22.txt',\n",
       " '35.txt',\n",
       " '54.txt',\n",
       " '58.txt',\n",
       " '69.txt',\n",
       " '74.txt',\n",
       " '75.txt',\n",
       " '77.txt',\n",
       " '79.txt',\n",
       " '83.txt',\n",
       " '115.txt',\n",
       " '125.txt',\n",
       " '127.txt',\n",
       " '129.txt',\n",
       " '131.txt',\n",
       " '134.txt',\n",
       " '136.txt',\n",
       " '140.txt',\n",
       " '142.txt',\n",
       " '146.txt',\n",
       " '148.txt',\n",
       " '150.txt',\n",
       " '155.txt',\n",
       " '162.txt',\n",
       " '164.txt',\n",
       " '166.txt',\n",
       " '168.txt',\n",
       " '172.txt',\n",
       " '174.txt',\n",
       " '178.txt',\n",
       " '181.txt',\n",
       " '187.txt',\n",
       " '190.txt',\n",
       " '193.txt',\n",
       " '198.txt',\n",
       " '215.txt',\n",
       " '216.txt',\n",
       " '221.txt',\n",
       " '232.txt',\n",
       " '235.txt',\n",
       " '244.txt',\n",
       " '251.txt',\n",
       " '255.txt',\n",
       " '259.txt',\n",
       " '277.txt',\n",
       " '285.txt',\n",
       " '287.txt',\n",
       " '294.txt',\n",
       " '296.txt',\n",
       " '298.txt',\n",
       " '301.txt',\n",
       " '304.txt',\n",
       " '306.txt',\n",
       " '308.txt',\n",
       " '312.txt',\n",
       " '319.txt',\n",
       " '321.txt',\n",
       " '325.txt',\n",
       " '330.txt',\n",
       " '336.txt',\n",
       " '343.txt',\n",
       " '348.txt',\n",
       " '350.txt',\n",
       " '353.txt',\n",
       " '355.txt',\n",
       " '357.txt',\n",
       " '359.txt',\n",
       " '366.txt',\n",
       " '370.txt',\n",
       " '390.txt',\n",
       " '392.txt',\n",
       " '396.txt',\n",
       " '399.txt',\n",
       " '408.txt',\n",
       " '412.txt',\n",
       " '414.txt',\n",
       " '422.txt',\n",
       " '424.txt',\n",
       " '431.txt',\n",
       " '445.txt',\n",
       " '448.txt',\n",
       " '450.txt',\n",
       " '457.txt',\n",
       " '459.txt',\n",
       " '470.txt',\n",
       " '482.txt',\n",
       " '495.txt',\n",
       " '497.txt',\n",
       " '499.txt',\n",
       " '501.txt',\n",
       " '504.txt',\n",
       " '511.txt',\n",
       " '512.txt',\n",
       " '514.txt',\n",
       " '523.txt',\n",
       " '525.txt',\n",
       " '528.txt',\n",
       " '531.txt',\n",
       " '542.txt',\n",
       " '550.txt',\n",
       " '556.txt',\n",
       " '563.txt',\n",
       " '567.txt',\n",
       " '573.txt',\n",
       " '575.txt',\n",
       " '577.txt',\n",
       " '589.txt',\n",
       " '592.txt',\n",
       " '602.txt',\n",
       " '605.txt',\n",
       " '614.txt',\n",
       " '617.txt',\n",
       " '619.txt',\n",
       " '620.txt',\n",
       " '622.txt',\n",
       " '625.txt',\n",
       " '630.txt',\n",
       " '636.txt',\n",
       " '639.txt',\n",
       " '643.txt',\n",
       " '646.txt',\n",
       " '649.txt',\n",
       " '651.txt',\n",
       " '655.txt',\n",
       " '659.txt',\n",
       " '660.txt',\n",
       " '661.txt',\n",
       " '672.txt',\n",
       " '674.txt',\n",
       " '693.txt',\n",
       " '699.txt',\n",
       " '701.txt',\n",
       " '704.txt',\n",
       " '710.txt',\n",
       " '726.txt',\n",
       " '729.txt',\n",
       " '731.txt',\n",
       " '736.txt',\n",
       " '739.txt',\n",
       " '740.txt',\n",
       " '742.txt',\n",
       " '745.txt',\n",
       " '757.txt',\n",
       " '761.txt',\n",
       " '763.txt',\n",
       " '767.txt',\n",
       " '776.txt',\n",
       " '778.txt',\n",
       " '780.txt',\n",
       " '797.txt',\n",
       " '798.txt',\n",
       " '801.txt',\n",
       " '804.txt',\n",
       " '814.txt',\n",
       " '829.txt',\n",
       " '835.txt',\n",
       " '837.txt',\n",
       " '841.txt',\n",
       " '843.txt',\n",
       " '848.txt',\n",
       " '849.txt',\n",
       " '853.txt',\n",
       " '854.txt',\n",
       " '856.txt',\n",
       " '862.txt',\n",
       " '867.txt',\n",
       " '881.txt',\n",
       " '888.txt',\n",
       " '904.txt',\n",
       " '906.txt',\n",
       " '910.txt',\n",
       " '912.txt',\n",
       " '913.txt',\n",
       " '916.txt',\n",
       " '920.txt',\n",
       " '927.txt',\n",
       " '931.txt',\n",
       " '937.txt',\n",
       " '938.txt',\n",
       " '941.txt',\n",
       " '945.txt',\n",
       " '948.txt',\n",
       " '950.txt',\n",
       " '960.txt',\n",
       " '963.txt',\n",
       " '965.txt',\n",
       " '967.txt',\n",
       " '969.txt',\n",
       " '972.txt',\n",
       " '980.txt',\n",
       " '990.txt',\n",
       " '995.txt',\n",
       " '1000.txt',\n",
       " '1004.txt',\n",
       " '1011.txt',\n",
       " '1014.txt',\n",
       " '1017.txt',\n",
       " '1021.txt',\n",
       " '1026.txt',\n",
       " '1031.txt',\n",
       " '1042.txt',\n",
       " '1047.txt',\n",
       " '1049.txt',\n",
       " '1058.txt',\n",
       " '1061.txt',\n",
       " '1062.txt',\n",
       " '1067.txt',\n",
       " '1070.txt',\n",
       " '1074.txt',\n",
       " '1077.txt',\n",
       " '1079.txt',\n",
       " '1083.txt',\n",
       " '1085.txt',\n",
       " '1089.txt',\n",
       " '1097.txt',\n",
       " '1100.txt',\n",
       " '1104.txt',\n",
       " '1107.txt',\n",
       " '1110.txt',\n",
       " '1111.txt',\n",
       " '1116.txt',\n",
       " '1120.txt',\n",
       " '1123.txt',\n",
       " '1129.txt',\n",
       " '1131.txt',\n",
       " '1134.txt',\n",
       " '1138.txt',\n",
       " '1140.txt',\n",
       " '1144.txt',\n",
       " '1145.txt',\n",
       " '1148.txt',\n",
       " '1155.txt',\n",
       " '1157.txt',\n",
       " '1159.txt',\n",
       " '1167.txt',\n",
       " '1173.txt',\n",
       " '1176.txt',\n",
       " '1178.txt',\n",
       " '1180.txt',\n",
       " '1182.txt',\n",
       " '1189.txt',\n",
       " '1202.txt',\n",
       " '1204.txt',\n",
       " '1206.txt',\n",
       " '1209.txt',\n",
       " '1212.txt',\n",
       " '1215.txt',\n",
       " '1218.txt',\n",
       " '1220.txt',\n",
       " '1226.txt',\n",
       " '1229.txt',\n",
       " '1232.txt',\n",
       " '1235.txt',\n",
       " '1236.txt',\n",
       " '1240.txt',\n",
       " '1246.txt',\n",
       " '1250.txt',\n",
       " '1270.txt',\n",
       " '1275.txt',\n",
       " '1281.txt',\n",
       " '1284.txt',\n",
       " '1286.txt',\n",
       " '1296.txt',\n",
       " '1298.txt',\n",
       " '1301.txt',\n",
       " '1304.txt',\n",
       " '1310.txt',\n",
       " '1313.txt',\n",
       " '1316.txt',\n",
       " '1321.txt',\n",
       " '1322.txt',\n",
       " '1328.txt',\n",
       " '1330.txt',\n",
       " '1333.txt',\n",
       " '1336.txt',\n",
       " '1338.txt',\n",
       " '1340.txt',\n",
       " '1342.txt',\n",
       " '1347.txt',\n",
       " '1350.txt',\n",
       " '1353.txt',\n",
       " '1355.txt',\n",
       " '1357.txt',\n",
       " '1366.txt',\n",
       " '1369.txt',\n",
       " '1370.txt',\n",
       " '1374.txt',\n",
       " '1378.txt',\n",
       " '1381.txt',\n",
       " '1382.txt',\n",
       " '1403.txt',\n",
       " '1406.txt',\n",
       " '1426.txt',\n",
       " '1428.txt',\n",
       " '1437.txt',\n",
       " '1438.txt',\n",
       " '1440.txt',\n",
       " '1445.txt',\n",
       " '1447.txt',\n",
       " '1450.txt',\n",
       " '1452.txt',\n",
       " '1457.txt',\n",
       " '1461.txt',\n",
       " '1466.txt',\n",
       " '1474.txt',\n",
       " '1478.txt',\n",
       " '1483.txt',\n",
       " '1486.txt',\n",
       " '1489.txt',\n",
       " '1492.txt',\n",
       " '1495.txt',\n",
       " '1500.txt',\n",
       " '1510.txt',\n",
       " '1514.txt',\n",
       " '1516.txt',\n",
       " '1522.txt',\n",
       " '1524.txt',\n",
       " '1527.txt',\n",
       " '1531.txt',\n",
       " '1535.txt',\n",
       " '1544.txt',\n",
       " '1547.txt',\n",
       " '1550.txt',\n",
       " '1557.txt',\n",
       " '1562.txt',\n",
       " '1564.txt',\n",
       " '1566.txt',\n",
       " '1571.txt',\n",
       " '1573.txt',\n",
       " '1575.txt',\n",
       " '1580.txt',\n",
       " '1584.txt',\n",
       " '1586.txt',\n",
       " '1591.txt',\n",
       " '1592.txt',\n",
       " '1593.txt',\n",
       " '1599.txt',\n",
       " '1601.txt',\n",
       " '1606.txt',\n",
       " '1609.txt',\n",
       " '1613.txt',\n",
       " '1614.txt',\n",
       " '1620.txt',\n",
       " '1628.txt',\n",
       " '1633.txt',\n",
       " '1640.txt',\n",
       " '1644.txt',\n",
       " '1648.txt',\n",
       " '1649.txt',\n",
       " '1653.txt',\n",
       " '1664.txt',\n",
       " '1665.txt',\n",
       " '1672.txt',\n",
       " '1674.txt',\n",
       " '1675.txt',\n",
       " '1681.txt',\n",
       " '1683.txt',\n",
       " '1691.txt',\n",
       " '1693.txt',\n",
       " '1706.txt',\n",
       " '1708.txt',\n",
       " '1714.txt',\n",
       " '1722.txt',\n",
       " '1724.txt',\n",
       " '1726.txt',\n",
       " '1729.txt',\n",
       " '1733.txt',\n",
       " '1736.txt',\n",
       " '1738.txt',\n",
       " '1740.txt',\n",
       " '1742.txt',\n",
       " '1746.txt',\n",
       " '1748.txt',\n",
       " '1763.txt',\n",
       " '1767.txt',\n",
       " '1772.txt',\n",
       " '1777.txt',\n",
       " '1779.txt',\n",
       " '1781.txt',\n",
       " '1785.txt',\n",
       " '1788.txt',\n",
       " '1790.txt',\n",
       " '1792.txt',\n",
       " '1796.txt',\n",
       " '1797.txt',\n",
       " '1807.txt',\n",
       " '1811.txt',\n",
       " '1813.txt',\n",
       " '1815.txt',\n",
       " '1817.txt',\n",
       " '1822.txt',\n",
       " '1823.txt',\n",
       " '1826.txt',\n",
       " '1837.txt',\n",
       " '1841.txt',\n",
       " '1843.txt',\n",
       " '1846.txt',\n",
       " '1849.txt',\n",
       " '1857.txt',\n",
       " '1859.txt',\n",
       " '1873.txt',\n",
       " '1875.txt',\n",
       " '1878.txt',\n",
       " '1882.txt',\n",
       " '1893.txt',\n",
       " '1897.txt',\n",
       " '1899.txt',\n",
       " '1902.txt',\n",
       " '1904.txt',\n",
       " '1905.txt',\n",
       " '1910.txt',\n",
       " '1912.txt',\n",
       " '1915.txt',\n",
       " '1925.txt',\n",
       " '1927.txt',\n",
       " '1931.txt',\n",
       " '1939.txt',\n",
       " '1940.txt',\n",
       " '1943.txt',\n",
       " '1945.txt',\n",
       " '1949.txt',\n",
       " '1960.txt',\n",
       " '1966.txt',\n",
       " '1971.txt',\n",
       " '1972.txt',\n",
       " '1978.txt',\n",
       " '1982.txt',\n",
       " '1985.txt',\n",
       " '1990.txt',\n",
       " '1993.txt',\n",
       " '2000.txt',\n",
       " '2006.txt',\n",
       " '2010.txt',\n",
       " '2019.txt',\n",
       " '2023.txt',\n",
       " '2027.txt',\n",
       " '2028.txt',\n",
       " '2036.txt',\n",
       " '2039.txt',\n",
       " '2047.txt',\n",
       " '2050.txt',\n",
       " '2059.txt',\n",
       " '2065.txt',\n",
       " '2070.txt',\n",
       " '2073.txt',\n",
       " '2079.txt',\n",
       " '2081.txt',\n",
       " '2091.txt',\n",
       " '2094.txt',\n",
       " '2100.txt',\n",
       " '2106.txt',\n",
       " '2109.txt',\n",
       " '2112.txt',\n",
       " '2115.txt',\n",
       " '2116.txt',\n",
       " '2120.txt',\n",
       " '2123.txt',\n",
       " '2124.txt',\n",
       " '2127.txt',\n",
       " '2132.txt',\n",
       " '2136.txt',\n",
       " '2138.txt',\n",
       " '2144.txt',\n",
       " '2146.txt',\n",
       " '2155.txt',\n",
       " '2158.txt',\n",
       " '2164.txt',\n",
       " '2167.txt',\n",
       " '2169.txt',\n",
       " '2178.txt',\n",
       " '2180.txt',\n",
       " '2183.txt',\n",
       " '2192.txt',\n",
       " '2195.txt',\n",
       " '2199.txt',\n",
       " '2205.txt',\n",
       " '2212.txt',\n",
       " '2216.txt',\n",
       " '2218.txt',\n",
       " '2224.txt',\n",
       " '2226.txt',\n",
       " '2228.txt',\n",
       " '2235.txt',\n",
       " '2238.txt',\n",
       " '2239.txt',\n",
       " '2246.txt',\n",
       " '2248.txt',\n",
       " '2254.txt',\n",
       " '2259.txt',\n",
       " '2262.txt',\n",
       " '2267.txt',\n",
       " '2269.txt',\n",
       " '2279.txt',\n",
       " '2281.txt',\n",
       " '2290.txt',\n",
       " '2293.txt',\n",
       " '2296.txt',\n",
       " '2298.txt',\n",
       " '2301.txt',\n",
       " '2303.txt',\n",
       " '2305.txt',\n",
       " '2311.txt',\n",
       " '2314.txt',\n",
       " '2317.txt',\n",
       " '2323.txt',\n",
       " '2329.txt',\n",
       " '2331.txt',\n",
       " '2335.txt',\n",
       " '2336.txt',\n",
       " '2338.txt',\n",
       " '2340.txt',\n",
       " '2345.txt',\n",
       " '2347.txt',\n",
       " '2356.txt',\n",
       " '2362.txt',\n",
       " '2363.txt',\n",
       " '2366.txt',\n",
       " '2373.txt',\n",
       " '2374.txt',\n",
       " '2377.txt',\n",
       " '2379.txt',\n",
       " '2381.txt',\n",
       " '2386.txt',\n",
       " '2389.txt',\n",
       " '2391.txt',\n",
       " '2393.txt',\n",
       " '2397.txt',\n",
       " '2407.txt',\n",
       " '2409.txt',\n",
       " '2414.txt',\n",
       " '2415.txt',\n",
       " '2421.txt',\n",
       " '2424.txt',\n",
       " '2427.txt',\n",
       " '2429.txt',\n",
       " '2431.txt',\n",
       " '2433.txt',\n",
       " '2438.txt',\n",
       " '2439.txt',\n",
       " '2441.txt',\n",
       " '2443.txt',\n",
       " '2446.txt',\n",
       " '2450.txt',\n",
       " '2452.txt',\n",
       " '2454.txt',\n",
       " '2458.txt',\n",
       " '2460.txt',\n",
       " '2463.txt',\n",
       " '2465.txt',\n",
       " '2467.txt',\n",
       " '2469.txt',\n",
       " '2478.txt',\n",
       " '2487.txt',\n",
       " '2492.txt',\n",
       " '2500.txt',\n",
       " '2519.txt',\n",
       " '2520.txt',\n",
       " '2525.txt',\n",
       " '2527.txt',\n",
       " '2529.txt',\n",
       " '2539.txt',\n",
       " '2546.txt',\n",
       " '2547.txt',\n",
       " '2555.txt',\n",
       " '2557.txt',\n",
       " '2559.txt',\n",
       " '2567.txt',\n",
       " '2573.txt',\n",
       " '2575.txt',\n",
       " '2577.txt',\n",
       " '2581.txt',\n",
       " '2588.txt',\n",
       " '2589.txt',\n",
       " '2591.txt',\n",
       " '2606.txt',\n",
       " '2607.txt',\n",
       " '2609.txt',\n",
       " '2612.txt',\n",
       " '2623.txt',\n",
       " '2627.txt',\n",
       " '2629.txt',\n",
       " '2633.txt',\n",
       " '2635.txt',\n",
       " '2645.txt',\n",
       " '2647.txt',\n",
       " '2657.txt',\n",
       " '2660.txt',\n",
       " '2668.txt',\n",
       " '2673.txt',\n",
       " '2675.txt',\n",
       " '2687.txt',\n",
       " '2688.txt',\n",
       " '2724.txt',\n",
       " '2737.txt',\n",
       " '2760.txt',\n",
       " '2762.txt',\n",
       " '2776.txt',\n",
       " '2779.txt',\n",
       " '2784.txt',\n",
       " '2790.txt',\n",
       " '2793.txt',\n",
       " '2803.txt',\n",
       " '2807.txt',\n",
       " '2816.txt',\n",
       " '2818.txt',\n",
       " '2822.txt',\n",
       " '2829.txt',\n",
       " '2831.txt',\n",
       " '2836.txt',\n",
       " '2843.txt',\n",
       " '2846.txt',\n",
       " '2857.txt',\n",
       " '2863.txt',\n",
       " '2864.txt',\n",
       " '2869.txt',\n",
       " '2874.txt',\n",
       " '2876.txt',\n",
       " '2878.txt',\n",
       " '2887.txt',\n",
       " '2900.txt',\n",
       " '2901.txt',\n",
       " '2903.txt',\n",
       " '2912.txt',\n",
       " '2926.txt',\n",
       " '2931.txt',\n",
       " '2939.txt',\n",
       " '2948.txt',\n",
       " '2952.txt',\n",
       " '2954.txt',\n",
       " '2960.txt',\n",
       " '2962.txt',\n",
       " '2964.txt',\n",
       " '2966.txt',\n",
       " '2977.txt',\n",
       " '2978.txt',\n",
       " '2981.txt',\n",
       " '2987.txt',\n",
       " '2988.txt',\n",
       " '2992.txt',\n",
       " '2994.txt',\n",
       " '2997.txt',\n",
       " '2999.txt',\n",
       " '3000.txt',\n",
       " '3003.txt',\n",
       " '3007.txt',\n",
       " '3013.txt',\n",
       " '3015.txt',\n",
       " '3017.txt',\n",
       " '3019.txt',\n",
       " '3022.txt',\n",
       " '3025.txt',\n",
       " '3026.txt',\n",
       " '3028.txt',\n",
       " '3031.txt',\n",
       " '3036.txt',\n",
       " '3038.txt',\n",
       " '3049.txt',\n",
       " '3050.txt',\n",
       " '3060.txt',\n",
       " '3062.txt',\n",
       " '3065.txt',\n",
       " '3074.txt',\n",
       " '3075.txt',\n",
       " '3081.txt',\n",
       " '3092.txt',\n",
       " '3097.txt',\n",
       " '3101.txt',\n",
       " '3104.txt',\n",
       " '3106.txt',\n",
       " '3109.txt',\n",
       " '3113.txt',\n",
       " '3115.txt',\n",
       " '3117.txt',\n",
       " '3122.txt',\n",
       " '3127.txt',\n",
       " '3134.txt',\n",
       " '3148.txt',\n",
       " '3150.txt',\n",
       " '3154.txt',\n",
       " '3162.txt',\n",
       " '3165.txt',\n",
       " '3167.txt',\n",
       " '3170.txt',\n",
       " '3171.txt',\n",
       " '3183.txt',\n",
       " '3186.txt',\n",
       " '3190.txt',\n",
       " '3202.txt',\n",
       " '3212.txt',\n",
       " '3214.txt',\n",
       " '3220.txt',\n",
       " '3223.txt',\n",
       " '3224.txt',\n",
       " '3225.txt',\n",
       " '3227.txt',\n",
       " '3233.txt',\n",
       " '3240.txt',\n",
       " '3242.txt',\n",
       " '3244.txt',\n",
       " '3246.txt',\n",
       " '3251.txt',\n",
       " '3253.txt',\n",
       " '3262.txt',\n",
       " '3264.txt',\n",
       " '3265.txt',\n",
       " '3269.txt',\n",
       " '3272.txt',\n",
       " '3274.txt',\n",
       " '3277.txt',\n",
       " '3285.txt',\n",
       " '3287.txt',\n",
       " '3290.txt',\n",
       " '3292.txt',\n",
       " '3297.txt',\n",
       " '3303.txt',\n",
       " '3320.txt',\n",
       " '3324.txt',\n",
       " '3326.txt',\n",
       " '3347.txt',\n",
       " '3352.txt',\n",
       " '3357.txt',\n",
       " '3368.txt',\n",
       " '3374.txt',\n",
       " '3376.txt',\n",
       " '3379.txt',\n",
       " '3381.txt',\n",
       " '3385.txt',\n",
       " '3387.txt',\n",
       " '3388.txt',\n",
       " '3392.txt',\n",
       " '3395.txt',\n",
       " '3399.txt',\n",
       " '3400.txt',\n",
       " '3402.txt',\n",
       " '3406.txt',\n",
       " '3409.txt',\n",
       " '3411.txt',\n",
       " '3415.txt',\n",
       " '3418.txt',\n",
       " '3422.txt',\n",
       " '3436.txt',\n",
       " '3439.txt',\n",
       " '3440.txt',\n",
       " '3442.txt',\n",
       " '3448.txt',\n",
       " '3451.txt',\n",
       " '3453.txt',\n",
       " '3459.txt',\n",
       " '3469.txt',\n",
       " '3474.txt',\n",
       " '3478.txt',\n",
       " '3482.txt',\n",
       " '3486.txt',\n",
       " '3488.txt',\n",
       " '3502.txt',\n",
       " '3509.txt',\n",
       " '3514.txt',\n",
       " '3523.txt',\n",
       " '3527.txt',\n",
       " '3531.txt',\n",
       " '3533.txt',\n",
       " '3538.txt',\n",
       " '3546.txt',\n",
       " '3548.txt',\n",
       " '3552.txt',\n",
       " '3553.txt',\n",
       " '3555.txt',\n",
       " '3558.txt',\n",
       " '3559.txt',\n",
       " '3562.txt',\n",
       " '3564.txt',\n",
       " '3569.txt',\n",
       " '3574.txt',\n",
       " '3580.txt',\n",
       " '3583.txt',\n",
       " '3586.txt',\n",
       " '3591.txt',\n",
       " '3593.txt',\n",
       " '3600.txt',\n",
       " '3602.txt',\n",
       " '3604.txt',\n",
       " '3614.txt',\n",
       " '3616.txt',\n",
       " '3627.txt',\n",
       " '3630.txt',\n",
       " '3636.txt',\n",
       " '3642.txt',\n",
       " '3644.txt',\n",
       " '3647.txt',\n",
       " '3648.txt',\n",
       " '3653.txt',\n",
       " '3655.txt',\n",
       " '3657.txt',\n",
       " '3659.txt',\n",
       " '3661.txt',\n",
       " '3663.txt',\n",
       " '3665.txt',\n",
       " '3669.txt',\n",
       " '3671.txt',\n",
       " '3676.txt',\n",
       " '3678.txt',\n",
       " '3680.txt',\n",
       " '3682.txt',\n",
       " '3684.txt',\n",
       " '3686.txt',\n",
       " '3687.txt',\n",
       " '3693.txt',\n",
       " '3695.txt',\n",
       " '3701.txt',\n",
       " '3708.txt',\n",
       " '3718.txt',\n",
       " '3722.txt',\n",
       " '3725.txt',\n",
       " '3727.txt',\n",
       " '3740.txt',\n",
       " '3742.txt',\n",
       " '3748.txt',\n",
       " '3754.txt',\n",
       " '3760.txt',\n",
       " '3765.txt',\n",
       " '3769.txt',\n",
       " '3771.txt',\n",
       " '3778.txt',\n",
       " '3780.txt',\n",
       " '3784.txt',\n",
       " '3785.txt',\n",
       " '3788.txt',\n",
       " '3790.txt',\n",
       " '3794.txt',\n",
       " '3799.txt',\n",
       " '3806.txt',\n",
       " '3812.txt',\n",
       " '3815.txt',\n",
       " '3818.txt',\n",
       " '3826.txt',\n",
       " '3828.txt',\n",
       " '3838.txt',\n",
       " '3842.txt',\n",
       " '3844.txt',\n",
       " '3848.txt',\n",
       " '3856.txt',\n",
       " '3863.txt',\n",
       " '3870.txt',\n",
       " '3873.txt',\n",
       " '3877.txt',\n",
       " '3880.txt',\n",
       " '3881.txt',\n",
       " '3884.txt',\n",
       " '3891.txt',\n",
       " '3895.txt',\n",
       " '3900.txt',\n",
       " '3904.txt',\n",
       " '3912.txt',\n",
       " '3917.txt',\n",
       " '3919.txt',\n",
       " '3923.txt',\n",
       " '3930.txt',\n",
       " '3937.txt',\n",
       " '3950.txt',\n",
       " '3952.txt',\n",
       " '3954.txt',\n",
       " '3965.txt',\n",
       " '3972.txt',\n",
       " '3973.txt',\n",
       " '3977.txt',\n",
       " '3980.txt',\n",
       " '3982.txt',\n",
       " '3984.txt',\n",
       " '3987.txt',\n",
       " '3995.txt',\n",
       " '3997.txt',\n",
       " '4000.txt',\n",
       " '4003.txt',\n",
       " '4006.txt',\n",
       " '4013.txt',\n",
       " '4015.txt',\n",
       " '4022.txt',\n",
       " '4027.txt',\n",
       " '4029.txt',\n",
       " '4031.txt',\n",
       " '4035.txt',\n",
       " '4041.txt',\n",
       " '4047.txt',\n",
       " '4052.txt',\n",
       " '4056.txt',\n",
       " '4057.txt',\n",
       " '4058.txt',\n",
       " '4073.txt',\n",
       " '4076.txt',\n",
       " '4078.txt',\n",
       " '4081.txt',\n",
       " '4084.txt',\n",
       " '4096.txt',\n",
       " '4101.txt',\n",
       " '4103.txt',\n",
       " '4115.txt',\n",
       " '4116.txt',\n",
       " '4124.txt',\n",
       " '4127.txt',\n",
       " '4135.txt',\n",
       " '4138.txt',\n",
       " '4145.txt',\n",
       " '4150.txt',\n",
       " '4154.txt',\n",
       " '4157.txt',\n",
       " '4159.txt',\n",
       " '4161.txt',\n",
       " '4162.txt',\n",
       " '4165.txt',\n",
       " '4171.txt',\n",
       " '4172.txt',\n",
       " '4177.txt',\n",
       " '4179.txt',\n",
       " '4180.txt',\n",
       " '4182.txt',\n",
       " '4187.txt',\n",
       " '4188.txt',\n",
       " '4193.txt',\n",
       " '4194.txt',\n",
       " '4199.txt',\n",
       " '4202.txt',\n",
       " '4205.txt',\n",
       " '4208.txt',\n",
       " '4229.txt',\n",
       " '4239.txt',\n",
       " '4240.txt',\n",
       " '4247.txt',\n",
       " '4251.txt',\n",
       " '4255.txt',\n",
       " '4263.txt',\n",
       " '4265.txt',\n",
       " '4266.txt',\n",
       " '4268.txt',\n",
       " '4275.txt',\n",
       " '4281.txt',\n",
       " '4284.txt',\n",
       " '4318.txt',\n",
       " '4324.txt',\n",
       " '4333.txt',\n",
       " '4347.txt',\n",
       " '4352.txt',\n",
       " '4353.txt',\n",
       " '4355.txt',\n",
       " '4359.txt',\n",
       " '4372.txt',\n",
       " '4374.txt',\n",
       " '4377.txt',\n",
       " '4386.txt',\n",
       " '4392.txt',\n",
       " '4393.txt',\n",
       " '4402.txt',\n",
       " '4404.txt',\n",
       " '4407.txt',\n",
       " '4411.txt',\n",
       " '4422.txt',\n",
       " '4424.txt',\n",
       " '4427.txt',\n",
       " '4436.txt',\n",
       " '4438.txt',\n",
       " '4443.txt',\n",
       " '4445.txt',\n",
       " '4448.txt',\n",
       " '4450.txt',\n",
       " '4460.txt',\n",
       " '4475.txt',\n",
       " '4482.txt',\n",
       " '4497.txt',\n",
       " '4508.txt',\n",
       " '4517.txt',\n",
       " '4521.txt',\n",
       " '4523.txt',\n",
       " '4530.txt',\n",
       " '4535.txt',\n",
       " '4538.txt',\n",
       " '4550.txt',\n",
       " '4553.txt',\n",
       " '4557.txt',\n",
       " '4559.txt',\n",
       " '4566.txt',\n",
       " '4573.txt',\n",
       " '4578.txt',\n",
       " '4586.txt',\n",
       " '4590.txt',\n",
       " '4592.txt',\n",
       " '4596.txt',\n",
       " '4598.txt',\n",
       " '4602.txt',\n",
       " '4608.txt',\n",
       " '4613.txt',\n",
       " '4641.txt',\n",
       " '4645.txt',\n",
       " '4649.txt',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_cases = os.listdir('D:\\\\DeepMind\\\\合肥高新杯心电人机智能大赛\\\\testA\\\\')\n",
    "all_test_cases.sort(key=lambda x:int(x[:-4]))\n",
    "all_test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.empty(shape=[8036, 5000, 12], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8036/8036 [01:04<00:00, 124.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, sample in enumerate(tqdm(all_test_cases)):\n",
    "    data = pd.read_table('testA\\\\'+sample,header=0, encoding='utf-8', sep=' ')\n",
    "    i = data['I']\n",
    "    ii = data['II']\n",
    "    data['III'] = ii-i\n",
    "    data['aVR']=-(ii+i)/2\n",
    "    data['aVL']=(i-ii)/2\n",
    "    data['aVF']=(ii-i)/2\n",
    "    x_test[idx] = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4,  17,  -6, ..., -10,  -6,   6],\n",
       "       [  3,  15,  -6, ...,  -9,  -6,   6],\n",
       "       [  3,  17,  -7, ..., -10,  -7,   7],\n",
       "       ...,\n",
       "       [ -5, -11,   0, ...,   8,   3,  -3],\n",
       "       [ -5, -11,   0, ...,   8,   3,  -3],\n",
       "       [ -5, -11,   0, ...,   8,   3,  -3]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X&Y Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = np.random.permutation(y_train.shape[0])\n",
    "x_train = x_train[per,:,:]\n",
    "y_train = y_train[per]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = x_train[:20000]\n",
    "y_train_ = y_train[:20000]\n",
    "x_dev_ = x_train[20000:]\n",
    "y_dev_ = y_train[20000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 4480/20000 [=====>........................] - ETA: 44:19 - loss: 0.7146 - accuracy: 0.535 - ETA: 40:10 - loss: 0.7118 - accuracy: 0.534 - ETA: 38:19 - loss: 0.7116 - accuracy: 0.533 - ETA: 37:48 - loss: 0.7073 - accuracy: 0.539 - ETA: 37:16 - loss: 0.7078 - accuracy: 0.537 - ETA: 37:06 - loss: 0.7069 - accuracy: 0.539 - ETA: 36:37 - loss: 0.7055 - accuracy: 0.540 - ETA: 36:18 - loss: 0.7042 - accuracy: 0.543 - ETA: 36:01 - loss: 0.7028 - accuracy: 0.545 - ETA: 35:47 - loss: 0.7004 - accuracy: 0.549 - ETA: 35:42 - loss: 0.6990 - accuracy: 0.549 - ETA: 35:38 - loss: 0.6968 - accuracy: 0.552 - ETA: 35:30 - loss: 0.6939 - accuracy: 0.556 - ETA: 35:21 - loss: 0.6929 - accuracy: 0.557 - ETA: 35:11 - loss: 0.6916 - accuracy: 0.558 - ETA: 35:11 - loss: 0.6902 - accuracy: 0.560 - ETA: 35:05 - loss: 0.6888 - accuracy: 0.561 - ETA: 34:57 - loss: 0.6872 - accuracy: 0.563 - ETA: 34:52 - loss: 0.6855 - accuracy: 0.566 - ETA: 34:44 - loss: 0.6838 - accuracy: 0.568 - ETA: 34:39 - loss: 0.6824 - accuracy: 0.570 - ETA: 34:32 - loss: 0.6811 - accuracy: 0.571 - ETA: 34:34 - loss: 0.6805 - accuracy: 0.571 - ETA: 34:30 - loss: 0.6787 - accuracy: 0.574 - ETA: 34:22 - loss: 0.6782 - accuracy: 0.575 - ETA: 34:17 - loss: 0.6765 - accuracy: 0.577 - ETA: 34:12 - loss: 0.6748 - accuracy: 0.579 - ETA: 34:07 - loss: 0.6732 - accuracy: 0.581 - ETA: 34:06 - loss: 0.6721 - accuracy: 0.583 - ETA: 34:05 - loss: 0.6701 - accuracy: 0.586 - ETA: 34:01 - loss: 0.6686 - accuracy: 0.588 - ETA: 33:59 - loss: 0.6673 - accuracy: 0.589 - ETA: 33:53 - loss: 0.6653 - accuracy: 0.592 - ETA: 33:46 - loss: 0.6641 - accuracy: 0.593 - ETA: 33:45 - loss: 0.6622 - accuracy: 0.596 - ETA: 33:44 - loss: 0.6610 - accuracy: 0.598 - ETA: 33:41 - loss: 0.6599 - accuracy: 0.599 - ETA: 33:37 - loss: 0.6585 - accuracy: 0.601 - ETA: 33:33 - loss: 0.6568 - accuracy: 0.603 - ETA: 33:30 - loss: 0.6556 - accuracy: 0.605 - ETA: 33:25 - loss: 0.6541 - accuracy: 0.607 - ETA: 33:21 - loss: 0.6530 - accuracy: 0.608 - ETA: 33:17 - loss: 0.6518 - accuracy: 0.610 - ETA: 33:14 - loss: 0.6494 - accuracy: 0.613 - ETA: 33:13 - loss: 0.6484 - accuracy: 0.615 - ETA: 33:11 - loss: 0.6470 - accuracy: 0.617 - ETA: 33:08 - loss: 0.6458 - accuracy: 0.618 - ETA: 33:04 - loss: 0.6439 - accuracy: 0.621 - ETA: 33:02 - loss: 0.6429 - accuracy: 0.622 - ETA: 32:59 - loss: 0.6413 - accuracy: 0.624 - ETA: 32:56 - loss: 0.6398 - accuracy: 0.626 - ETA: 32:52 - loss: 0.6383 - accuracy: 0.628 - ETA: 32:48 - loss: 0.6366 - accuracy: 0.630 - ETA: 32:43 - loss: 0.6349 - accuracy: 0.633 - ETA: 32:40 - loss: 0.6331 - accuracy: 0.635 - ETA: 32:36 - loss: 0.6315 - accuracy: 0.637 - ETA: 32:31 - loss: 0.6296 - accuracy: 0.639 - ETA: 32:26 - loss: 0.6277 - accuracy: 0.642 - ETA: 32:22 - loss: 0.6261 - accuracy: 0.644 - ETA: 32:19 - loss: 0.6245 - accuracy: 0.646 - ETA: 32:15 - loss: 0.6228 - accuracy: 0.648 - ETA: 32:10 - loss: 0.6205 - accuracy: 0.651 - ETA: 32:06 - loss: 0.6185 - accuracy: 0.653 - ETA: 32:02 - loss: 0.6167 - accuracy: 0.656 - ETA: 31:59 - loss: 0.6147 - accuracy: 0.658 - ETA: 31:54 - loss: 0.6130 - accuracy: 0.661 - ETA: 31:50 - loss: 0.6110 - accuracy: 0.663 - ETA: 31:46 - loss: 0.6093 - accuracy: 0.665 - ETA: 31:42 - loss: 0.6076 - accuracy: 0.667 - ETA: 31:38 - loss: 0.6059 - accuracy: 0.670 - ETA: 31:35 - loss: 0.6041 - accuracy: 0.672 - ETA: 31:33 - loss: 0.6023 - accuracy: 0.674 - ETA: 31:29 - loss: 0.6009 - accuracy: 0.676 - ETA: 31:26 - loss: 0.5987 - accuracy: 0.678 - ETA: 31:24 - loss: 0.5968 - accuracy: 0.681 - ETA: 31:20 - loss: 0.5953 - accuracy: 0.683 - ETA: 31:16 - loss: 0.5935 - accuracy: 0.685 - ETA: 31:12 - loss: 0.5917 - accuracy: 0.687 - ETA: 31:09 - loss: 0.5901 - accuracy: 0.688 - ETA: 31:05 - loss: 0.5884 - accuracy: 0.690 - ETA: 31:01 - loss: 0.5866 - accuracy: 0.692 - ETA: 30:57 - loss: 0.5851 - accuracy: 0.694 - ETA: 30:54 - loss: 0.5829 - accuracy: 0.696 - ETA: 30:50 - loss: 0.5813 - accuracy: 0.698 - ETA: 30:47 - loss: 0.5799 - accuracy: 0.700 - ETA: 30:43 - loss: 0.5784 - accuracy: 0.702 - ETA: 30:40 - loss: 0.5766 - accuracy: 0.704 - ETA: 30:36 - loss: 0.5749 - accuracy: 0.706 - ETA: 30:33 - loss: 0.5731 - accuracy: 0.707 - ETA: 30:30 - loss: 0.5714 - accuracy: 0.709 - ETA: 30:27 - loss: 0.5692 - accuracy: 0.711 - ETA: 30:23 - loss: 0.5672 - accuracy: 0.713 - ETA: 30:20 - loss: 0.5652 - accuracy: 0.716 - ETA: 30:17 - loss: 0.5633 - accuracy: 0.717 - ETA: 30:14 - loss: 0.5614 - accuracy: 0.719 - ETA: 30:10 - loss: 0.5597 - accuracy: 0.721 - ETA: 30:08 - loss: 0.5577 - accuracy: 0.723 - ETA: 30:05 - loss: 0.5560 - accuracy: 0.725 - ETA: 30:02 - loss: 0.5543 - accuracy: 0.727 - ETA: 29:59 - loss: 0.5526 - accuracy: 0.728 - ETA: 29:55 - loss: 0.5510 - accuracy: 0.730 - ETA: 29:51 - loss: 0.5494 - accuracy: 0.732 - ETA: 29:48 - loss: 0.5475 - accuracy: 0.733 - ETA: 29:44 - loss: 0.5457 - accuracy: 0.735 - ETA: 29:40 - loss: 0.5441 - accuracy: 0.737 - ETA: 29:36 - loss: 0.5426 - accuracy: 0.738 - ETA: 29:32 - loss: 0.5407 - accuracy: 0.740 - ETA: 29:29 - loss: 0.5389 - accuracy: 0.742 - ETA: 29:26 - loss: 0.5372 - accuracy: 0.743 - ETA: 29:23 - loss: 0.5353 - accuracy: 0.745 - ETA: 29:19 - loss: 0.5333 - accuracy: 0.747 - ETA: 29:16 - loss: 0.5315 - accuracy: 0.748 - ETA: 29:13 - loss: 0.5296 - accuracy: 0.750 - ETA: 29:09 - loss: 0.5280 - accuracy: 0.752 - ETA: 29:05 - loss: 0.5261 - accuracy: 0.753 - ETA: 29:02 - loss: 0.5246 - accuracy: 0.755 - ETA: 28:59 - loss: 0.5231 - accuracy: 0.756 - ETA: 28:56 - loss: 0.5212 - accuracy: 0.758 - ETA: 28:52 - loss: 0.5195 - accuracy: 0.759 - ETA: 28:49 - loss: 0.5179 - accuracy: 0.761 - ETA: 28:46 - loss: 0.5164 - accuracy: 0.762 - ETA: 28:42 - loss: 0.5145 - accuracy: 0.763 - ETA: 28:39 - loss: 0.5128 - accuracy: 0.765 - ETA: 28:35 - loss: 0.5114 - accuracy: 0.766 - ETA: 28:32 - loss: 0.5097 - accuracy: 0.767 - ETA: 28:29 - loss: 0.5080 - accuracy: 0.769 - ETA: 28:26 - loss: 0.5066 - accuracy: 0.770 - ETA: 28:24 - loss: 0.5052 - accuracy: 0.771 - ETA: 28:20 - loss: 0.5037 - accuracy: 0.773 - ETA: 28:17 - loss: 0.5021 - accuracy: 0.774 - ETA: 28:14 - loss: 0.5004 - accuracy: 0.775 - ETA: 28:11 - loss: 0.4989 - accuracy: 0.776 - ETA: 28:07 - loss: 0.4972 - accuracy: 0.778 - ETA: 28:03 - loss: 0.4960 - accuracy: 0.778 - ETA: 28:00 - loss: 0.4943 - accuracy: 0.780 - ETA: 27:57 - loss: 0.4930 - accuracy: 0.781 - ETA: 27:54 - loss: 0.4916 - accuracy: 0.782 - ETA: 27:50 - loss: 0.4901 - accuracy: 0.783 - ETA: 27:46 - loss: 0.4886 - accuracy: 0.784 - ETA: 27:42 - loss: 0.4875 - accuracy: 0.7859"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7aa79fc7741d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(55, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_, y_train_, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4106/4106 [==============================] - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 58s - ETA: 57 - ETA: 55 - ETA: 54 - ETA: 52 - ETA: 51 - ETA: 49 - ETA: 48 - ETA: 47 - ETA: 45 - ETA: 44 - ETA: 42 - ETA: 41 - ETA: 39 - ETA: 38 - ETA: 36 - ETA: 35 - ETA: 33 - ETA: 32 - ETA: 30 - ETA: 29 - ETA: 28 - ETA: 26 - ETA: 25 - ETA: 23 - ETA: 22 - ETA: 20 - ETA: 19 - ETA: 17 - ETA: 16 - ETA: 14 - ETA: 13 - ETA: 12 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 187s 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24333301540763566, 0.9633219242095947]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_dev_, y_dev_, batch_size=32)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a9cdcd9c14f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "y_test = model.predict(x_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6766484 , 0.35022932, 0.16154328, 0.28941578, 0.28497666,\n",
       "       0.22030514, 0.24055925, 0.20772591, 0.1482819 , 0.48427814,\n",
       "       0.28301758, 0.22382769, 0.24948785, 0.25200352, 0.20208713,\n",
       "       0.21583503, 0.21663427, 0.22100121, 0.24663994, 0.287032  ,\n",
       "       0.15702209, 0.24644867, 0.26547974, 0.25943142, 0.3930442 ,\n",
       "       0.24795714, 0.24410117, 0.19096336, 0.23484051, 0.23680454,\n",
       "       0.20235676, 0.25933266, 0.22119838, 0.25082195, 0.15721476,\n",
       "       0.38187242, 0.31222337, 0.24417636, 0.2646821 , 0.1180208 ,\n",
       "       0.18628877, 0.18242243, 0.21291104, 0.22750565, 0.35375094,\n",
       "       0.152069  , 0.12692443, 0.14713252, 0.14009166, 0.18553552,\n",
       "       0.30090833, 0.31592965, 0.1395658 , 0.19307888, 0.11731905],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5856/20000 [=======>......................] - ETA: 5:28 - loss: 11.8277 - accuracy: 0.062 - ETA: 4:09 - loss: 11.2758 - accuracy: 0.296 - ETA: 3:39 - loss: 10.8591 - accuracy: 0.416 - ETA: 3:24 - loss: 11.2181 - accuracy: 0.484 - ETA: 3:15 - loss: 11.5114 - accuracy: 0.550 - ETA: 3:09 - loss: 11.0502 - accuracy: 0.588 - ETA: 3:04 - loss: 11.1830 - accuracy: 0.584 - ETA: 3:01 - loss: 11.0571 - accuracy: 0.609 - ETA: 2:58 - loss: 10.9991 - accuracy: 0.614 - ETA: 2:56 - loss: 10.9321 - accuracy: 0.615 - ETA: 2:54 - loss: 10.9780 - accuracy: 0.625 - ETA: 2:52 - loss: 10.8731 - accuracy: 0.630 - ETA: 2:51 - loss: 10.8460 - accuracy: 0.637 - ETA: 2:50 - loss: 10.7920 - accuracy: 0.627 - ETA: 2:49 - loss: 10.9810 - accuracy: 0.637 - ETA: 2:48 - loss: 11.1251 - accuracy: 0.642 - ETA: 2:47 - loss: 11.2350 - accuracy: 0.645 - ETA: 2:46 - loss: 11.1951 - accuracy: 0.649 - ETA: 2:45 - loss: 11.0695 - accuracy: 0.651 - ETA: 2:45 - loss: 11.0762 - accuracy: 0.653 - ETA: 2:44 - loss: 11.1994 - accuracy: 0.659 - ETA: 2:44 - loss: 11.1394 - accuracy: 0.661 - ETA: 2:43 - loss: 11.1080 - accuracy: 0.659 - ETA: 2:43 - loss: 11.1260 - accuracy: 0.657 - ETA: 2:42 - loss: 10.9992 - accuracy: 0.657 - ETA: 2:42 - loss: 10.9754 - accuracy: 0.659 - ETA: 2:41 - loss: 10.9855 - accuracy: 0.658 - ETA: 2:41 - loss: 10.9042 - accuracy: 0.660 - ETA: 2:40 - loss: 10.9330 - accuracy: 0.662 - ETA: 2:40 - loss: 10.8722 - accuracy: 0.665 - ETA: 2:39 - loss: 10.8270 - accuracy: 0.665 - ETA: 2:39 - loss: 10.8066 - accuracy: 0.664 - ETA: 2:38 - loss: 10.7537 - accuracy: 0.666 - ETA: 2:38 - loss: 10.7383 - accuracy: 0.669 - ETA: 2:37 - loss: 10.7404 - accuracy: 0.671 - ETA: 2:37 - loss: 10.7073 - accuracy: 0.674 - ETA: 2:37 - loss: 10.6802 - accuracy: 0.676 - ETA: 2:36 - loss: 10.6642 - accuracy: 0.678 - ETA: 2:36 - loss: 10.6050 - accuracy: 0.679 - ETA: 2:36 - loss: 10.6164 - accuracy: 0.674 - ETA: 2:35 - loss: 10.5622 - accuracy: 0.669 - ETA: 2:35 - loss: 10.5097 - accuracy: 0.657 - ETA: 2:34 - loss: 10.4598 - accuracy: 0.649 - ETA: 2:34 - loss: 10.4047 - accuracy: 0.641 - ETA: 2:34 - loss: 10.3459 - accuracy: 0.636 - ETA: 2:33 - loss: 10.2880 - accuracy: 0.630 - ETA: 2:33 - loss: 10.2403 - accuracy: 0.627 - ETA: 2:33 - loss: 10.2096 - accuracy: 0.621 - ETA: 2:32 - loss: 10.1660 - accuracy: 0.617 - ETA: 2:32 - loss: 10.1219 - accuracy: 0.617 - ETA: 2:32 - loss: 10.0859 - accuracy: 0.615 - ETA: 2:31 - loss: 10.0743 - accuracy: 0.614 - ETA: 2:31 - loss: 10.0257 - accuracy: 0.613 - ETA: 2:31 - loss: 9.9767 - accuracy: 0.614 - ETA: 2:30 - loss: 9.9318 - accuracy: 0.61 - ETA: 2:30 - loss: 9.8972 - accuracy: 0.60 - ETA: 2:30 - loss: 9.8517 - accuracy: 0.60 - ETA: 2:29 - loss: 9.8049 - accuracy: 0.60 - ETA: 2:29 - loss: 9.7624 - accuracy: 0.60 - ETA: 2:29 - loss: 9.7150 - accuracy: 0.59 - ETA: 2:29 - loss: 9.6819 - accuracy: 0.59 - ETA: 2:28 - loss: 9.6432 - accuracy: 0.59 - ETA: 2:28 - loss: 9.6168 - accuracy: 0.59 - ETA: 2:28 - loss: 9.5875 - accuracy: 0.59 - ETA: 2:27 - loss: 9.5559 - accuracy: 0.59 - ETA: 2:27 - loss: 9.5223 - accuracy: 0.58 - ETA: 2:27 - loss: 9.4788 - accuracy: 0.58 - ETA: 2:26 - loss: 9.4546 - accuracy: 0.58 - ETA: 2:26 - loss: 9.4145 - accuracy: 0.58 - ETA: 2:26 - loss: 9.3847 - accuracy: 0.57 - ETA: 2:25 - loss: 9.3549 - accuracy: 0.57 - ETA: 2:25 - loss: 9.3307 - accuracy: 0.57 - ETA: 2:25 - loss: 9.2979 - accuracy: 0.57 - ETA: 2:25 - loss: 9.2750 - accuracy: 0.56 - ETA: 2:24 - loss: 9.2459 - accuracy: 0.56 - ETA: 2:24 - loss: 9.2123 - accuracy: 0.56 - ETA: 2:24 - loss: 9.1838 - accuracy: 0.56 - ETA: 2:23 - loss: 9.1565 - accuracy: 0.55 - ETA: 2:23 - loss: 9.1256 - accuracy: 0.55 - ETA: 2:23 - loss: 9.0907 - accuracy: 0.55 - ETA: 2:23 - loss: 9.0584 - accuracy: 0.55 - ETA: 2:22 - loss: 9.0422 - accuracy: 0.55 - ETA: 2:22 - loss: 9.0184 - accuracy: 0.55 - ETA: 2:22 - loss: 9.0036 - accuracy: 0.55 - ETA: 2:21 - loss: 8.9793 - accuracy: 0.55 - ETA: 2:21 - loss: 8.9494 - accuracy: 0.55 - ETA: 2:21 - loss: 8.9372 - accuracy: 0.55 - ETA: 2:21 - loss: 8.9154 - accuracy: 0.54 - ETA: 2:20 - loss: 8.8886 - accuracy: 0.55 - ETA: 2:20 - loss: 8.8666 - accuracy: 0.55 - ETA: 2:20 - loss: 8.8373 - accuracy: 0.55 - ETA: 2:19 - loss: 8.8184 - accuracy: 0.55 - ETA: 2:19 - loss: 8.7913 - accuracy: 0.55 - ETA: 2:19 - loss: 8.7743 - accuracy: 0.55 - ETA: 2:18 - loss: 8.7539 - accuracy: 0.55 - ETA: 2:18 - loss: 8.7404 - accuracy: 0.55 - ETA: 2:18 - loss: 8.7241 - accuracy: 0.55 - ETA: 2:18 - loss: 8.7050 - accuracy: 0.55 - ETA: 2:17 - loss: 8.6920 - accuracy: 0.55 - ETA: 2:17 - loss: 8.6687 - accuracy: 0.55 - ETA: 2:17 - loss: 8.6511 - accuracy: 0.55 - ETA: 2:17 - loss: 8.6274 - accuracy: 0.55 - ETA: 2:16 - loss: 8.6101 - accuracy: 0.55 - ETA: 2:16 - loss: 8.6012 - accuracy: 0.55 - ETA: 2:16 - loss: 8.5786 - accuracy: 0.55 - ETA: 2:16 - loss: 8.5680 - accuracy: 0.55 - ETA: 2:15 - loss: 8.5677 - accuracy: 0.55 - ETA: 2:15 - loss: 8.5486 - accuracy: 0.55 - ETA: 2:15 - loss: 8.5284 - accuracy: 0.55 - ETA: 2:14 - loss: 8.4995 - accuracy: 0.55 - ETA: 2:14 - loss: 8.4897 - accuracy: 0.55 - ETA: 2:14 - loss: 8.4716 - accuracy: 0.55 - ETA: 2:14 - loss: 8.4696 - accuracy: 0.55 - ETA: 2:13 - loss: 8.4570 - accuracy: 0.55 - ETA: 2:13 - loss: 8.4359 - accuracy: 0.55 - ETA: 2:13 - loss: 8.4225 - accuracy: 0.55 - ETA: 2:13 - loss: 8.4133 - accuracy: 0.55 - ETA: 2:12 - loss: 8.4050 - accuracy: 0.55 - ETA: 2:12 - loss: 8.3979 - accuracy: 0.55 - ETA: 2:12 - loss: 8.3801 - accuracy: 0.55 - ETA: 2:12 - loss: 8.3704 - accuracy: 0.55 - ETA: 2:11 - loss: 8.3545 - accuracy: 0.55 - ETA: 2:11 - loss: 8.3414 - accuracy: 0.55 - ETA: 2:11 - loss: 8.3264 - accuracy: 0.55 - ETA: 2:11 - loss: 8.3087 - accuracy: 0.55 - ETA: 2:10 - loss: 8.2990 - accuracy: 0.55 - ETA: 2:10 - loss: 8.2841 - accuracy: 0.56 - ETA: 2:10 - loss: 8.2729 - accuracy: 0.56 - ETA: 2:10 - loss: 8.2574 - accuracy: 0.56 - ETA: 2:09 - loss: 8.2495 - accuracy: 0.56 - ETA: 2:09 - loss: 8.2422 - accuracy: 0.56 - ETA: 2:09 - loss: 8.2275 - accuracy: 0.56 - ETA: 2:08 - loss: 8.2155 - accuracy: 0.56 - ETA: 2:08 - loss: 8.2008 - accuracy: 0.56 - ETA: 2:08 - loss: 8.1890 - accuracy: 0.56 - ETA: 2:08 - loss: 8.1843 - accuracy: 0.56 - ETA: 2:08 - loss: 8.1765 - accuracy: 0.56 - ETA: 2:09 - loss: 8.1665 - accuracy: 0.56 - ETA: 2:08 - loss: 8.1546 - accuracy: 0.56 - ETA: 2:08 - loss: 8.1483 - accuracy: 0.56 - ETA: 2:08 - loss: 8.1406 - accuracy: 0.56 - ETA: 2:07 - loss: 8.1379 - accuracy: 0.56 - ETA: 2:07 - loss: 8.1323 - accuracy: 0.56 - ETA: 2:07 - loss: 8.1226 - accuracy: 0.56 - ETA: 2:07 - loss: 8.1151 - accuracy: 0.56 - ETA: 2:06 - loss: 8.1038 - accuracy: 0.56 - ETA: 2:06 - loss: 8.0943 - accuracy: 0.56 - ETA: 2:06 - loss: 8.0839 - accuracy: 0.56 - ETA: 2:06 - loss: 8.0773 - accuracy: 0.56 - ETA: 2:05 - loss: 8.0740 - accuracy: 0.56 - ETA: 2:05 - loss: 8.0677 - accuracy: 0.56 - ETA: 2:05 - loss: 8.0608 - accuracy: 0.56 - ETA: 2:04 - loss: 8.0511 - accuracy: 0.56 - ETA: 2:04 - loss: 8.0381 - accuracy: 0.56 - ETA: 2:04 - loss: 8.0249 - accuracy: 0.56 - ETA: 2:04 - loss: 8.0155 - accuracy: 0.56 - ETA: 2:03 - loss: 8.0035 - accuracy: 0.56 - ETA: 2:03 - loss: 7.9896 - accuracy: 0.56 - ETA: 2:03 - loss: 7.9793 - accuracy: 0.56 - ETA: 2:03 - loss: 7.9765 - accuracy: 0.56 - ETA: 2:02 - loss: 7.9705 - accuracy: 0.57 - ETA: 2:02 - loss: 7.9612 - accuracy: 0.57 - ETA: 2:02 - loss: 7.9554 - accuracy: 0.57 - ETA: 2:01 - loss: 7.9471 - accuracy: 0.57 - ETA: 2:01 - loss: 7.9356 - accuracy: 0.57 - ETA: 2:01 - loss: 7.9211 - accuracy: 0.57 - ETA: 2:01 - loss: 7.9163 - accuracy: 0.57 - ETA: 2:01 - loss: 7.9066 - accuracy: 0.57 - ETA: 2:00 - loss: 7.8962 - accuracy: 0.57 - ETA: 2:00 - loss: 7.8869 - accuracy: 0.57 - ETA: 2:00 - loss: 7.8773 - accuracy: 0.57 - ETA: 1:59 - loss: 7.8631 - accuracy: 0.57 - ETA: 1:59 - loss: 7.8539 - accuracy: 0.57 - ETA: 1:59 - loss: 7.8479 - accuracy: 0.57 - ETA: 1:59 - loss: 7.8448 - accuracy: 0.57 - ETA: 1:58 - loss: 7.8362 - accuracy: 0.57 - ETA: 1:58 - loss: 7.8311 - accuracy: 0.57 - ETA: 1:58 - loss: 7.8325 - accuracy: 0.57 - ETA: 1:58 - loss: 7.8312 - accuracy: 0.58 - ETA: 1:58 - loss: 7.8288 - accuracy: 0.58 - ETA: 1:57 - loss: 7.8213 - accuracy: 0.58 - ETA: 1:57 - loss: 7.8122 - accuracy: 0.58 - ETA: 1:57 - loss: 7.8014 - accuracy: 0.5845\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11808/20000 [================>.............] - ETA: 1:57 - loss: 7.7923 - accuracy: 0.58 - ETA: 1:56 - loss: 7.7827 - accuracy: 0.58 - ETA: 1:56 - loss: 7.7829 - accuracy: 0.58 - ETA: 1:56 - loss: 7.7783 - accuracy: 0.58 - ETA: 1:56 - loss: 7.7712 - accuracy: 0.58 - ETA: 1:55 - loss: 7.7640 - accuracy: 0.58 - ETA: 1:55 - loss: 7.7566 - accuracy: 0.58 - ETA: 1:55 - loss: 7.7475 - accuracy: 0.58 - ETA: 1:55 - loss: 7.7416 - accuracy: 0.58 - ETA: 1:54 - loss: 7.7311 - accuracy: 0.59 - ETA: 1:54 - loss: 7.7234 - accuracy: 0.59 - ETA: 1:54 - loss: 7.7102 - accuracy: 0.59 - ETA: 1:53 - loss: 7.6991 - accuracy: 0.59 - ETA: 1:53 - loss: 7.6972 - accuracy: 0.59 - ETA: 1:53 - loss: 7.6941 - accuracy: 0.59 - ETA: 1:53 - loss: 7.6856 - accuracy: 0.59 - ETA: 1:52 - loss: 7.6818 - accuracy: 0.59 - ETA: 1:52 - loss: 7.6724 - accuracy: 0.59 - ETA: 1:52 - loss: 7.6673 - accuracy: 0.59 - ETA: 1:52 - loss: 7.6592 - accuracy: 0.59 - ETA: 1:51 - loss: 7.6495 - accuracy: 0.59 - ETA: 1:51 - loss: 7.6473 - accuracy: 0.59 - ETA: 1:51 - loss: 7.6405 - accuracy: 0.59 - ETA: 1:50 - loss: 7.6345 - accuracy: 0.59 - ETA: 1:50 - loss: 7.6267 - accuracy: 0.59 - ETA: 1:50 - loss: 7.6194 - accuracy: 0.59 - ETA: 1:50 - loss: 7.6082 - accuracy: 0.59 - ETA: 1:49 - loss: 7.6069 - accuracy: 0.59 - ETA: 1:49 - loss: 7.5999 - accuracy: 0.59 - ETA: 1:49 - loss: 7.5961 - accuracy: 0.59 - ETA: 1:49 - loss: 7.5919 - accuracy: 0.59 - ETA: 1:48 - loss: 7.5838 - accuracy: 0.59 - ETA: 1:48 - loss: 7.5787 - accuracy: 0.59 - ETA: 1:48 - loss: 7.5734 - accuracy: 0.60 - ETA: 1:47 - loss: 7.5662 - accuracy: 0.60 - ETA: 1:47 - loss: 7.5646 - accuracy: 0.60 - ETA: 1:47 - loss: 7.5588 - accuracy: 0.60 - ETA: 1:47 - loss: 7.5511 - accuracy: 0.60 - ETA: 1:46 - loss: 7.5501 - accuracy: 0.60 - ETA: 1:46 - loss: 7.5485 - accuracy: 0.60 - ETA: 1:46 - loss: 7.5420 - accuracy: 0.60 - ETA: 1:46 - loss: 7.5349 - accuracy: 0.60 - ETA: 1:45 - loss: 7.5316 - accuracy: 0.60 - ETA: 1:45 - loss: 7.5269 - accuracy: 0.60 - ETA: 1:45 - loss: 7.5206 - accuracy: 0.60 - ETA: 1:45 - loss: 7.5147 - accuracy: 0.60 - ETA: 1:44 - loss: 7.5076 - accuracy: 0.60 - ETA: 1:44 - loss: 7.5034 - accuracy: 0.60 - ETA: 1:44 - loss: 7.4963 - accuracy: 0.60 - ETA: 1:44 - loss: 7.4926 - accuracy: 0.60 - ETA: 1:43 - loss: 7.4856 - accuracy: 0.60 - ETA: 1:43 - loss: 7.4803 - accuracy: 0.60 - ETA: 1:43 - loss: 7.4682 - accuracy: 0.60 - ETA: 1:43 - loss: 7.4685 - accuracy: 0.60 - ETA: 1:42 - loss: 7.4667 - accuracy: 0.60 - ETA: 1:42 - loss: 7.4671 - accuracy: 0.60 - ETA: 1:42 - loss: 7.4612 - accuracy: 0.60 - ETA: 1:41 - loss: 7.4571 - accuracy: 0.60 - ETA: 1:41 - loss: 7.4498 - accuracy: 0.60 - ETA: 1:41 - loss: 7.4494 - accuracy: 0.60 - ETA: 1:41 - loss: 7.4467 - accuracy: 0.61 - ETA: 1:41 - loss: 7.4434 - accuracy: 0.61 - ETA: 1:40 - loss: 7.4422 - accuracy: 0.61 - ETA: 1:40 - loss: 7.4377 - accuracy: 0.61 - ETA: 1:40 - loss: 7.4312 - accuracy: 0.61 - ETA: 1:40 - loss: 7.4287 - accuracy: 0.61 - ETA: 1:39 - loss: 7.4201 - accuracy: 0.61 - ETA: 1:39 - loss: 7.4188 - accuracy: 0.61 - ETA: 1:39 - loss: 7.4123 - accuracy: 0.61 - ETA: 1:39 - loss: 7.4089 - accuracy: 0.61 - ETA: 1:38 - loss: 7.4041 - accuracy: 0.61 - ETA: 1:38 - loss: 7.3997 - accuracy: 0.61 - ETA: 1:38 - loss: 7.3946 - accuracy: 0.61 - ETA: 1:37 - loss: 7.3922 - accuracy: 0.61 - ETA: 1:37 - loss: 7.3879 - accuracy: 0.61 - ETA: 1:37 - loss: 7.3834 - accuracy: 0.61 - ETA: 1:37 - loss: 7.3812 - accuracy: 0.61 - ETA: 1:36 - loss: 7.3745 - accuracy: 0.61 - ETA: 1:36 - loss: 7.3687 - accuracy: 0.61 - ETA: 1:36 - loss: 7.3630 - accuracy: 0.61 - ETA: 1:36 - loss: 7.3567 - accuracy: 0.61 - ETA: 1:36 - loss: 7.3554 - accuracy: 0.61 - ETA: 1:35 - loss: 7.3524 - accuracy: 0.61 - ETA: 1:35 - loss: 7.3473 - accuracy: 0.62 - ETA: 1:35 - loss: 7.3402 - accuracy: 0.62 - ETA: 1:35 - loss: 7.3421 - accuracy: 0.62 - ETA: 1:34 - loss: 7.3340 - accuracy: 0.62 - ETA: 1:34 - loss: 7.3267 - accuracy: 0.62 - ETA: 1:34 - loss: 7.3282 - accuracy: 0.62 - ETA: 1:34 - loss: 7.3241 - accuracy: 0.62 - ETA: 1:33 - loss: 7.3198 - accuracy: 0.62 - ETA: 1:33 - loss: 7.3166 - accuracy: 0.62 - ETA: 1:33 - loss: 7.3120 - accuracy: 0.62 - ETA: 1:33 - loss: 7.3051 - accuracy: 0.62 - ETA: 1:33 - loss: 7.3046 - accuracy: 0.62 - ETA: 1:32 - loss: 7.3019 - accuracy: 0.62 - ETA: 1:32 - loss: 7.2982 - accuracy: 0.62 - ETA: 1:32 - loss: 7.2950 - accuracy: 0.62 - ETA: 1:31 - loss: 7.2929 - accuracy: 0.62 - ETA: 1:31 - loss: 7.2845 - accuracy: 0.62 - ETA: 1:31 - loss: 7.2802 - accuracy: 0.62 - ETA: 1:31 - loss: 7.2757 - accuracy: 0.62 - ETA: 1:30 - loss: 7.2707 - accuracy: 0.62 - ETA: 1:30 - loss: 7.2690 - accuracy: 0.62 - ETA: 1:30 - loss: 7.2646 - accuracy: 0.62 - ETA: 1:30 - loss: 7.2618 - accuracy: 0.62 - ETA: 1:29 - loss: 7.2561 - accuracy: 0.62 - ETA: 1:29 - loss: 7.2568 - accuracy: 0.62 - ETA: 1:29 - loss: 7.2545 - accuracy: 0.62 - ETA: 1:29 - loss: 7.2495 - accuracy: 0.62 - ETA: 1:28 - loss: 7.2469 - accuracy: 0.62 - ETA: 1:28 - loss: 7.2433 - accuracy: 0.62 - ETA: 1:28 - loss: 7.2386 - accuracy: 0.62 - ETA: 1:28 - loss: 7.2317 - accuracy: 0.62 - ETA: 1:27 - loss: 7.2289 - accuracy: 0.62 - ETA: 1:27 - loss: 7.2238 - accuracy: 0.62 - ETA: 1:27 - loss: 7.2184 - accuracy: 0.62 - ETA: 1:27 - loss: 7.2121 - accuracy: 0.62 - ETA: 1:26 - loss: 7.2107 - accuracy: 0.62 - ETA: 1:26 - loss: 7.2046 - accuracy: 0.62 - ETA: 1:26 - loss: 7.2004 - accuracy: 0.62 - ETA: 1:26 - loss: 7.1969 - accuracy: 0.62 - ETA: 1:25 - loss: 7.1946 - accuracy: 0.62 - ETA: 1:25 - loss: 7.1901 - accuracy: 0.62 - ETA: 1:25 - loss: 7.1878 - accuracy: 0.62 - ETA: 1:24 - loss: 7.1850 - accuracy: 0.63 - ETA: 1:24 - loss: 7.1821 - accuracy: 0.63 - ETA: 1:24 - loss: 7.1809 - accuracy: 0.63 - ETA: 1:24 - loss: 7.1781 - accuracy: 0.63 - ETA: 1:23 - loss: 7.1770 - accuracy: 0.63 - ETA: 1:23 - loss: 7.1753 - accuracy: 0.63 - ETA: 1:23 - loss: 7.1727 - accuracy: 0.63 - ETA: 1:23 - loss: 7.1693 - accuracy: 0.63 - ETA: 1:22 - loss: 7.1660 - accuracy: 0.63 - ETA: 1:22 - loss: 7.1623 - accuracy: 0.63 - ETA: 1:22 - loss: 7.1587 - accuracy: 0.63 - ETA: 1:22 - loss: 7.1568 - accuracy: 0.63 - ETA: 1:21 - loss: 7.1531 - accuracy: 0.63 - ETA: 1:21 - loss: 7.1478 - accuracy: 0.63 - ETA: 1:21 - loss: 7.1442 - accuracy: 0.63 - ETA: 1:20 - loss: 7.1419 - accuracy: 0.63 - ETA: 1:20 - loss: 7.1409 - accuracy: 0.63 - ETA: 1:20 - loss: 7.1372 - accuracy: 0.63 - ETA: 1:20 - loss: 7.1337 - accuracy: 0.63 - ETA: 1:19 - loss: 7.1297 - accuracy: 0.63 - ETA: 1:19 - loss: 7.1260 - accuracy: 0.63 - ETA: 1:19 - loss: 7.1227 - accuracy: 0.63 - ETA: 1:19 - loss: 7.1187 - accuracy: 0.63 - ETA: 1:18 - loss: 7.1203 - accuracy: 0.63 - ETA: 1:18 - loss: 7.1199 - accuracy: 0.63 - ETA: 1:18 - loss: 7.1160 - accuracy: 0.63 - ETA: 1:18 - loss: 7.1114 - accuracy: 0.63 - ETA: 1:17 - loss: 7.1092 - accuracy: 0.63 - ETA: 1:17 - loss: 7.1040 - accuracy: 0.63 - ETA: 1:17 - loss: 7.1018 - accuracy: 0.63 - ETA: 1:17 - loss: 7.0971 - accuracy: 0.63 - ETA: 1:16 - loss: 7.0919 - accuracy: 0.63 - ETA: 1:16 - loss: 7.0906 - accuracy: 0.63 - ETA: 1:16 - loss: 7.0846 - accuracy: 0.63 - ETA: 1:16 - loss: 7.0791 - accuracy: 0.63 - ETA: 1:15 - loss: 7.0751 - accuracy: 0.64 - ETA: 1:15 - loss: 7.0719 - accuracy: 0.64 - ETA: 1:15 - loss: 7.0722 - accuracy: 0.64 - ETA: 1:14 - loss: 7.0705 - accuracy: 0.64 - ETA: 1:14 - loss: 7.0647 - accuracy: 0.64 - ETA: 1:14 - loss: 7.0589 - accuracy: 0.64 - ETA: 1:14 - loss: 7.0549 - accuracy: 0.64 - ETA: 1:13 - loss: 7.0502 - accuracy: 0.64 - ETA: 1:13 - loss: 7.0450 - accuracy: 0.64 - ETA: 1:13 - loss: 7.0407 - accuracy: 0.64 - ETA: 1:13 - loss: 7.0361 - accuracy: 0.64 - ETA: 1:12 - loss: 7.0327 - accuracy: 0.64 - ETA: 1:12 - loss: 7.0278 - accuracy: 0.64 - ETA: 1:12 - loss: 7.0244 - accuracy: 0.64 - ETA: 1:12 - loss: 7.0209 - accuracy: 0.64 - ETA: 1:11 - loss: 7.0160 - accuracy: 0.64 - ETA: 1:11 - loss: 7.0137 - accuracy: 0.64 - ETA: 1:11 - loss: 7.0081 - accuracy: 0.64 - ETA: 1:11 - loss: 7.0009 - accuracy: 0.64 - ETA: 1:10 - loss: 6.9956 - accuracy: 0.64 - ETA: 1:10 - loss: 6.9899 - accuracy: 0.64 - ETA: 1:10 - loss: 6.9886 - accuracy: 0.64 - ETA: 1:10 - loss: 6.9869 - accuracy: 0.64 - ETA: 1:09 - loss: 6.9857 - accuracy: 0.64 - ETA: 1:09 - loss: 6.9843 - accuracy: 0.64 - ETA: 1:09 - loss: 6.9806 - accuracy: 0.6440"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17760/20000 [=========================>....] - ETA: 1:09 - loss: 6.9757 - accuracy: 0.64 - ETA: 1:08 - loss: 6.9701 - accuracy: 0.64 - ETA: 1:08 - loss: 6.9684 - accuracy: 0.64 - ETA: 1:08 - loss: 6.9664 - accuracy: 0.64 - ETA: 1:08 - loss: 6.9640 - accuracy: 0.64 - ETA: 1:08 - loss: 6.9625 - accuracy: 0.64 - ETA: 1:07 - loss: 6.9611 - accuracy: 0.64 - ETA: 1:07 - loss: 6.9564 - accuracy: 0.64 - ETA: 1:07 - loss: 6.9525 - accuracy: 0.64 - ETA: 1:06 - loss: 6.9511 - accuracy: 0.64 - ETA: 1:06 - loss: 6.9485 - accuracy: 0.64 - ETA: 1:06 - loss: 6.9465 - accuracy: 0.64 - ETA: 1:06 - loss: 6.9425 - accuracy: 0.64 - ETA: 1:05 - loss: 6.9390 - accuracy: 0.64 - ETA: 1:05 - loss: 6.9345 - accuracy: 0.64 - ETA: 1:05 - loss: 6.9322 - accuracy: 0.64 - ETA: 1:04 - loss: 6.9304 - accuracy: 0.64 - ETA: 1:04 - loss: 6.9249 - accuracy: 0.64 - ETA: 1:04 - loss: 6.9215 - accuracy: 0.64 - ETA: 1:04 - loss: 6.9205 - accuracy: 0.64 - ETA: 1:03 - loss: 6.9195 - accuracy: 0.64 - ETA: 1:03 - loss: 6.9169 - accuracy: 0.64 - ETA: 1:03 - loss: 6.9120 - accuracy: 0.64 - ETA: 1:03 - loss: 6.9143 - accuracy: 0.64 - ETA: 1:02 - loss: 6.9118 - accuracy: 0.64 - ETA: 1:02 - loss: 6.9114 - accuracy: 0.64 - ETA: 1:02 - loss: 6.9098 - accuracy: 0.64 - ETA: 1:01 - loss: 6.9071 - accuracy: 0.64 - ETA: 1:01 - loss: 6.9028 - accuracy: 0.64 - ETA: 1:01 - loss: 6.9004 - accuracy: 0.64 - ETA: 1:01 - loss: 6.9027 - accuracy: 0.64 - ETA: 1:00 - loss: 6.8995 - accuracy: 0.64 - ETA: 1:00 - loss: 6.8946 - accuracy: 0.64 - ETA: 1:00 - loss: 6.8941 - accuracy: 0.64 - ETA: 1:00 - loss: 6.8900 - accuracy: 0.64 - ETA: 59s - loss: 6.8863 - accuracy: 0.6476 - ETA: 59s - loss: 6.8819 - accuracy: 0.647 - ETA: 59s - loss: 6.8792 - accuracy: 0.647 - ETA: 58s - loss: 6.8752 - accuracy: 0.648 - ETA: 58s - loss: 6.8722 - accuracy: 0.648 - ETA: 58s - loss: 6.8698 - accuracy: 0.648 - ETA: 58s - loss: 6.8689 - accuracy: 0.648 - ETA: 57s - loss: 6.8699 - accuracy: 0.648 - ETA: 57s - loss: 6.8672 - accuracy: 0.648 - ETA: 57s - loss: 6.8633 - accuracy: 0.648 - ETA: 57s - loss: 6.8596 - accuracy: 0.648 - ETA: 56s - loss: 6.8623 - accuracy: 0.648 - ETA: 56s - loss: 6.8601 - accuracy: 0.649 - ETA: 56s - loss: 6.8565 - accuracy: 0.649 - ETA: 55s - loss: 6.8541 - accuracy: 0.649 - ETA: 55s - loss: 6.8522 - accuracy: 0.649 - ETA: 55s - loss: 6.8474 - accuracy: 0.649 - ETA: 55s - loss: 6.8443 - accuracy: 0.649 - ETA: 54s - loss: 6.8438 - accuracy: 0.649 - ETA: 54s - loss: 6.8419 - accuracy: 0.649 - ETA: 54s - loss: 6.8436 - accuracy: 0.649 - ETA: 54s - loss: 6.8403 - accuracy: 0.649 - ETA: 53s - loss: 6.8407 - accuracy: 0.648 - ETA: 53s - loss: 6.8396 - accuracy: 0.649 - ETA: 53s - loss: 6.8412 - accuracy: 0.648 - ETA: 52s - loss: 6.8374 - accuracy: 0.649 - ETA: 52s - loss: 6.8355 - accuracy: 0.649 - ETA: 52s - loss: 6.8323 - accuracy: 0.649 - ETA: 52s - loss: 6.8314 - accuracy: 0.649 - ETA: 51s - loss: 6.8283 - accuracy: 0.649 - ETA: 51s - loss: 6.8243 - accuracy: 0.650 - ETA: 51s - loss: 6.8227 - accuracy: 0.650 - ETA: 51s - loss: 6.8201 - accuracy: 0.650 - ETA: 50s - loss: 6.8160 - accuracy: 0.650 - ETA: 50s - loss: 6.8170 - accuracy: 0.650 - ETA: 50s - loss: 6.8157 - accuracy: 0.650 - ETA: 50s - loss: 6.8167 - accuracy: 0.650 - ETA: 49s - loss: 6.8117 - accuracy: 0.650 - ETA: 49s - loss: 6.8110 - accuracy: 0.651 - ETA: 49s - loss: 6.8103 - accuracy: 0.651 - ETA: 48s - loss: 6.8078 - accuracy: 0.651 - ETA: 48s - loss: 6.8063 - accuracy: 0.651 - ETA: 48s - loss: 6.8053 - accuracy: 0.651 - ETA: 48s - loss: 6.8073 - accuracy: 0.651 - ETA: 47s - loss: 6.8035 - accuracy: 0.652 - ETA: 47s - loss: 6.8003 - accuracy: 0.652 - ETA: 47s - loss: 6.7962 - accuracy: 0.652 - ETA: 47s - loss: 6.7932 - accuracy: 0.652 - ETA: 46s - loss: 6.7902 - accuracy: 0.651 - ETA: 46s - loss: 6.7888 - accuracy: 0.651 - ETA: 46s - loss: 6.7864 - accuracy: 0.652 - ETA: 45s - loss: 6.7833 - accuracy: 0.652 - ETA: 45s - loss: 6.7810 - accuracy: 0.652 - ETA: 45s - loss: 6.7809 - accuracy: 0.652 - ETA: 45s - loss: 6.7768 - accuracy: 0.652 - ETA: 44s - loss: 6.7755 - accuracy: 0.652 - ETA: 44s - loss: 6.7737 - accuracy: 0.652 - ETA: 44s - loss: 6.7706 - accuracy: 0.653 - ETA: 44s - loss: 6.7673 - accuracy: 0.653 - ETA: 43s - loss: 6.7655 - accuracy: 0.653 - ETA: 43s - loss: 6.7629 - accuracy: 0.653 - ETA: 43s - loss: 6.7601 - accuracy: 0.653 - ETA: 43s - loss: 6.7562 - accuracy: 0.653 - ETA: 42s - loss: 6.7535 - accuracy: 0.653 - ETA: 42s - loss: 6.7541 - accuracy: 0.654 - ETA: 42s - loss: 6.7528 - accuracy: 0.654 - ETA: 41s - loss: 6.7492 - accuracy: 0.654 - ETA: 41s - loss: 6.7482 - accuracy: 0.654 - ETA: 41s - loss: 6.7476 - accuracy: 0.654 - ETA: 41s - loss: 6.7464 - accuracy: 0.654 - ETA: 40s - loss: 6.7427 - accuracy: 0.654 - ETA: 40s - loss: 6.7404 - accuracy: 0.654 - ETA: 40s - loss: 6.7384 - accuracy: 0.654 - ETA: 40s - loss: 6.7383 - accuracy: 0.654 - ETA: 39s - loss: 6.7381 - accuracy: 0.654 - ETA: 39s - loss: 6.7364 - accuracy: 0.655 - ETA: 39s - loss: 6.7347 - accuracy: 0.655 - ETA: 38s - loss: 6.7342 - accuracy: 0.655 - ETA: 38s - loss: 6.7307 - accuracy: 0.655 - ETA: 38s - loss: 6.7314 - accuracy: 0.655 - ETA: 38s - loss: 6.7330 - accuracy: 0.655 - ETA: 37s - loss: 6.7312 - accuracy: 0.655 - ETA: 37s - loss: 6.7303 - accuracy: 0.655 - ETA: 37s - loss: 6.7294 - accuracy: 0.655 - ETA: 37s - loss: 6.7254 - accuracy: 0.655 - ETA: 36s - loss: 6.7231 - accuracy: 0.655 - ETA: 36s - loss: 6.7236 - accuracy: 0.655 - ETA: 36s - loss: 6.7206 - accuracy: 0.655 - ETA: 35s - loss: 6.7190 - accuracy: 0.655 - ETA: 35s - loss: 6.7163 - accuracy: 0.655 - ETA: 35s - loss: 6.7142 - accuracy: 0.655 - ETA: 35s - loss: 6.7105 - accuracy: 0.656 - ETA: 34s - loss: 6.7109 - accuracy: 0.656 - ETA: 34s - loss: 6.7096 - accuracy: 0.656 - ETA: 34s - loss: 6.7099 - accuracy: 0.656 - ETA: 34s - loss: 6.7103 - accuracy: 0.656 - ETA: 33s - loss: 6.7067 - accuracy: 0.656 - ETA: 33s - loss: 6.7043 - accuracy: 0.656 - ETA: 33s - loss: 6.7035 - accuracy: 0.656 - ETA: 32s - loss: 6.7034 - accuracy: 0.656 - ETA: 32s - loss: 6.7011 - accuracy: 0.656 - ETA: 32s - loss: 6.6986 - accuracy: 0.656 - ETA: 32s - loss: 6.6942 - accuracy: 0.657 - ETA: 31s - loss: 6.6913 - accuracy: 0.656 - ETA: 31s - loss: 6.6877 - accuracy: 0.656 - ETA: 31s - loss: 6.6875 - accuracy: 0.657 - ETA: 31s - loss: 6.6853 - accuracy: 0.657 - ETA: 30s - loss: 6.6819 - accuracy: 0.657 - ETA: 30s - loss: 6.6801 - accuracy: 0.657 - ETA: 30s - loss: 6.6797 - accuracy: 0.657 - ETA: 30s - loss: 6.6764 - accuracy: 0.657 - ETA: 29s - loss: 6.6757 - accuracy: 0.657 - ETA: 29s - loss: 6.6726 - accuracy: 0.657 - ETA: 29s - loss: 6.6698 - accuracy: 0.657 - ETA: 29s - loss: 6.6679 - accuracy: 0.658 - ETA: 28s - loss: 6.6654 - accuracy: 0.658 - ETA: 28s - loss: 6.6664 - accuracy: 0.657 - ETA: 28s - loss: 6.6655 - accuracy: 0.658 - ETA: 27s - loss: 6.6636 - accuracy: 0.658 - ETA: 27s - loss: 6.6603 - accuracy: 0.658 - ETA: 27s - loss: 6.6566 - accuracy: 0.658 - ETA: 27s - loss: 6.6547 - accuracy: 0.658 - ETA: 26s - loss: 6.6521 - accuracy: 0.658 - ETA: 26s - loss: 6.6489 - accuracy: 0.659 - ETA: 26s - loss: 6.6453 - accuracy: 0.659 - ETA: 26s - loss: 6.6420 - accuracy: 0.659 - ETA: 25s - loss: 6.6405 - accuracy: 0.659 - ETA: 25s - loss: 6.6375 - accuracy: 0.659 - ETA: 25s - loss: 6.6383 - accuracy: 0.658 - ETA: 24s - loss: 6.6344 - accuracy: 0.659 - ETA: 24s - loss: 6.6331 - accuracy: 0.659 - ETA: 24s - loss: 6.6301 - accuracy: 0.659 - ETA: 24s - loss: 6.6282 - accuracy: 0.659 - ETA: 23s - loss: 6.6283 - accuracy: 0.658 - ETA: 23s - loss: 6.6245 - accuracy: 0.658 - ETA: 23s - loss: 6.6235 - accuracy: 0.658 - ETA: 23s - loss: 6.6210 - accuracy: 0.659 - ETA: 22s - loss: 6.6201 - accuracy: 0.659 - ETA: 22s - loss: 6.6191 - accuracy: 0.659 - ETA: 22s - loss: 6.6178 - accuracy: 0.658 - ETA: 21s - loss: 6.6153 - accuracy: 0.659 - ETA: 21s - loss: 6.6137 - accuracy: 0.659 - ETA: 21s - loss: 6.6142 - accuracy: 0.659 - ETA: 21s - loss: 6.6132 - accuracy: 0.659 - ETA: 20s - loss: 6.6109 - accuracy: 0.659 - ETA: 20s - loss: 6.6090 - accuracy: 0.659 - ETA: 20s - loss: 6.6084 - accuracy: 0.659 - ETA: 20s - loss: 6.6062 - accuracy: 0.659 - ETA: 19s - loss: 6.6031 - accuracy: 0.660 - ETA: 19s - loss: 6.6015 - accuracy: 0.660 - ETA: 19s - loss: 6.6004 - accuracy: 0.6604"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - ETA: 18s - loss: 6.5988 - accuracy: 0.660 - ETA: 18s - loss: 6.5968 - accuracy: 0.660 - ETA: 18s - loss: 6.5957 - accuracy: 0.660 - ETA: 18s - loss: 6.5933 - accuracy: 0.660 - ETA: 17s - loss: 6.5907 - accuracy: 0.660 - ETA: 17s - loss: 6.5903 - accuracy: 0.660 - ETA: 17s - loss: 6.5864 - accuracy: 0.660 - ETA: 17s - loss: 6.5846 - accuracy: 0.660 - ETA: 16s - loss: 6.5818 - accuracy: 0.660 - ETA: 16s - loss: 6.5793 - accuracy: 0.660 - ETA: 16s - loss: 6.5772 - accuracy: 0.660 - ETA: 15s - loss: 6.5754 - accuracy: 0.661 - ETA: 15s - loss: 6.5733 - accuracy: 0.661 - ETA: 15s - loss: 6.5731 - accuracy: 0.661 - ETA: 15s - loss: 6.5727 - accuracy: 0.661 - ETA: 14s - loss: 6.5703 - accuracy: 0.661 - ETA: 14s - loss: 6.5691 - accuracy: 0.661 - ETA: 14s - loss: 6.5684 - accuracy: 0.661 - ETA: 14s - loss: 6.5682 - accuracy: 0.661 - ETA: 13s - loss: 6.5654 - accuracy: 0.661 - ETA: 13s - loss: 6.5639 - accuracy: 0.661 - ETA: 13s - loss: 6.5653 - accuracy: 0.661 - ETA: 12s - loss: 6.5643 - accuracy: 0.662 - ETA: 12s - loss: 6.5629 - accuracy: 0.662 - ETA: 12s - loss: 6.5632 - accuracy: 0.661 - ETA: 12s - loss: 6.5612 - accuracy: 0.662 - ETA: 11s - loss: 6.5593 - accuracy: 0.662 - ETA: 11s - loss: 6.5588 - accuracy: 0.662 - ETA: 11s - loss: 6.5590 - accuracy: 0.662 - ETA: 11s - loss: 6.5560 - accuracy: 0.662 - ETA: 10s - loss: 6.5533 - accuracy: 0.662 - ETA: 10s - loss: 6.5528 - accuracy: 0.662 - ETA: 10s - loss: 6.5495 - accuracy: 0.662 - ETA: 9s - loss: 6.5478 - accuracy: 0.662 - ETA: 9s - loss: 6.5461 - accuracy: 0.66 - ETA: 9s - loss: 6.5462 - accuracy: 0.66 - ETA: 9s - loss: 6.5444 - accuracy: 0.66 - ETA: 8s - loss: 6.5439 - accuracy: 0.66 - ETA: 8s - loss: 6.5407 - accuracy: 0.66 - ETA: 8s - loss: 6.5412 - accuracy: 0.66 - ETA: 8s - loss: 6.5417 - accuracy: 0.66 - ETA: 7s - loss: 6.5421 - accuracy: 0.66 - ETA: 7s - loss: 6.5391 - accuracy: 0.66 - ETA: 7s - loss: 6.5371 - accuracy: 0.66 - ETA: 6s - loss: 6.5357 - accuracy: 0.66 - ETA: 6s - loss: 6.5339 - accuracy: 0.66 - ETA: 6s - loss: 6.5323 - accuracy: 0.66 - ETA: 6s - loss: 6.5289 - accuracy: 0.66 - ETA: 5s - loss: 6.5276 - accuracy: 0.66 - ETA: 5s - loss: 6.5268 - accuracy: 0.66 - ETA: 5s - loss: 6.5248 - accuracy: 0.66 - ETA: 4s - loss: 6.5229 - accuracy: 0.66 - ETA: 4s - loss: 6.5210 - accuracy: 0.66 - ETA: 4s - loss: 6.5203 - accuracy: 0.66 - ETA: 4s - loss: 6.5203 - accuracy: 0.66 - ETA: 3s - loss: 6.5195 - accuracy: 0.66 - ETA: 3s - loss: 6.5177 - accuracy: 0.66 - ETA: 3s - loss: 6.5148 - accuracy: 0.66 - ETA: 3s - loss: 6.5122 - accuracy: 0.66 - ETA: 2s - loss: 6.5097 - accuracy: 0.66 - ETA: 2s - loss: 6.5075 - accuracy: 0.66 - ETA: 2s - loss: 6.5069 - accuracy: 0.66 - ETA: 1s - loss: 6.5047 - accuracy: 0.66 - ETA: 1s - loss: 6.5033 - accuracy: 0.66 - ETA: 1s - loss: 6.5009 - accuracy: 0.66 - ETA: 1s - loss: 6.4998 - accuracy: 0.66 - ETA: 0s - loss: 6.4973 - accuracy: 0.66 - ETA: 0s - loss: 6.4965 - accuracy: 0.66 - ETA: 0s - loss: 6.4952 - accuracy: 0.66 - 173s 9ms/step - loss: 6.4950 - accuracy: 0.6646\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5952/20000 [=======>......................] - ETA: 2:57 - loss: 5.4973 - accuracy: 0.75 - ETA: 3:02 - loss: 5.2202 - accuracy: 0.73 - ETA: 2:56 - loss: 5.3971 - accuracy: 0.68 - ETA: 2:51 - loss: 5.4960 - accuracy: 0.68 - ETA: 2:48 - loss: 5.4438 - accuracy: 0.68 - ETA: 2:46 - loss: 5.5082 - accuracy: 0.66 - ETA: 2:44 - loss: 5.8025 - accuracy: 0.66 - ETA: 2:44 - loss: 5.7394 - accuracy: 0.67 - ETA: 2:43 - loss: 5.8338 - accuracy: 0.67 - ETA: 2:43 - loss: 5.7145 - accuracy: 0.67 - ETA: 2:41 - loss: 5.6172 - accuracy: 0.69 - ETA: 2:40 - loss: 5.5863 - accuracy: 0.69 - ETA: 2:40 - loss: 5.6348 - accuracy: 0.69 - ETA: 2:39 - loss: 5.6338 - accuracy: 0.69 - ETA: 2:38 - loss: 5.5901 - accuracy: 0.70 - ETA: 2:37 - loss: 5.5231 - accuracy: 0.69 - ETA: 2:37 - loss: 5.5276 - accuracy: 0.69 - ETA: 2:36 - loss: 5.5455 - accuracy: 0.69 - ETA: 2:36 - loss: 5.6404 - accuracy: 0.69 - ETA: 2:35 - loss: 5.6568 - accuracy: 0.70 - ETA: 2:35 - loss: 5.6634 - accuracy: 0.69 - ETA: 2:35 - loss: 5.6357 - accuracy: 0.69 - ETA: 2:34 - loss: 5.6415 - accuracy: 0.68 - ETA: 2:34 - loss: 5.6154 - accuracy: 0.68 - ETA: 2:34 - loss: 5.6193 - accuracy: 0.68 - ETA: 2:33 - loss: 5.6236 - accuracy: 0.68 - ETA: 2:33 - loss: 5.6558 - accuracy: 0.68 - ETA: 2:33 - loss: 5.6256 - accuracy: 0.69 - ETA: 2:33 - loss: 5.6630 - accuracy: 0.69 - ETA: 2:33 - loss: 5.6931 - accuracy: 0.69 - ETA: 2:33 - loss: 5.6838 - accuracy: 0.69 - ETA: 2:33 - loss: 5.7043 - accuracy: 0.69 - ETA: 2:33 - loss: 5.7515 - accuracy: 0.69 - ETA: 2:32 - loss: 5.7367 - accuracy: 0.69 - ETA: 2:32 - loss: 5.7246 - accuracy: 0.69 - ETA: 2:32 - loss: 5.7394 - accuracy: 0.69 - ETA: 2:31 - loss: 5.7172 - accuracy: 0.69 - ETA: 2:31 - loss: 5.7523 - accuracy: 0.69 - ETA: 2:30 - loss: 5.7402 - accuracy: 0.69 - ETA: 2:30 - loss: 5.7403 - accuracy: 0.69 - ETA: 2:30 - loss: 5.7215 - accuracy: 0.69 - ETA: 2:29 - loss: 5.7097 - accuracy: 0.69 - ETA: 2:29 - loss: 5.7166 - accuracy: 0.69 - ETA: 2:29 - loss: 5.6942 - accuracy: 0.69 - ETA: 2:28 - loss: 5.7036 - accuracy: 0.69 - ETA: 2:28 - loss: 5.7216 - accuracy: 0.69 - ETA: 2:27 - loss: 5.7007 - accuracy: 0.69 - ETA: 2:27 - loss: 5.7048 - accuracy: 0.68 - ETA: 2:27 - loss: 5.7182 - accuracy: 0.69 - ETA: 2:27 - loss: 5.6988 - accuracy: 0.69 - ETA: 2:26 - loss: 5.7123 - accuracy: 0.69 - ETA: 2:26 - loss: 5.7064 - accuracy: 0.69 - ETA: 2:26 - loss: 5.7055 - accuracy: 0.69 - ETA: 2:25 - loss: 5.7074 - accuracy: 0.69 - ETA: 2:25 - loss: 5.7179 - accuracy: 0.69 - ETA: 2:25 - loss: 5.7054 - accuracy: 0.69 - ETA: 2:24 - loss: 5.7165 - accuracy: 0.69 - ETA: 2:24 - loss: 5.7161 - accuracy: 0.69 - ETA: 2:24 - loss: 5.7195 - accuracy: 0.69 - ETA: 2:24 - loss: 5.7020 - accuracy: 0.69 - ETA: 2:23 - loss: 5.7018 - accuracy: 0.69 - ETA: 2:23 - loss: 5.6952 - accuracy: 0.69 - ETA: 2:23 - loss: 5.7004 - accuracy: 0.69 - ETA: 2:22 - loss: 5.7035 - accuracy: 0.69 - ETA: 2:22 - loss: 5.6946 - accuracy: 0.68 - ETA: 2:22 - loss: 5.6910 - accuracy: 0.68 - ETA: 2:22 - loss: 5.6819 - accuracy: 0.68 - ETA: 2:21 - loss: 5.6771 - accuracy: 0.68 - ETA: 2:21 - loss: 5.6820 - accuracy: 0.68 - ETA: 2:21 - loss: 5.6760 - accuracy: 0.68 - ETA: 2:21 - loss: 5.6814 - accuracy: 0.68 - ETA: 2:20 - loss: 5.6836 - accuracy: 0.68 - ETA: 2:20 - loss: 5.6674 - accuracy: 0.68 - ETA: 2:20 - loss: 5.6555 - accuracy: 0.68 - ETA: 2:19 - loss: 5.6411 - accuracy: 0.68 - ETA: 2:19 - loss: 5.6312 - accuracy: 0.68 - ETA: 2:19 - loss: 5.6292 - accuracy: 0.68 - ETA: 2:19 - loss: 5.6421 - accuracy: 0.68 - ETA: 2:18 - loss: 5.6335 - accuracy: 0.68 - ETA: 2:18 - loss: 5.6453 - accuracy: 0.68 - ETA: 2:18 - loss: 5.6341 - accuracy: 0.68 - ETA: 2:17 - loss: 5.6437 - accuracy: 0.68 - ETA: 2:17 - loss: 5.6355 - accuracy: 0.68 - ETA: 2:17 - loss: 5.6305 - accuracy: 0.68 - ETA: 2:16 - loss: 5.6201 - accuracy: 0.68 - ETA: 2:16 - loss: 5.6185 - accuracy: 0.68 - ETA: 2:16 - loss: 5.6180 - accuracy: 0.68 - ETA: 2:16 - loss: 5.6227 - accuracy: 0.68 - ETA: 2:16 - loss: 5.6216 - accuracy: 0.68 - ETA: 2:15 - loss: 5.6070 - accuracy: 0.68 - ETA: 2:15 - loss: 5.5975 - accuracy: 0.68 - ETA: 2:15 - loss: 5.5985 - accuracy: 0.68 - ETA: 2:14 - loss: 5.5988 - accuracy: 0.68 - ETA: 2:14 - loss: 5.5974 - accuracy: 0.68 - ETA: 2:14 - loss: 5.5959 - accuracy: 0.68 - ETA: 2:14 - loss: 5.5863 - accuracy: 0.68 - ETA: 2:13 - loss: 5.5741 - accuracy: 0.68 - ETA: 2:13 - loss: 5.5851 - accuracy: 0.68 - ETA: 2:13 - loss: 5.5906 - accuracy: 0.68 - ETA: 2:13 - loss: 5.5915 - accuracy: 0.68 - ETA: 2:12 - loss: 5.5923 - accuracy: 0.68 - ETA: 2:12 - loss: 5.5900 - accuracy: 0.69 - ETA: 2:12 - loss: 5.5855 - accuracy: 0.69 - ETA: 2:11 - loss: 5.5744 - accuracy: 0.69 - ETA: 2:11 - loss: 5.5692 - accuracy: 0.69 - ETA: 2:11 - loss: 5.5627 - accuracy: 0.69 - ETA: 2:11 - loss: 5.5562 - accuracy: 0.69 - ETA: 2:10 - loss: 5.5688 - accuracy: 0.69 - ETA: 2:10 - loss: 5.5613 - accuracy: 0.69 - ETA: 2:10 - loss: 5.5601 - accuracy: 0.69 - ETA: 2:10 - loss: 5.5626 - accuracy: 0.69 - ETA: 2:10 - loss: 5.5587 - accuracy: 0.69 - ETA: 2:09 - loss: 5.5532 - accuracy: 0.69 - ETA: 2:09 - loss: 5.5468 - accuracy: 0.69 - ETA: 2:09 - loss: 5.5445 - accuracy: 0.69 - ETA: 2:08 - loss: 5.5503 - accuracy: 0.69 - ETA: 2:08 - loss: 5.5423 - accuracy: 0.69 - ETA: 2:08 - loss: 5.5430 - accuracy: 0.69 - ETA: 2:08 - loss: 5.5442 - accuracy: 0.69 - ETA: 2:07 - loss: 5.5476 - accuracy: 0.69 - ETA: 2:07 - loss: 5.5450 - accuracy: 0.69 - ETA: 2:07 - loss: 5.5398 - accuracy: 0.69 - ETA: 2:07 - loss: 5.5372 - accuracy: 0.69 - ETA: 2:06 - loss: 5.5386 - accuracy: 0.69 - ETA: 2:06 - loss: 5.5439 - accuracy: 0.69 - ETA: 2:06 - loss: 5.5465 - accuracy: 0.69 - ETA: 2:05 - loss: 5.5460 - accuracy: 0.69 - ETA: 2:05 - loss: 5.5480 - accuracy: 0.69 - ETA: 2:05 - loss: 5.5432 - accuracy: 0.69 - ETA: 2:05 - loss: 5.5397 - accuracy: 0.69 - ETA: 2:05 - loss: 5.5350 - accuracy: 0.69 - ETA: 2:04 - loss: 5.5305 - accuracy: 0.69 - ETA: 2:04 - loss: 5.5273 - accuracy: 0.69 - ETA: 2:04 - loss: 5.5219 - accuracy: 0.69 - ETA: 2:03 - loss: 5.5194 - accuracy: 0.69 - ETA: 2:03 - loss: 5.5199 - accuracy: 0.69 - ETA: 2:03 - loss: 5.5137 - accuracy: 0.69 - ETA: 2:03 - loss: 5.5276 - accuracy: 0.68 - ETA: 2:02 - loss: 5.5290 - accuracy: 0.69 - ETA: 2:02 - loss: 5.5273 - accuracy: 0.69 - ETA: 2:02 - loss: 5.5220 - accuracy: 0.69 - ETA: 2:02 - loss: 5.5171 - accuracy: 0.69 - ETA: 2:01 - loss: 5.5147 - accuracy: 0.69 - ETA: 2:01 - loss: 5.5143 - accuracy: 0.69 - ETA: 2:01 - loss: 5.5146 - accuracy: 0.69 - ETA: 2:01 - loss: 5.5095 - accuracy: 0.68 - ETA: 2:00 - loss: 5.5064 - accuracy: 0.69 - ETA: 2:00 - loss: 5.5021 - accuracy: 0.69 - ETA: 2:00 - loss: 5.5031 - accuracy: 0.68 - ETA: 2:00 - loss: 5.4955 - accuracy: 0.69 - ETA: 1:59 - loss: 5.4996 - accuracy: 0.69 - ETA: 1:59 - loss: 5.5006 - accuracy: 0.69 - ETA: 1:59 - loss: 5.5016 - accuracy: 0.69 - ETA: 1:58 - loss: 5.4933 - accuracy: 0.69 - ETA: 1:58 - loss: 5.4937 - accuracy: 0.68 - ETA: 1:58 - loss: 5.4987 - accuracy: 0.69 - ETA: 1:58 - loss: 5.5011 - accuracy: 0.69 - ETA: 1:57 - loss: 5.4988 - accuracy: 0.69 - ETA: 1:57 - loss: 5.4976 - accuracy: 0.69 - ETA: 1:57 - loss: 5.4964 - accuracy: 0.69 - ETA: 1:57 - loss: 5.4919 - accuracy: 0.69 - ETA: 1:56 - loss: 5.4909 - accuracy: 0.69 - ETA: 1:56 - loss: 5.4901 - accuracy: 0.69 - ETA: 1:56 - loss: 5.4901 - accuracy: 0.69 - ETA: 1:56 - loss: 5.4950 - accuracy: 0.69 - ETA: 1:55 - loss: 5.4845 - accuracy: 0.69 - ETA: 1:55 - loss: 5.4790 - accuracy: 0.69 - ETA: 1:55 - loss: 5.4814 - accuracy: 0.69 - ETA: 1:55 - loss: 5.4843 - accuracy: 0.69 - ETA: 1:54 - loss: 5.4869 - accuracy: 0.69 - ETA: 1:54 - loss: 5.4833 - accuracy: 0.69 - ETA: 1:54 - loss: 5.4835 - accuracy: 0.69 - ETA: 1:54 - loss: 5.4795 - accuracy: 0.69 - ETA: 1:53 - loss: 5.4783 - accuracy: 0.69 - ETA: 1:53 - loss: 5.4764 - accuracy: 0.69 - ETA: 1:53 - loss: 5.4773 - accuracy: 0.69 - ETA: 1:53 - loss: 5.4761 - accuracy: 0.69 - ETA: 1:52 - loss: 5.4786 - accuracy: 0.69 - ETA: 1:52 - loss: 5.4776 - accuracy: 0.69 - ETA: 1:52 - loss: 5.4799 - accuracy: 0.69 - ETA: 1:51 - loss: 5.4762 - accuracy: 0.69 - ETA: 1:51 - loss: 5.4803 - accuracy: 0.69 - ETA: 1:51 - loss: 5.4827 - accuracy: 0.69 - ETA: 1:51 - loss: 5.4848 - accuracy: 0.69 - ETA: 1:50 - loss: 5.4833 - accuracy: 0.69 - ETA: 1:50 - loss: 5.4860 - accuracy: 0.6917"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/20000 [================>.............] - ETA: 1:50 - loss: 5.4824 - accuracy: 0.69 - ETA: 1:50 - loss: 5.4791 - accuracy: 0.69 - ETA: 1:49 - loss: 5.4814 - accuracy: 0.69 - ETA: 1:49 - loss: 5.4761 - accuracy: 0.69 - ETA: 1:49 - loss: 5.4744 - accuracy: 0.69 - ETA: 1:49 - loss: 5.4741 - accuracy: 0.69 - ETA: 1:48 - loss: 5.4752 - accuracy: 0.69 - ETA: 1:48 - loss: 5.4718 - accuracy: 0.69 - ETA: 1:48 - loss: 5.4664 - accuracy: 0.69 - ETA: 1:48 - loss: 5.4649 - accuracy: 0.69 - ETA: 1:47 - loss: 5.4656 - accuracy: 0.69 - ETA: 1:47 - loss: 5.4704 - accuracy: 0.69 - ETA: 1:47 - loss: 5.4721 - accuracy: 0.69 - ETA: 1:47 - loss: 5.4689 - accuracy: 0.69 - ETA: 1:46 - loss: 5.4714 - accuracy: 0.69 - ETA: 1:46 - loss: 5.4820 - accuracy: 0.69 - ETA: 1:46 - loss: 5.4833 - accuracy: 0.69 - ETA: 1:46 - loss: 5.4848 - accuracy: 0.69 - ETA: 1:45 - loss: 5.4809 - accuracy: 0.69 - ETA: 1:45 - loss: 5.4856 - accuracy: 0.69 - ETA: 1:45 - loss: 5.4845 - accuracy: 0.69 - ETA: 1:45 - loss: 5.4803 - accuracy: 0.69 - ETA: 1:44 - loss: 5.4761 - accuracy: 0.69 - ETA: 1:44 - loss: 5.4706 - accuracy: 0.69 - ETA: 1:44 - loss: 5.4726 - accuracy: 0.69 - ETA: 1:44 - loss: 5.4717 - accuracy: 0.69 - ETA: 1:43 - loss: 5.4650 - accuracy: 0.69 - ETA: 1:43 - loss: 5.4689 - accuracy: 0.69 - ETA: 1:43 - loss: 5.4683 - accuracy: 0.69 - ETA: 1:43 - loss: 5.4665 - accuracy: 0.69 - ETA: 1:42 - loss: 5.4748 - accuracy: 0.69 - ETA: 1:42 - loss: 5.4723 - accuracy: 0.69 - ETA: 1:42 - loss: 5.4716 - accuracy: 0.69 - ETA: 1:42 - loss: 5.4683 - accuracy: 0.69 - ETA: 1:41 - loss: 5.4634 - accuracy: 0.69 - ETA: 1:41 - loss: 5.4630 - accuracy: 0.69 - ETA: 1:41 - loss: 5.4605 - accuracy: 0.69 - ETA: 1:41 - loss: 5.4579 - accuracy: 0.69 - ETA: 1:40 - loss: 5.4542 - accuracy: 0.69 - ETA: 1:40 - loss: 5.4496 - accuracy: 0.69 - ETA: 1:40 - loss: 5.4431 - accuracy: 0.69 - ETA: 1:40 - loss: 5.4444 - accuracy: 0.69 - ETA: 1:39 - loss: 5.4446 - accuracy: 0.69 - ETA: 1:39 - loss: 5.4499 - accuracy: 0.69 - ETA: 1:39 - loss: 5.4524 - accuracy: 0.69 - ETA: 1:39 - loss: 5.4507 - accuracy: 0.69 - ETA: 1:38 - loss: 5.4472 - accuracy: 0.69 - ETA: 1:38 - loss: 5.4486 - accuracy: 0.69 - ETA: 1:38 - loss: 5.4483 - accuracy: 0.69 - ETA: 1:37 - loss: 5.4465 - accuracy: 0.69 - ETA: 1:37 - loss: 5.4441 - accuracy: 0.69 - ETA: 1:37 - loss: 5.4423 - accuracy: 0.69 - ETA: 1:37 - loss: 5.4393 - accuracy: 0.69 - ETA: 1:36 - loss: 5.4370 - accuracy: 0.69 - ETA: 1:36 - loss: 5.4312 - accuracy: 0.69 - ETA: 1:36 - loss: 5.4294 - accuracy: 0.69 - ETA: 1:36 - loss: 5.4307 - accuracy: 0.69 - ETA: 1:35 - loss: 5.4314 - accuracy: 0.69 - ETA: 1:35 - loss: 5.4332 - accuracy: 0.69 - ETA: 1:35 - loss: 5.4324 - accuracy: 0.69 - ETA: 1:35 - loss: 5.4322 - accuracy: 0.69 - ETA: 1:34 - loss: 5.4323 - accuracy: 0.69 - ETA: 1:34 - loss: 5.4311 - accuracy: 0.69 - ETA: 1:34 - loss: 5.4285 - accuracy: 0.69 - ETA: 1:34 - loss: 5.4289 - accuracy: 0.69 - ETA: 1:33 - loss: 5.4281 - accuracy: 0.69 - ETA: 1:33 - loss: 5.4254 - accuracy: 0.69 - ETA: 1:33 - loss: 5.4262 - accuracy: 0.69 - ETA: 1:33 - loss: 5.4220 - accuracy: 0.69 - ETA: 1:32 - loss: 5.4222 - accuracy: 0.69 - ETA: 1:32 - loss: 5.4218 - accuracy: 0.69 - ETA: 1:32 - loss: 5.4204 - accuracy: 0.69 - ETA: 1:32 - loss: 5.4171 - accuracy: 0.69 - ETA: 1:31 - loss: 5.4142 - accuracy: 0.69 - ETA: 1:31 - loss: 5.4126 - accuracy: 0.69 - ETA: 1:31 - loss: 5.4109 - accuracy: 0.69 - ETA: 1:31 - loss: 5.4138 - accuracy: 0.69 - ETA: 1:30 - loss: 5.4120 - accuracy: 0.69 - ETA: 1:30 - loss: 5.4092 - accuracy: 0.69 - ETA: 1:30 - loss: 5.4133 - accuracy: 0.69 - ETA: 1:30 - loss: 5.4093 - accuracy: 0.69 - ETA: 1:29 - loss: 5.4055 - accuracy: 0.69 - ETA: 1:29 - loss: 5.4051 - accuracy: 0.69 - ETA: 1:29 - loss: 5.4053 - accuracy: 0.69 - ETA: 1:29 - loss: 5.4049 - accuracy: 0.69 - ETA: 1:28 - loss: 5.4030 - accuracy: 0.69 - ETA: 1:28 - loss: 5.4055 - accuracy: 0.69 - ETA: 1:28 - loss: 5.4043 - accuracy: 0.69 - ETA: 1:28 - loss: 5.4037 - accuracy: 0.69 - ETA: 1:27 - loss: 5.4034 - accuracy: 0.69 - ETA: 1:27 - loss: 5.4039 - accuracy: 0.69 - ETA: 1:27 - loss: 5.4047 - accuracy: 0.69 - ETA: 1:27 - loss: 5.4037 - accuracy: 0.69 - ETA: 1:26 - loss: 5.4016 - accuracy: 0.69 - ETA: 1:26 - loss: 5.4020 - accuracy: 0.69 - ETA: 1:26 - loss: 5.4038 - accuracy: 0.69 - ETA: 1:26 - loss: 5.4035 - accuracy: 0.69 - ETA: 1:25 - loss: 5.4035 - accuracy: 0.69 - ETA: 1:25 - loss: 5.4025 - accuracy: 0.69 - ETA: 1:25 - loss: 5.4012 - accuracy: 0.69 - ETA: 1:25 - loss: 5.3997 - accuracy: 0.69 - ETA: 1:24 - loss: 5.3976 - accuracy: 0.69 - ETA: 1:24 - loss: 5.3935 - accuracy: 0.69 - ETA: 1:24 - loss: 5.3937 - accuracy: 0.69 - ETA: 1:24 - loss: 5.3912 - accuracy: 0.69 - ETA: 1:23 - loss: 5.3890 - accuracy: 0.69 - ETA: 1:23 - loss: 5.3875 - accuracy: 0.69 - ETA: 1:23 - loss: 5.3863 - accuracy: 0.69 - ETA: 1:23 - loss: 5.3857 - accuracy: 0.69 - ETA: 1:22 - loss: 5.3838 - accuracy: 0.69 - ETA: 1:22 - loss: 5.3812 - accuracy: 0.69 - ETA: 1:22 - loss: 5.3799 - accuracy: 0.69 - ETA: 1:22 - loss: 5.3764 - accuracy: 0.69 - ETA: 1:21 - loss: 5.3786 - accuracy: 0.69 - ETA: 1:21 - loss: 5.3737 - accuracy: 0.69 - ETA: 1:21 - loss: 5.3735 - accuracy: 0.69 - ETA: 1:21 - loss: 5.3722 - accuracy: 0.69 - ETA: 1:20 - loss: 5.3756 - accuracy: 0.69 - ETA: 1:20 - loss: 5.3742 - accuracy: 0.69 - ETA: 1:20 - loss: 5.3790 - accuracy: 0.69 - ETA: 1:19 - loss: 5.3826 - accuracy: 0.69 - ETA: 1:19 - loss: 5.3801 - accuracy: 0.69 - ETA: 1:19 - loss: 5.3811 - accuracy: 0.69 - ETA: 1:19 - loss: 5.3811 - accuracy: 0.69 - ETA: 1:18 - loss: 5.3815 - accuracy: 0.69 - ETA: 1:18 - loss: 5.3812 - accuracy: 0.69 - ETA: 1:18 - loss: 5.3774 - accuracy: 0.69 - ETA: 1:18 - loss: 5.3742 - accuracy: 0.69 - ETA: 1:18 - loss: 5.3714 - accuracy: 0.69 - ETA: 1:17 - loss: 5.3718 - accuracy: 0.69 - ETA: 1:17 - loss: 5.3705 - accuracy: 0.69 - ETA: 1:17 - loss: 5.3681 - accuracy: 0.69 - ETA: 1:17 - loss: 5.3660 - accuracy: 0.69 - ETA: 1:16 - loss: 5.3652 - accuracy: 0.69 - ETA: 1:16 - loss: 5.3650 - accuracy: 0.69 - ETA: 1:16 - loss: 5.3624 - accuracy: 0.69 - ETA: 1:16 - loss: 5.3648 - accuracy: 0.69 - ETA: 1:15 - loss: 5.3603 - accuracy: 0.69 - ETA: 1:15 - loss: 5.3619 - accuracy: 0.69 - ETA: 1:15 - loss: 5.3621 - accuracy: 0.69 - ETA: 1:15 - loss: 5.3632 - accuracy: 0.69 - ETA: 1:14 - loss: 5.3676 - accuracy: 0.69 - ETA: 1:14 - loss: 5.3701 - accuracy: 0.69 - ETA: 1:14 - loss: 5.3721 - accuracy: 0.69 - ETA: 1:14 - loss: 5.3738 - accuracy: 0.69 - ETA: 1:13 - loss: 5.3722 - accuracy: 0.69 - ETA: 1:13 - loss: 5.3739 - accuracy: 0.69 - ETA: 1:13 - loss: 5.3725 - accuracy: 0.69 - ETA: 1:13 - loss: 5.3740 - accuracy: 0.69 - ETA: 1:12 - loss: 5.3735 - accuracy: 0.69 - ETA: 1:12 - loss: 5.3732 - accuracy: 0.69 - ETA: 1:12 - loss: 5.3741 - accuracy: 0.69 - ETA: 1:11 - loss: 5.3729 - accuracy: 0.69 - ETA: 1:11 - loss: 5.3718 - accuracy: 0.69 - ETA: 1:11 - loss: 5.3726 - accuracy: 0.69 - ETA: 1:11 - loss: 5.3721 - accuracy: 0.69 - ETA: 1:10 - loss: 5.3727 - accuracy: 0.69 - ETA: 1:10 - loss: 5.3706 - accuracy: 0.69 - ETA: 1:10 - loss: 5.3699 - accuracy: 0.69 - ETA: 1:10 - loss: 5.3675 - accuracy: 0.69 - ETA: 1:09 - loss: 5.3644 - accuracy: 0.69 - ETA: 1:09 - loss: 5.3677 - accuracy: 0.69 - ETA: 1:09 - loss: 5.3685 - accuracy: 0.69 - ETA: 1:09 - loss: 5.3707 - accuracy: 0.69 - ETA: 1:08 - loss: 5.3719 - accuracy: 0.69 - ETA: 1:08 - loss: 5.3718 - accuracy: 0.69 - ETA: 1:08 - loss: 5.3711 - accuracy: 0.69 - ETA: 1:08 - loss: 5.3739 - accuracy: 0.69 - ETA: 1:07 - loss: 5.3757 - accuracy: 0.69 - ETA: 1:07 - loss: 5.3752 - accuracy: 0.69 - ETA: 1:07 - loss: 5.3778 - accuracy: 0.69 - ETA: 1:07 - loss: 5.3784 - accuracy: 0.69 - ETA: 1:06 - loss: 5.3826 - accuracy: 0.69 - ETA: 1:06 - loss: 5.3825 - accuracy: 0.69 - ETA: 1:06 - loss: 5.3830 - accuracy: 0.69 - ETA: 1:06 - loss: 5.3835 - accuracy: 0.69 - ETA: 1:05 - loss: 5.3869 - accuracy: 0.69 - ETA: 1:05 - loss: 5.3888 - accuracy: 0.69 - ETA: 1:05 - loss: 5.3906 - accuracy: 0.69 - ETA: 1:05 - loss: 5.3888 - accuracy: 0.69 - ETA: 1:04 - loss: 5.3873 - accuracy: 0.69 - ETA: 1:04 - loss: 5.3880 - accuracy: 0.69 - ETA: 1:04 - loss: 5.3875 - accuracy: 0.69 - ETA: 1:04 - loss: 5.3882 - accuracy: 0.69 - ETA: 1:03 - loss: 5.3903 - accuracy: 0.69 - ETA: 1:03 - loss: 5.3924 - accuracy: 0.6957"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17856/20000 [=========================>....] - ETA: 1:03 - loss: 5.3928 - accuracy: 0.69 - ETA: 1:03 - loss: 5.3903 - accuracy: 0.69 - ETA: 1:02 - loss: 5.3872 - accuracy: 0.69 - ETA: 1:02 - loss: 5.3838 - accuracy: 0.69 - ETA: 1:02 - loss: 5.3831 - accuracy: 0.69 - ETA: 1:02 - loss: 5.3836 - accuracy: 0.69 - ETA: 1:01 - loss: 5.3829 - accuracy: 0.69 - ETA: 1:01 - loss: 5.3815 - accuracy: 0.69 - ETA: 1:01 - loss: 5.3824 - accuracy: 0.69 - ETA: 1:01 - loss: 5.3807 - accuracy: 0.69 - ETA: 1:00 - loss: 5.3776 - accuracy: 0.69 - ETA: 1:00 - loss: 5.3747 - accuracy: 0.69 - ETA: 1:00 - loss: 5.3725 - accuracy: 0.69 - ETA: 1:00 - loss: 5.3704 - accuracy: 0.69 - ETA: 59s - loss: 5.3716 - accuracy: 0.6949 - ETA: 59s - loss: 5.3707 - accuracy: 0.694 - ETA: 59s - loss: 5.3703 - accuracy: 0.694 - ETA: 59s - loss: 5.3688 - accuracy: 0.694 - ETA: 58s - loss: 5.3698 - accuracy: 0.694 - ETA: 58s - loss: 5.3692 - accuracy: 0.694 - ETA: 58s - loss: 5.3686 - accuracy: 0.694 - ETA: 58s - loss: 5.3710 - accuracy: 0.694 - ETA: 58s - loss: 5.3701 - accuracy: 0.694 - ETA: 58s - loss: 5.3695 - accuracy: 0.694 - ETA: 57s - loss: 5.3724 - accuracy: 0.693 - ETA: 57s - loss: 5.3707 - accuracy: 0.693 - ETA: 57s - loss: 5.3719 - accuracy: 0.693 - ETA: 57s - loss: 5.3721 - accuracy: 0.693 - ETA: 56s - loss: 5.3729 - accuracy: 0.693 - ETA: 56s - loss: 5.3732 - accuracy: 0.693 - ETA: 56s - loss: 5.3744 - accuracy: 0.693 - ETA: 56s - loss: 5.3719 - accuracy: 0.693 - ETA: 55s - loss: 5.3722 - accuracy: 0.693 - ETA: 55s - loss: 5.3705 - accuracy: 0.694 - ETA: 55s - loss: 5.3701 - accuracy: 0.694 - ETA: 55s - loss: 5.3678 - accuracy: 0.694 - ETA: 54s - loss: 5.3664 - accuracy: 0.693 - ETA: 54s - loss: 5.3631 - accuracy: 0.694 - ETA: 54s - loss: 5.3629 - accuracy: 0.693 - ETA: 54s - loss: 5.3623 - accuracy: 0.693 - ETA: 53s - loss: 5.3615 - accuracy: 0.693 - ETA: 53s - loss: 5.3610 - accuracy: 0.693 - ETA: 53s - loss: 5.3576 - accuracy: 0.693 - ETA: 53s - loss: 5.3572 - accuracy: 0.693 - ETA: 52s - loss: 5.3550 - accuracy: 0.693 - ETA: 52s - loss: 5.3549 - accuracy: 0.694 - ETA: 52s - loss: 5.3555 - accuracy: 0.694 - ETA: 52s - loss: 5.3556 - accuracy: 0.693 - ETA: 51s - loss: 5.3558 - accuracy: 0.694 - ETA: 51s - loss: 5.3539 - accuracy: 0.694 - ETA: 51s - loss: 5.3514 - accuracy: 0.694 - ETA: 51s - loss: 5.3478 - accuracy: 0.694 - ETA: 50s - loss: 5.3468 - accuracy: 0.694 - ETA: 50s - loss: 5.3474 - accuracy: 0.694 - ETA: 50s - loss: 5.3473 - accuracy: 0.694 - ETA: 50s - loss: 5.3452 - accuracy: 0.694 - ETA: 50s - loss: 5.3449 - accuracy: 0.695 - ETA: 49s - loss: 5.3432 - accuracy: 0.694 - ETA: 49s - loss: 5.3431 - accuracy: 0.694 - ETA: 49s - loss: 5.3443 - accuracy: 0.694 - ETA: 49s - loss: 5.3438 - accuracy: 0.694 - ETA: 48s - loss: 5.3415 - accuracy: 0.694 - ETA: 48s - loss: 5.3389 - accuracy: 0.694 - ETA: 48s - loss: 5.3385 - accuracy: 0.694 - ETA: 48s - loss: 5.3377 - accuracy: 0.693 - ETA: 47s - loss: 5.3364 - accuracy: 0.693 - ETA: 47s - loss: 5.3350 - accuracy: 0.693 - ETA: 47s - loss: 5.3338 - accuracy: 0.693 - ETA: 47s - loss: 5.3337 - accuracy: 0.693 - ETA: 46s - loss: 5.3323 - accuracy: 0.693 - ETA: 46s - loss: 5.3323 - accuracy: 0.693 - ETA: 46s - loss: 5.3331 - accuracy: 0.693 - ETA: 46s - loss: 5.3313 - accuracy: 0.693 - ETA: 45s - loss: 5.3321 - accuracy: 0.693 - ETA: 45s - loss: 5.3311 - accuracy: 0.693 - ETA: 45s - loss: 5.3328 - accuracy: 0.693 - ETA: 45s - loss: 5.3306 - accuracy: 0.693 - ETA: 44s - loss: 5.3286 - accuracy: 0.693 - ETA: 44s - loss: 5.3279 - accuracy: 0.693 - ETA: 44s - loss: 5.3275 - accuracy: 0.693 - ETA: 44s - loss: 5.3273 - accuracy: 0.693 - ETA: 43s - loss: 5.3276 - accuracy: 0.693 - ETA: 43s - loss: 5.3256 - accuracy: 0.693 - ETA: 43s - loss: 5.3259 - accuracy: 0.693 - ETA: 43s - loss: 5.3291 - accuracy: 0.693 - ETA: 42s - loss: 5.3261 - accuracy: 0.693 - ETA: 42s - loss: 5.3247 - accuracy: 0.693 - ETA: 42s - loss: 5.3231 - accuracy: 0.693 - ETA: 42s - loss: 5.3236 - accuracy: 0.693 - ETA: 41s - loss: 5.3245 - accuracy: 0.692 - ETA: 41s - loss: 5.3233 - accuracy: 0.692 - ETA: 41s - loss: 5.3235 - accuracy: 0.692 - ETA: 41s - loss: 5.3219 - accuracy: 0.692 - ETA: 40s - loss: 5.3205 - accuracy: 0.692 - ETA: 40s - loss: 5.3199 - accuracy: 0.692 - ETA: 40s - loss: 5.3193 - accuracy: 0.692 - ETA: 40s - loss: 5.3207 - accuracy: 0.692 - ETA: 39s - loss: 5.3213 - accuracy: 0.692 - ETA: 39s - loss: 5.3207 - accuracy: 0.692 - ETA: 39s - loss: 5.3193 - accuracy: 0.692 - ETA: 39s - loss: 5.3198 - accuracy: 0.692 - ETA: 38s - loss: 5.3215 - accuracy: 0.692 - ETA: 38s - loss: 5.3224 - accuracy: 0.693 - ETA: 38s - loss: 5.3226 - accuracy: 0.693 - ETA: 38s - loss: 5.3253 - accuracy: 0.692 - ETA: 37s - loss: 5.3247 - accuracy: 0.693 - ETA: 37s - loss: 5.3231 - accuracy: 0.693 - ETA: 37s - loss: 5.3206 - accuracy: 0.693 - ETA: 37s - loss: 5.3189 - accuracy: 0.693 - ETA: 36s - loss: 5.3175 - accuracy: 0.693 - ETA: 36s - loss: 5.3181 - accuracy: 0.693 - ETA: 36s - loss: 5.3157 - accuracy: 0.693 - ETA: 36s - loss: 5.3130 - accuracy: 0.693 - ETA: 35s - loss: 5.3140 - accuracy: 0.693 - ETA: 35s - loss: 5.3166 - accuracy: 0.693 - ETA: 35s - loss: 5.3169 - accuracy: 0.693 - ETA: 35s - loss: 5.3170 - accuracy: 0.693 - ETA: 34s - loss: 5.3172 - accuracy: 0.693 - ETA: 34s - loss: 5.3183 - accuracy: 0.692 - ETA: 34s - loss: 5.3193 - accuracy: 0.692 - ETA: 34s - loss: 5.3159 - accuracy: 0.693 - ETA: 33s - loss: 5.3133 - accuracy: 0.693 - ETA: 33s - loss: 5.3128 - accuracy: 0.693 - ETA: 33s - loss: 5.3119 - accuracy: 0.693 - ETA: 33s - loss: 5.3105 - accuracy: 0.693 - ETA: 32s - loss: 5.3099 - accuracy: 0.693 - ETA: 32s - loss: 5.3089 - accuracy: 0.693 - ETA: 32s - loss: 5.3108 - accuracy: 0.693 - ETA: 32s - loss: 5.3095 - accuracy: 0.693 - ETA: 31s - loss: 5.3110 - accuracy: 0.693 - ETA: 31s - loss: 5.3131 - accuracy: 0.693 - ETA: 31s - loss: 5.3115 - accuracy: 0.693 - ETA: 31s - loss: 5.3098 - accuracy: 0.693 - ETA: 30s - loss: 5.3086 - accuracy: 0.693 - ETA: 30s - loss: 5.3072 - accuracy: 0.693 - ETA: 30s - loss: 5.3058 - accuracy: 0.693 - ETA: 30s - loss: 5.3055 - accuracy: 0.693 - ETA: 29s - loss: 5.3042 - accuracy: 0.693 - ETA: 29s - loss: 5.3052 - accuracy: 0.693 - ETA: 29s - loss: 5.3070 - accuracy: 0.694 - ETA: 28s - loss: 5.3086 - accuracy: 0.694 - ETA: 28s - loss: 5.3074 - accuracy: 0.694 - ETA: 28s - loss: 5.3056 - accuracy: 0.693 - ETA: 28s - loss: 5.3052 - accuracy: 0.693 - ETA: 27s - loss: 5.3055 - accuracy: 0.694 - ETA: 27s - loss: 5.3058 - accuracy: 0.694 - ETA: 27s - loss: 5.3082 - accuracy: 0.694 - ETA: 27s - loss: 5.3097 - accuracy: 0.694 - ETA: 26s - loss: 5.3090 - accuracy: 0.694 - ETA: 26s - loss: 5.3084 - accuracy: 0.694 - ETA: 26s - loss: 5.3089 - accuracy: 0.694 - ETA: 26s - loss: 5.3097 - accuracy: 0.694 - ETA: 25s - loss: 5.3112 - accuracy: 0.694 - ETA: 25s - loss: 5.3116 - accuracy: 0.694 - ETA: 25s - loss: 5.3108 - accuracy: 0.694 - ETA: 25s - loss: 5.3092 - accuracy: 0.695 - ETA: 24s - loss: 5.3078 - accuracy: 0.694 - ETA: 24s - loss: 5.3079 - accuracy: 0.694 - ETA: 24s - loss: 5.3076 - accuracy: 0.694 - ETA: 24s - loss: 5.3089 - accuracy: 0.694 - ETA: 23s - loss: 5.3099 - accuracy: 0.694 - ETA: 23s - loss: 5.3091 - accuracy: 0.694 - ETA: 23s - loss: 5.3104 - accuracy: 0.694 - ETA: 23s - loss: 5.3099 - accuracy: 0.694 - ETA: 22s - loss: 5.3089 - accuracy: 0.695 - ETA: 22s - loss: 5.3099 - accuracy: 0.694 - ETA: 22s - loss: 5.3095 - accuracy: 0.694 - ETA: 22s - loss: 5.3089 - accuracy: 0.694 - ETA: 21s - loss: 5.3078 - accuracy: 0.694 - ETA: 21s - loss: 5.3064 - accuracy: 0.695 - ETA: 21s - loss: 5.3064 - accuracy: 0.695 - ETA: 21s - loss: 5.3082 - accuracy: 0.695 - ETA: 20s - loss: 5.3080 - accuracy: 0.695 - ETA: 20s - loss: 5.3072 - accuracy: 0.694 - ETA: 20s - loss: 5.3073 - accuracy: 0.694 - ETA: 20s - loss: 5.3068 - accuracy: 0.694 - ETA: 19s - loss: 5.3056 - accuracy: 0.694 - ETA: 19s - loss: 5.3054 - accuracy: 0.694 - ETA: 19s - loss: 5.3053 - accuracy: 0.694 - ETA: 19s - loss: 5.3043 - accuracy: 0.694 - ETA: 18s - loss: 5.3033 - accuracy: 0.694 - ETA: 18s - loss: 5.3038 - accuracy: 0.694 - ETA: 18s - loss: 5.3009 - accuracy: 0.694 - ETA: 18s - loss: 5.3000 - accuracy: 0.694 - ETA: 17s - loss: 5.2968 - accuracy: 0.694 - ETA: 17s - loss: 5.2972 - accuracy: 0.6943"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - ETA: 17s - loss: 5.2956 - accuracy: 0.694 - ETA: 17s - loss: 5.2940 - accuracy: 0.694 - ETA: 16s - loss: 5.2940 - accuracy: 0.694 - ETA: 16s - loss: 5.2944 - accuracy: 0.694 - ETA: 16s - loss: 5.2929 - accuracy: 0.694 - ETA: 16s - loss: 5.2939 - accuracy: 0.694 - ETA: 15s - loss: 5.2940 - accuracy: 0.694 - ETA: 15s - loss: 5.2921 - accuracy: 0.694 - ETA: 15s - loss: 5.2910 - accuracy: 0.694 - ETA: 15s - loss: 5.2904 - accuracy: 0.694 - ETA: 14s - loss: 5.2876 - accuracy: 0.694 - ETA: 14s - loss: 5.2872 - accuracy: 0.694 - ETA: 14s - loss: 5.2888 - accuracy: 0.694 - ETA: 13s - loss: 5.2885 - accuracy: 0.694 - ETA: 13s - loss: 5.2870 - accuracy: 0.694 - ETA: 13s - loss: 5.2870 - accuracy: 0.694 - ETA: 13s - loss: 5.2852 - accuracy: 0.694 - ETA: 12s - loss: 5.2858 - accuracy: 0.694 - ETA: 12s - loss: 5.2877 - accuracy: 0.694 - ETA: 12s - loss: 5.2873 - accuracy: 0.694 - ETA: 12s - loss: 5.2889 - accuracy: 0.694 - ETA: 11s - loss: 5.2876 - accuracy: 0.694 - ETA: 11s - loss: 5.2869 - accuracy: 0.694 - ETA: 11s - loss: 5.2871 - accuracy: 0.694 - ETA: 11s - loss: 5.2867 - accuracy: 0.694 - ETA: 10s - loss: 5.2845 - accuracy: 0.694 - ETA: 10s - loss: 5.2854 - accuracy: 0.694 - ETA: 10s - loss: 5.2871 - accuracy: 0.693 - ETA: 10s - loss: 5.2882 - accuracy: 0.693 - ETA: 9s - loss: 5.2877 - accuracy: 0.693 - ETA: 9s - loss: 5.2871 - accuracy: 0.69 - ETA: 9s - loss: 5.2855 - accuracy: 0.69 - ETA: 9s - loss: 5.2847 - accuracy: 0.69 - ETA: 8s - loss: 5.2859 - accuracy: 0.69 - ETA: 8s - loss: 5.2869 - accuracy: 0.69 - ETA: 8s - loss: 5.2853 - accuracy: 0.69 - ETA: 7s - loss: 5.2869 - accuracy: 0.69 - ETA: 7s - loss: 5.2878 - accuracy: 0.69 - ETA: 7s - loss: 5.2874 - accuracy: 0.69 - ETA: 7s - loss: 5.2864 - accuracy: 0.69 - ETA: 6s - loss: 5.2852 - accuracy: 0.69 - ETA: 6s - loss: 5.2849 - accuracy: 0.69 - ETA: 6s - loss: 5.2854 - accuracy: 0.69 - ETA: 6s - loss: 5.2876 - accuracy: 0.69 - ETA: 5s - loss: 5.2870 - accuracy: 0.69 - ETA: 5s - loss: 5.2858 - accuracy: 0.69 - ETA: 5s - loss: 5.2847 - accuracy: 0.69 - ETA: 5s - loss: 5.2829 - accuracy: 0.69 - ETA: 4s - loss: 5.2811 - accuracy: 0.69 - ETA: 4s - loss: 5.2809 - accuracy: 0.69 - ETA: 4s - loss: 5.2796 - accuracy: 0.69 - ETA: 4s - loss: 5.2801 - accuracy: 0.69 - ETA: 3s - loss: 5.2790 - accuracy: 0.69 - ETA: 3s - loss: 5.2800 - accuracy: 0.69 - ETA: 3s - loss: 5.2814 - accuracy: 0.69 - ETA: 2s - loss: 5.2814 - accuracy: 0.69 - ETA: 2s - loss: 5.2805 - accuracy: 0.69 - ETA: 2s - loss: 5.2801 - accuracy: 0.69 - ETA: 2s - loss: 5.2788 - accuracy: 0.69 - ETA: 1s - loss: 5.2787 - accuracy: 0.69 - ETA: 1s - loss: 5.2772 - accuracy: 0.69 - ETA: 1s - loss: 5.2774 - accuracy: 0.69 - ETA: 1s - loss: 5.2775 - accuracy: 0.69 - ETA: 0s - loss: 5.2794 - accuracy: 0.69 - ETA: 0s - loss: 5.2781 - accuracy: 0.69 - ETA: 0s - loss: 5.2776 - accuracy: 0.69 - 168s 8ms/step - loss: 5.2778 - accuracy: 0.6935\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5952/20000 [=======>......................] - ETA: 2:53 - loss: 5.8760 - accuracy: 0.62 - ETA: 2:50 - loss: 5.3153 - accuracy: 0.68 - ETA: 2:49 - loss: 5.2909 - accuracy: 0.66 - ETA: 2:48 - loss: 5.1482 - accuracy: 0.68 - ETA: 2:48 - loss: 5.3458 - accuracy: 0.69 - ETA: 2:47 - loss: 5.3831 - accuracy: 0.68 - ETA: 2:47 - loss: 5.3636 - accuracy: 0.68 - ETA: 2:46 - loss: 5.1871 - accuracy: 0.69 - ETA: 2:47 - loss: 5.1213 - accuracy: 0.71 - ETA: 2:46 - loss: 5.1724 - accuracy: 0.70 - ETA: 2:46 - loss: 5.2630 - accuracy: 0.70 - ETA: 2:46 - loss: 5.2649 - accuracy: 0.69 - ETA: 2:45 - loss: 5.1802 - accuracy: 0.70 - ETA: 2:45 - loss: 5.1712 - accuracy: 0.71 - ETA: 2:45 - loss: 5.1981 - accuracy: 0.70 - ETA: 2:44 - loss: 5.2022 - accuracy: 0.70 - ETA: 2:44 - loss: 5.2522 - accuracy: 0.70 - ETA: 2:44 - loss: 5.2250 - accuracy: 0.70 - ETA: 2:45 - loss: 5.2495 - accuracy: 0.70 - ETA: 2:46 - loss: 5.2453 - accuracy: 0.70 - ETA: 2:45 - loss: 5.1968 - accuracy: 0.70 - ETA: 2:45 - loss: 5.1785 - accuracy: 0.69 - ETA: 2:44 - loss: 5.1774 - accuracy: 0.69 - ETA: 2:44 - loss: 5.1713 - accuracy: 0.69 - ETA: 2:44 - loss: 5.1720 - accuracy: 0.69 - ETA: 2:44 - loss: 5.2297 - accuracy: 0.68 - ETA: 2:43 - loss: 5.2517 - accuracy: 0.68 - ETA: 2:43 - loss: 5.2380 - accuracy: 0.68 - ETA: 2:42 - loss: 5.2450 - accuracy: 0.68 - ETA: 2:42 - loss: 5.2108 - accuracy: 0.68 - ETA: 2:42 - loss: 5.1991 - accuracy: 0.69 - ETA: 2:41 - loss: 5.2295 - accuracy: 0.69 - ETA: 2:41 - loss: 5.2025 - accuracy: 0.68 - ETA: 2:41 - loss: 5.2205 - accuracy: 0.69 - ETA: 2:40 - loss: 5.2001 - accuracy: 0.69 - ETA: 2:40 - loss: 5.1976 - accuracy: 0.69 - ETA: 2:40 - loss: 5.1813 - accuracy: 0.70 - ETA: 2:39 - loss: 5.1976 - accuracy: 0.70 - ETA: 2:39 - loss: 5.1756 - accuracy: 0.70 - ETA: 2:39 - loss: 5.2120 - accuracy: 0.70 - ETA: 2:38 - loss: 5.2487 - accuracy: 0.69 - ETA: 2:38 - loss: 5.2455 - accuracy: 0.69 - ETA: 2:38 - loss: 5.2554 - accuracy: 0.69 - ETA: 2:37 - loss: 5.2383 - accuracy: 0.69 - ETA: 2:37 - loss: 5.2401 - accuracy: 0.69 - ETA: 2:37 - loss: 5.2241 - accuracy: 0.69 - ETA: 2:37 - loss: 5.2232 - accuracy: 0.69 - ETA: 2:36 - loss: 5.2327 - accuracy: 0.69 - ETA: 2:36 - loss: 5.2415 - accuracy: 0.69 - ETA: 2:36 - loss: 5.2294 - accuracy: 0.69 - ETA: 2:35 - loss: 5.2185 - accuracy: 0.69 - ETA: 2:35 - loss: 5.2268 - accuracy: 0.69 - ETA: 2:35 - loss: 5.2050 - accuracy: 0.69 - ETA: 2:35 - loss: 5.1944 - accuracy: 0.69 - ETA: 2:34 - loss: 5.1904 - accuracy: 0.69 - ETA: 2:34 - loss: 5.2070 - accuracy: 0.69 - ETA: 2:34 - loss: 5.2029 - accuracy: 0.69 - ETA: 2:34 - loss: 5.2085 - accuracy: 0.69 - ETA: 2:33 - loss: 5.1828 - accuracy: 0.69 - ETA: 2:33 - loss: 5.1839 - accuracy: 0.69 - ETA: 2:33 - loss: 5.1892 - accuracy: 0.69 - ETA: 2:33 - loss: 5.1751 - accuracy: 0.69 - ETA: 2:33 - loss: 5.1769 - accuracy: 0.69 - ETA: 2:32 - loss: 5.1599 - accuracy: 0.69 - ETA: 2:32 - loss: 5.1484 - accuracy: 0.68 - ETA: 2:32 - loss: 5.1386 - accuracy: 0.69 - ETA: 2:32 - loss: 5.1464 - accuracy: 0.69 - ETA: 2:31 - loss: 5.1508 - accuracy: 0.69 - ETA: 2:31 - loss: 5.1394 - accuracy: 0.69 - ETA: 2:31 - loss: 5.1297 - accuracy: 0.69 - ETA: 2:31 - loss: 5.1178 - accuracy: 0.69 - ETA: 2:30 - loss: 5.1104 - accuracy: 0.69 - ETA: 2:30 - loss: 5.1140 - accuracy: 0.69 - ETA: 2:30 - loss: 5.0999 - accuracy: 0.69 - ETA: 2:30 - loss: 5.1064 - accuracy: 0.70 - ETA: 2:29 - loss: 5.0970 - accuracy: 0.70 - ETA: 2:29 - loss: 5.0831 - accuracy: 0.69 - ETA: 2:29 - loss: 5.0935 - accuracy: 0.69 - ETA: 2:29 - loss: 5.0882 - accuracy: 0.69 - ETA: 2:28 - loss: 5.0865 - accuracy: 0.69 - ETA: 2:28 - loss: 5.0795 - accuracy: 0.70 - ETA: 2:28 - loss: 5.0671 - accuracy: 0.70 - ETA: 2:27 - loss: 5.0807 - accuracy: 0.69 - ETA: 2:27 - loss: 5.0722 - accuracy: 0.69 - ETA: 2:27 - loss: 5.0624 - accuracy: 0.69 - ETA: 2:27 - loss: 5.0556 - accuracy: 0.69 - ETA: 2:26 - loss: 5.0496 - accuracy: 0.70 - ETA: 2:26 - loss: 5.0541 - accuracy: 0.70 - ETA: 2:26 - loss: 5.0528 - accuracy: 0.70 - ETA: 2:26 - loss: 5.0481 - accuracy: 0.70 - ETA: 2:25 - loss: 5.0454 - accuracy: 0.70 - ETA: 2:25 - loss: 5.0412 - accuracy: 0.69 - ETA: 2:25 - loss: 5.0381 - accuracy: 0.69 - ETA: 2:25 - loss: 5.0376 - accuracy: 0.69 - ETA: 2:25 - loss: 5.0426 - accuracy: 0.69 - ETA: 2:24 - loss: 5.0396 - accuracy: 0.69 - ETA: 2:24 - loss: 5.0371 - accuracy: 0.69 - ETA: 2:24 - loss: 5.0303 - accuracy: 0.69 - ETA: 2:24 - loss: 5.0306 - accuracy: 0.69 - ETA: 2:24 - loss: 5.0232 - accuracy: 0.69 - ETA: 2:23 - loss: 5.0177 - accuracy: 0.69 - ETA: 2:23 - loss: 5.0121 - accuracy: 0.69 - ETA: 2:23 - loss: 5.0156 - accuracy: 0.69 - ETA: 2:22 - loss: 5.0207 - accuracy: 0.69 - ETA: 2:22 - loss: 5.0225 - accuracy: 0.69 - ETA: 2:22 - loss: 5.0211 - accuracy: 0.69 - ETA: 2:22 - loss: 5.0309 - accuracy: 0.69 - ETA: 2:21 - loss: 5.0281 - accuracy: 0.69 - ETA: 2:21 - loss: 5.0288 - accuracy: 0.69 - ETA: 2:21 - loss: 5.0327 - accuracy: 0.69 - ETA: 2:21 - loss: 5.0310 - accuracy: 0.69 - ETA: 2:20 - loss: 5.0284 - accuracy: 0.69 - ETA: 2:20 - loss: 5.0302 - accuracy: 0.69 - ETA: 2:20 - loss: 5.0286 - accuracy: 0.69 - ETA: 2:19 - loss: 5.0274 - accuracy: 0.69 - ETA: 2:19 - loss: 5.0272 - accuracy: 0.69 - ETA: 2:19 - loss: 5.0234 - accuracy: 0.69 - ETA: 2:19 - loss: 5.0214 - accuracy: 0.69 - ETA: 2:18 - loss: 5.0206 - accuracy: 0.69 - ETA: 2:18 - loss: 5.0276 - accuracy: 0.69 - ETA: 2:18 - loss: 5.0287 - accuracy: 0.69 - ETA: 2:18 - loss: 5.0239 - accuracy: 0.69 - ETA: 2:17 - loss: 5.0256 - accuracy: 0.69 - ETA: 2:17 - loss: 5.0279 - accuracy: 0.69 - ETA: 2:17 - loss: 5.0298 - accuracy: 0.69 - ETA: 2:17 - loss: 5.0321 - accuracy: 0.69 - ETA: 2:16 - loss: 5.0289 - accuracy: 0.69 - ETA: 2:16 - loss: 5.0365 - accuracy: 0.69 - ETA: 2:16 - loss: 5.0358 - accuracy: 0.69 - ETA: 2:15 - loss: 5.0374 - accuracy: 0.69 - ETA: 2:15 - loss: 5.0409 - accuracy: 0.69 - ETA: 2:15 - loss: 5.0414 - accuracy: 0.69 - ETA: 2:15 - loss: 5.0400 - accuracy: 0.69 - ETA: 2:14 - loss: 5.0407 - accuracy: 0.69 - ETA: 2:14 - loss: 5.0439 - accuracy: 0.69 - ETA: 2:14 - loss: 5.0472 - accuracy: 0.69 - ETA: 2:14 - loss: 5.0448 - accuracy: 0.69 - ETA: 2:13 - loss: 5.0437 - accuracy: 0.69 - ETA: 2:13 - loss: 5.0415 - accuracy: 0.69 - ETA: 2:13 - loss: 5.0416 - accuracy: 0.69 - ETA: 2:13 - loss: 5.0391 - accuracy: 0.69 - ETA: 2:12 - loss: 5.0385 - accuracy: 0.69 - ETA: 2:12 - loss: 5.0438 - accuracy: 0.69 - ETA: 2:12 - loss: 5.0559 - accuracy: 0.69 - ETA: 2:12 - loss: 5.0559 - accuracy: 0.69 - ETA: 2:11 - loss: 5.0489 - accuracy: 0.69 - ETA: 2:11 - loss: 5.0505 - accuracy: 0.69 - ETA: 2:11 - loss: 5.0503 - accuracy: 0.69 - ETA: 2:10 - loss: 5.0474 - accuracy: 0.69 - ETA: 2:10 - loss: 5.0473 - accuracy: 0.69 - ETA: 2:10 - loss: 5.0432 - accuracy: 0.69 - ETA: 2:10 - loss: 5.0413 - accuracy: 0.69 - ETA: 2:09 - loss: 5.0387 - accuracy: 0.69 - ETA: 2:09 - loss: 5.0429 - accuracy: 0.69 - ETA: 2:09 - loss: 5.0434 - accuracy: 0.69 - ETA: 2:09 - loss: 5.0495 - accuracy: 0.69 - ETA: 2:08 - loss: 5.0514 - accuracy: 0.69 - ETA: 2:08 - loss: 5.0519 - accuracy: 0.69 - ETA: 2:08 - loss: 5.0567 - accuracy: 0.69 - ETA: 2:07 - loss: 5.0514 - accuracy: 0.69 - ETA: 2:07 - loss: 5.0524 - accuracy: 0.69 - ETA: 2:07 - loss: 5.0495 - accuracy: 0.69 - ETA: 2:07 - loss: 5.0542 - accuracy: 0.69 - ETA: 2:06 - loss: 5.0547 - accuracy: 0.69 - ETA: 2:06 - loss: 5.0471 - accuracy: 0.69 - ETA: 2:06 - loss: 5.0484 - accuracy: 0.69 - ETA: 2:06 - loss: 5.0484 - accuracy: 0.69 - ETA: 2:05 - loss: 5.0440 - accuracy: 0.69 - ETA: 2:05 - loss: 5.0493 - accuracy: 0.69 - ETA: 2:05 - loss: 5.0442 - accuracy: 0.69 - ETA: 2:04 - loss: 5.0426 - accuracy: 0.69 - ETA: 2:04 - loss: 5.0437 - accuracy: 0.69 - ETA: 2:04 - loss: 5.0406 - accuracy: 0.69 - ETA: 2:04 - loss: 5.0398 - accuracy: 0.69 - ETA: 2:03 - loss: 5.0401 - accuracy: 0.69 - ETA: 2:03 - loss: 5.0323 - accuracy: 0.69 - ETA: 2:03 - loss: 5.0386 - accuracy: 0.69 - ETA: 2:03 - loss: 5.0340 - accuracy: 0.69 - ETA: 2:03 - loss: 5.0321 - accuracy: 0.69 - ETA: 2:03 - loss: 5.0312 - accuracy: 0.69 - ETA: 2:03 - loss: 5.0323 - accuracy: 0.68 - ETA: 2:02 - loss: 5.0311 - accuracy: 0.68 - ETA: 2:02 - loss: 5.0314 - accuracy: 0.68 - ETA: 2:02 - loss: 5.0262 - accuracy: 0.68 - ETA: 2:02 - loss: 5.0278 - accuracy: 0.68 - ETA: 2:01 - loss: 5.0266 - accuracy: 0.6880"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/20000 [================>.............] - ETA: 2:01 - loss: 5.0227 - accuracy: 0.68 - ETA: 2:01 - loss: 5.0230 - accuracy: 0.68 - ETA: 2:00 - loss: 5.0230 - accuracy: 0.68 - ETA: 2:00 - loss: 5.0206 - accuracy: 0.68 - ETA: 2:00 - loss: 5.0206 - accuracy: 0.68 - ETA: 2:00 - loss: 5.0182 - accuracy: 0.68 - ETA: 1:59 - loss: 5.0204 - accuracy: 0.68 - ETA: 1:59 - loss: 5.0222 - accuracy: 0.68 - ETA: 1:59 - loss: 5.0275 - accuracy: 0.68 - ETA: 1:58 - loss: 5.0335 - accuracy: 0.68 - ETA: 1:58 - loss: 5.0324 - accuracy: 0.68 - ETA: 1:58 - loss: 5.0274 - accuracy: 0.68 - ETA: 1:58 - loss: 5.0266 - accuracy: 0.68 - ETA: 1:57 - loss: 5.0272 - accuracy: 0.68 - ETA: 1:57 - loss: 5.0299 - accuracy: 0.68 - ETA: 1:57 - loss: 5.0280 - accuracy: 0.69 - ETA: 1:56 - loss: 5.0264 - accuracy: 0.69 - ETA: 1:56 - loss: 5.0210 - accuracy: 0.68 - ETA: 1:56 - loss: 5.0172 - accuracy: 0.69 - ETA: 1:56 - loss: 5.0168 - accuracy: 0.69 - ETA: 1:55 - loss: 5.0157 - accuracy: 0.69 - ETA: 1:55 - loss: 5.0147 - accuracy: 0.68 - ETA: 1:55 - loss: 5.0109 - accuracy: 0.68 - ETA: 1:55 - loss: 5.0112 - accuracy: 0.68 - ETA: 1:55 - loss: 5.0052 - accuracy: 0.68 - ETA: 1:54 - loss: 5.0054 - accuracy: 0.68 - ETA: 1:54 - loss: 5.0069 - accuracy: 0.68 - ETA: 1:54 - loss: 5.0189 - accuracy: 0.68 - ETA: 1:53 - loss: 5.0204 - accuracy: 0.69 - ETA: 1:53 - loss: 5.0242 - accuracy: 0.69 - ETA: 1:53 - loss: 5.0254 - accuracy: 0.68 - ETA: 1:53 - loss: 5.0258 - accuracy: 0.68 - ETA: 1:52 - loss: 5.0300 - accuracy: 0.68 - ETA: 1:52 - loss: 5.0343 - accuracy: 0.68 - ETA: 1:52 - loss: 5.0357 - accuracy: 0.68 - ETA: 1:51 - loss: 5.0390 - accuracy: 0.68 - ETA: 1:51 - loss: 5.0416 - accuracy: 0.68 - ETA: 1:51 - loss: 5.0415 - accuracy: 0.69 - ETA: 1:51 - loss: 5.0391 - accuracy: 0.68 - ETA: 1:50 - loss: 5.0392 - accuracy: 0.68 - ETA: 1:50 - loss: 5.0419 - accuracy: 0.68 - ETA: 1:50 - loss: 5.0446 - accuracy: 0.68 - ETA: 1:49 - loss: 5.0428 - accuracy: 0.68 - ETA: 1:49 - loss: 5.0450 - accuracy: 0.68 - ETA: 1:49 - loss: 5.0469 - accuracy: 0.68 - ETA: 1:49 - loss: 5.0489 - accuracy: 0.68 - ETA: 1:48 - loss: 5.0480 - accuracy: 0.68 - ETA: 1:48 - loss: 5.0518 - accuracy: 0.68 - ETA: 1:48 - loss: 5.0509 - accuracy: 0.68 - ETA: 1:47 - loss: 5.0511 - accuracy: 0.69 - ETA: 1:47 - loss: 5.0513 - accuracy: 0.69 - ETA: 1:47 - loss: 5.0513 - accuracy: 0.69 - ETA: 1:47 - loss: 5.0542 - accuracy: 0.69 - ETA: 1:46 - loss: 5.0600 - accuracy: 0.69 - ETA: 1:46 - loss: 5.0565 - accuracy: 0.68 - ETA: 1:46 - loss: 5.0545 - accuracy: 0.69 - ETA: 1:45 - loss: 5.0517 - accuracy: 0.69 - ETA: 1:45 - loss: 5.0455 - accuracy: 0.69 - ETA: 1:45 - loss: 5.0439 - accuracy: 0.69 - ETA: 1:45 - loss: 5.0402 - accuracy: 0.69 - ETA: 1:44 - loss: 5.0381 - accuracy: 0.69 - ETA: 1:44 - loss: 5.0388 - accuracy: 0.69 - ETA: 1:44 - loss: 5.0348 - accuracy: 0.69 - ETA: 1:43 - loss: 5.0324 - accuracy: 0.69 - ETA: 1:43 - loss: 5.0388 - accuracy: 0.69 - ETA: 1:43 - loss: 5.0401 - accuracy: 0.69 - ETA: 1:43 - loss: 5.0395 - accuracy: 0.69 - ETA: 1:42 - loss: 5.0375 - accuracy: 0.69 - ETA: 1:42 - loss: 5.0332 - accuracy: 0.69 - ETA: 1:42 - loss: 5.0353 - accuracy: 0.69 - ETA: 1:42 - loss: 5.0342 - accuracy: 0.69 - ETA: 1:41 - loss: 5.0380 - accuracy: 0.69 - ETA: 1:41 - loss: 5.0388 - accuracy: 0.69 - ETA: 1:41 - loss: 5.0368 - accuracy: 0.69 - ETA: 1:40 - loss: 5.0388 - accuracy: 0.69 - ETA: 1:40 - loss: 5.0399 - accuracy: 0.69 - ETA: 1:40 - loss: 5.0379 - accuracy: 0.69 - ETA: 1:40 - loss: 5.0345 - accuracy: 0.69 - ETA: 1:39 - loss: 5.0339 - accuracy: 0.69 - ETA: 1:39 - loss: 5.0347 - accuracy: 0.69 - ETA: 1:39 - loss: 5.0356 - accuracy: 0.69 - ETA: 1:38 - loss: 5.0381 - accuracy: 0.69 - ETA: 1:38 - loss: 5.0383 - accuracy: 0.69 - ETA: 1:38 - loss: 5.0354 - accuracy: 0.69 - ETA: 1:38 - loss: 5.0373 - accuracy: 0.69 - ETA: 1:37 - loss: 5.0372 - accuracy: 0.69 - ETA: 1:37 - loss: 5.0379 - accuracy: 0.69 - ETA: 1:37 - loss: 5.0362 - accuracy: 0.69 - ETA: 1:36 - loss: 5.0345 - accuracy: 0.69 - ETA: 1:36 - loss: 5.0373 - accuracy: 0.69 - ETA: 1:36 - loss: 5.0358 - accuracy: 0.69 - ETA: 1:36 - loss: 5.0336 - accuracy: 0.69 - ETA: 1:36 - loss: 5.0312 - accuracy: 0.69 - ETA: 1:35 - loss: 5.0332 - accuracy: 0.69 - ETA: 1:35 - loss: 5.0311 - accuracy: 0.69 - ETA: 1:35 - loss: 5.0288 - accuracy: 0.69 - ETA: 1:34 - loss: 5.0299 - accuracy: 0.69 - ETA: 1:34 - loss: 5.0337 - accuracy: 0.69 - ETA: 1:34 - loss: 5.0357 - accuracy: 0.69 - ETA: 1:34 - loss: 5.0388 - accuracy: 0.69 - ETA: 1:33 - loss: 5.0373 - accuracy: 0.69 - ETA: 1:33 - loss: 5.0370 - accuracy: 0.69 - ETA: 1:33 - loss: 5.0381 - accuracy: 0.69 - ETA: 1:32 - loss: 5.0384 - accuracy: 0.69 - ETA: 1:32 - loss: 5.0356 - accuracy: 0.69 - ETA: 1:32 - loss: 5.0379 - accuracy: 0.69 - ETA: 1:32 - loss: 5.0350 - accuracy: 0.69 - ETA: 1:31 - loss: 5.0325 - accuracy: 0.69 - ETA: 1:31 - loss: 5.0339 - accuracy: 0.69 - ETA: 1:31 - loss: 5.0318 - accuracy: 0.69 - ETA: 1:30 - loss: 5.0304 - accuracy: 0.69 - ETA: 1:30 - loss: 5.0289 - accuracy: 0.69 - ETA: 1:30 - loss: 5.0307 - accuracy: 0.69 - ETA: 1:30 - loss: 5.0302 - accuracy: 0.69 - ETA: 1:29 - loss: 5.0292 - accuracy: 0.69 - ETA: 1:29 - loss: 5.0281 - accuracy: 0.69 - ETA: 1:29 - loss: 5.0270 - accuracy: 0.69 - ETA: 1:29 - loss: 5.0275 - accuracy: 0.69 - ETA: 1:28 - loss: 5.0263 - accuracy: 0.69 - ETA: 1:28 - loss: 5.0285 - accuracy: 0.69 - ETA: 1:28 - loss: 5.0266 - accuracy: 0.69 - ETA: 1:27 - loss: 5.0249 - accuracy: 0.69 - ETA: 1:27 - loss: 5.0238 - accuracy: 0.69 - ETA: 1:27 - loss: 5.0221 - accuracy: 0.69 - ETA: 1:27 - loss: 5.0179 - accuracy: 0.69 - ETA: 1:26 - loss: 5.0147 - accuracy: 0.69 - ETA: 1:26 - loss: 5.0135 - accuracy: 0.69 - ETA: 1:26 - loss: 5.0144 - accuracy: 0.69 - ETA: 1:25 - loss: 5.0127 - accuracy: 0.69 - ETA: 1:25 - loss: 5.0125 - accuracy: 0.69 - ETA: 1:25 - loss: 5.0136 - accuracy: 0.69 - ETA: 1:25 - loss: 5.0131 - accuracy: 0.69 - ETA: 1:24 - loss: 5.0112 - accuracy: 0.69 - ETA: 1:24 - loss: 5.0100 - accuracy: 0.69 - ETA: 1:24 - loss: 5.0083 - accuracy: 0.69 - ETA: 1:23 - loss: 5.0112 - accuracy: 0.69 - ETA: 1:23 - loss: 5.0114 - accuracy: 0.69 - ETA: 1:23 - loss: 5.0101 - accuracy: 0.69 - ETA: 1:23 - loss: 5.0118 - accuracy: 0.69 - ETA: 1:22 - loss: 5.0157 - accuracy: 0.69 - ETA: 1:22 - loss: 5.0154 - accuracy: 0.69 - ETA: 1:22 - loss: 5.0146 - accuracy: 0.69 - ETA: 1:22 - loss: 5.0156 - accuracy: 0.69 - ETA: 1:21 - loss: 5.0147 - accuracy: 0.69 - ETA: 1:21 - loss: 5.0169 - accuracy: 0.69 - ETA: 1:21 - loss: 5.0199 - accuracy: 0.69 - ETA: 1:20 - loss: 5.0207 - accuracy: 0.69 - ETA: 1:20 - loss: 5.0209 - accuracy: 0.69 - ETA: 1:20 - loss: 5.0214 - accuracy: 0.69 - ETA: 1:20 - loss: 5.0204 - accuracy: 0.69 - ETA: 1:19 - loss: 5.0213 - accuracy: 0.69 - ETA: 1:19 - loss: 5.0223 - accuracy: 0.69 - ETA: 1:19 - loss: 5.0214 - accuracy: 0.69 - ETA: 1:18 - loss: 5.0252 - accuracy: 0.69 - ETA: 1:18 - loss: 5.0240 - accuracy: 0.69 - ETA: 1:18 - loss: 5.0222 - accuracy: 0.69 - ETA: 1:18 - loss: 5.0229 - accuracy: 0.69 - ETA: 1:17 - loss: 5.0206 - accuracy: 0.69 - ETA: 1:17 - loss: 5.0225 - accuracy: 0.69 - ETA: 1:17 - loss: 5.0209 - accuracy: 0.69 - ETA: 1:16 - loss: 5.0188 - accuracy: 0.69 - ETA: 1:16 - loss: 5.0187 - accuracy: 0.69 - ETA: 1:16 - loss: 5.0209 - accuracy: 0.69 - ETA: 1:16 - loss: 5.0178 - accuracy: 0.69 - ETA: 1:15 - loss: 5.0180 - accuracy: 0.69 - ETA: 1:15 - loss: 5.0187 - accuracy: 0.69 - ETA: 1:15 - loss: 5.0165 - accuracy: 0.69 - ETA: 1:15 - loss: 5.0172 - accuracy: 0.69 - ETA: 1:14 - loss: 5.0156 - accuracy: 0.69 - ETA: 1:14 - loss: 5.0172 - accuracy: 0.69 - ETA: 1:14 - loss: 5.0173 - accuracy: 0.69 - ETA: 1:13 - loss: 5.0174 - accuracy: 0.69 - ETA: 1:13 - loss: 5.0156 - accuracy: 0.69 - ETA: 1:13 - loss: 5.0162 - accuracy: 0.69 - ETA: 1:13 - loss: 5.0187 - accuracy: 0.69 - ETA: 1:12 - loss: 5.0193 - accuracy: 0.69 - ETA: 1:12 - loss: 5.0179 - accuracy: 0.69 - ETA: 1:12 - loss: 5.0161 - accuracy: 0.69 - ETA: 1:11 - loss: 5.0169 - accuracy: 0.69 - ETA: 1:11 - loss: 5.0170 - accuracy: 0.69 - ETA: 1:11 - loss: 5.0155 - accuracy: 0.69 - ETA: 1:11 - loss: 5.0132 - accuracy: 0.69 - ETA: 1:10 - loss: 5.0122 - accuracy: 0.69 - ETA: 1:10 - loss: 5.0122 - accuracy: 0.69 - ETA: 1:10 - loss: 5.0125 - accuracy: 0.69 - ETA: 1:10 - loss: 5.0136 - accuracy: 0.6904"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17856/20000 [=========================>....] - ETA: 1:09 - loss: 5.0143 - accuracy: 0.69 - ETA: 1:09 - loss: 5.0150 - accuracy: 0.69 - ETA: 1:09 - loss: 5.0186 - accuracy: 0.68 - ETA: 1:08 - loss: 5.0192 - accuracy: 0.68 - ETA: 1:08 - loss: 5.0195 - accuracy: 0.68 - ETA: 1:08 - loss: 5.0184 - accuracy: 0.69 - ETA: 1:08 - loss: 5.0157 - accuracy: 0.69 - ETA: 1:07 - loss: 5.0161 - accuracy: 0.69 - ETA: 1:07 - loss: 5.0142 - accuracy: 0.69 - ETA: 1:07 - loss: 5.0146 - accuracy: 0.69 - ETA: 1:06 - loss: 5.0142 - accuracy: 0.69 - ETA: 1:06 - loss: 5.0117 - accuracy: 0.69 - ETA: 1:06 - loss: 5.0104 - accuracy: 0.69 - ETA: 1:06 - loss: 5.0096 - accuracy: 0.69 - ETA: 1:05 - loss: 5.0078 - accuracy: 0.69 - ETA: 1:05 - loss: 5.0063 - accuracy: 0.69 - ETA: 1:05 - loss: 5.0042 - accuracy: 0.69 - ETA: 1:05 - loss: 5.0058 - accuracy: 0.69 - ETA: 1:04 - loss: 5.0046 - accuracy: 0.69 - ETA: 1:04 - loss: 5.0011 - accuracy: 0.69 - ETA: 1:04 - loss: 5.0025 - accuracy: 0.69 - ETA: 1:03 - loss: 5.0033 - accuracy: 0.69 - ETA: 1:03 - loss: 5.0021 - accuracy: 0.69 - ETA: 1:03 - loss: 5.0021 - accuracy: 0.69 - ETA: 1:03 - loss: 5.0021 - accuracy: 0.69 - ETA: 1:02 - loss: 5.0006 - accuracy: 0.69 - ETA: 1:02 - loss: 5.0003 - accuracy: 0.69 - ETA: 1:02 - loss: 5.0004 - accuracy: 0.69 - ETA: 1:01 - loss: 4.9999 - accuracy: 0.69 - ETA: 1:01 - loss: 4.9981 - accuracy: 0.69 - ETA: 1:01 - loss: 4.9999 - accuracy: 0.69 - ETA: 1:01 - loss: 4.9979 - accuracy: 0.69 - ETA: 1:00 - loss: 4.9969 - accuracy: 0.69 - ETA: 1:00 - loss: 4.9992 - accuracy: 0.69 - ETA: 1:00 - loss: 4.9964 - accuracy: 0.69 - ETA: 1:00 - loss: 4.9958 - accuracy: 0.69 - ETA: 59s - loss: 4.9984 - accuracy: 0.6916 - ETA: 59s - loss: 4.9989 - accuracy: 0.691 - ETA: 59s - loss: 4.9988 - accuracy: 0.691 - ETA: 58s - loss: 4.9995 - accuracy: 0.691 - ETA: 58s - loss: 4.9997 - accuracy: 0.691 - ETA: 58s - loss: 4.9973 - accuracy: 0.691 - ETA: 58s - loss: 4.9991 - accuracy: 0.691 - ETA: 57s - loss: 4.9992 - accuracy: 0.691 - ETA: 57s - loss: 4.9998 - accuracy: 0.691 - ETA: 57s - loss: 5.0024 - accuracy: 0.691 - ETA: 56s - loss: 5.0009 - accuracy: 0.691 - ETA: 56s - loss: 5.0034 - accuracy: 0.690 - ETA: 56s - loss: 5.0041 - accuracy: 0.690 - ETA: 56s - loss: 5.0053 - accuracy: 0.690 - ETA: 55s - loss: 5.0035 - accuracy: 0.691 - ETA: 55s - loss: 5.0033 - accuracy: 0.691 - ETA: 55s - loss: 5.0020 - accuracy: 0.691 - ETA: 55s - loss: 5.0045 - accuracy: 0.691 - ETA: 54s - loss: 5.0035 - accuracy: 0.691 - ETA: 54s - loss: 5.0042 - accuracy: 0.691 - ETA: 54s - loss: 5.0015 - accuracy: 0.691 - ETA: 53s - loss: 5.0038 - accuracy: 0.691 - ETA: 53s - loss: 5.0054 - accuracy: 0.691 - ETA: 53s - loss: 5.0059 - accuracy: 0.691 - ETA: 53s - loss: 5.0053 - accuracy: 0.691 - ETA: 52s - loss: 5.0058 - accuracy: 0.691 - ETA: 52s - loss: 5.0046 - accuracy: 0.691 - ETA: 52s - loss: 5.0036 - accuracy: 0.691 - ETA: 51s - loss: 5.0046 - accuracy: 0.691 - ETA: 51s - loss: 5.0038 - accuracy: 0.691 - ETA: 51s - loss: 5.0045 - accuracy: 0.691 - ETA: 51s - loss: 5.0059 - accuracy: 0.691 - ETA: 50s - loss: 5.0045 - accuracy: 0.692 - ETA: 50s - loss: 5.0050 - accuracy: 0.692 - ETA: 50s - loss: 5.0067 - accuracy: 0.691 - ETA: 50s - loss: 5.0070 - accuracy: 0.692 - ETA: 49s - loss: 5.0063 - accuracy: 0.691 - ETA: 49s - loss: 5.0041 - accuracy: 0.692 - ETA: 49s - loss: 5.0013 - accuracy: 0.692 - ETA: 48s - loss: 5.0034 - accuracy: 0.692 - ETA: 48s - loss: 5.0046 - accuracy: 0.692 - ETA: 48s - loss: 5.0053 - accuracy: 0.692 - ETA: 48s - loss: 5.0034 - accuracy: 0.692 - ETA: 47s - loss: 5.0019 - accuracy: 0.691 - ETA: 47s - loss: 5.0010 - accuracy: 0.692 - ETA: 47s - loss: 5.0036 - accuracy: 0.691 - ETA: 46s - loss: 5.0058 - accuracy: 0.692 - ETA: 46s - loss: 5.0040 - accuracy: 0.692 - ETA: 46s - loss: 5.0062 - accuracy: 0.692 - ETA: 46s - loss: 5.0080 - accuracy: 0.692 - ETA: 45s - loss: 5.0102 - accuracy: 0.692 - ETA: 45s - loss: 5.0095 - accuracy: 0.692 - ETA: 45s - loss: 5.0091 - accuracy: 0.692 - ETA: 45s - loss: 5.0098 - accuracy: 0.692 - ETA: 44s - loss: 5.0097 - accuracy: 0.692 - ETA: 44s - loss: 5.0077 - accuracy: 0.691 - ETA: 44s - loss: 5.0073 - accuracy: 0.691 - ETA: 43s - loss: 5.0089 - accuracy: 0.691 - ETA: 43s - loss: 5.0094 - accuracy: 0.691 - ETA: 43s - loss: 5.0081 - accuracy: 0.691 - ETA: 43s - loss: 5.0095 - accuracy: 0.691 - ETA: 42s - loss: 5.0105 - accuracy: 0.691 - ETA: 42s - loss: 5.0105 - accuracy: 0.690 - ETA: 42s - loss: 5.0109 - accuracy: 0.691 - ETA: 41s - loss: 5.0125 - accuracy: 0.690 - ETA: 41s - loss: 5.0128 - accuracy: 0.691 - ETA: 41s - loss: 5.0123 - accuracy: 0.691 - ETA: 41s - loss: 5.0117 - accuracy: 0.691 - ETA: 40s - loss: 5.0119 - accuracy: 0.691 - ETA: 40s - loss: 5.0119 - accuracy: 0.691 - ETA: 40s - loss: 5.0099 - accuracy: 0.691 - ETA: 40s - loss: 5.0095 - accuracy: 0.691 - ETA: 39s - loss: 5.0084 - accuracy: 0.691 - ETA: 39s - loss: 5.0088 - accuracy: 0.691 - ETA: 39s - loss: 5.0095 - accuracy: 0.690 - ETA: 38s - loss: 5.0086 - accuracy: 0.691 - ETA: 38s - loss: 5.0082 - accuracy: 0.691 - ETA: 38s - loss: 5.0118 - accuracy: 0.691 - ETA: 38s - loss: 5.0106 - accuracy: 0.691 - ETA: 37s - loss: 5.0102 - accuracy: 0.691 - ETA: 37s - loss: 5.0104 - accuracy: 0.691 - ETA: 37s - loss: 5.0107 - accuracy: 0.690 - ETA: 37s - loss: 5.0104 - accuracy: 0.690 - ETA: 36s - loss: 5.0108 - accuracy: 0.690 - ETA: 36s - loss: 5.0104 - accuracy: 0.690 - ETA: 36s - loss: 5.0109 - accuracy: 0.690 - ETA: 35s - loss: 5.0112 - accuracy: 0.690 - ETA: 35s - loss: 5.0101 - accuracy: 0.690 - ETA: 35s - loss: 5.0086 - accuracy: 0.690 - ETA: 35s - loss: 5.0084 - accuracy: 0.690 - ETA: 34s - loss: 5.0074 - accuracy: 0.690 - ETA: 34s - loss: 5.0077 - accuracy: 0.691 - ETA: 34s - loss: 5.0081 - accuracy: 0.690 - ETA: 33s - loss: 5.0084 - accuracy: 0.690 - ETA: 33s - loss: 5.0093 - accuracy: 0.690 - ETA: 33s - loss: 5.0095 - accuracy: 0.691 - ETA: 33s - loss: 5.0090 - accuracy: 0.691 - ETA: 32s - loss: 5.0122 - accuracy: 0.690 - ETA: 32s - loss: 5.0149 - accuracy: 0.690 - ETA: 32s - loss: 5.0145 - accuracy: 0.690 - ETA: 32s - loss: 5.0133 - accuracy: 0.690 - ETA: 31s - loss: 5.0114 - accuracy: 0.690 - ETA: 31s - loss: 5.0103 - accuracy: 0.691 - ETA: 31s - loss: 5.0109 - accuracy: 0.691 - ETA: 30s - loss: 5.0098 - accuracy: 0.691 - ETA: 30s - loss: 5.0084 - accuracy: 0.691 - ETA: 30s - loss: 5.0087 - accuracy: 0.691 - ETA: 30s - loss: 5.0068 - accuracy: 0.691 - ETA: 29s - loss: 5.0071 - accuracy: 0.691 - ETA: 29s - loss: 5.0062 - accuracy: 0.691 - ETA: 29s - loss: 5.0050 - accuracy: 0.691 - ETA: 29s - loss: 5.0042 - accuracy: 0.691 - ETA: 28s - loss: 5.0045 - accuracy: 0.691 - ETA: 28s - loss: 5.0045 - accuracy: 0.691 - ETA: 28s - loss: 5.0036 - accuracy: 0.691 - ETA: 27s - loss: 5.0040 - accuracy: 0.691 - ETA: 27s - loss: 5.0066 - accuracy: 0.692 - ETA: 27s - loss: 5.0042 - accuracy: 0.692 - ETA: 27s - loss: 5.0038 - accuracy: 0.692 - ETA: 26s - loss: 5.0049 - accuracy: 0.692 - ETA: 26s - loss: 5.0071 - accuracy: 0.692 - ETA: 26s - loss: 5.0061 - accuracy: 0.692 - ETA: 25s - loss: 5.0069 - accuracy: 0.692 - ETA: 25s - loss: 5.0068 - accuracy: 0.692 - ETA: 25s - loss: 5.0081 - accuracy: 0.692 - ETA: 25s - loss: 5.0072 - accuracy: 0.692 - ETA: 24s - loss: 5.0065 - accuracy: 0.692 - ETA: 24s - loss: 5.0090 - accuracy: 0.691 - ETA: 24s - loss: 5.0106 - accuracy: 0.691 - ETA: 24s - loss: 5.0117 - accuracy: 0.691 - ETA: 23s - loss: 5.0129 - accuracy: 0.691 - ETA: 23s - loss: 5.0115 - accuracy: 0.691 - ETA: 23s - loss: 5.0125 - accuracy: 0.691 - ETA: 22s - loss: 5.0126 - accuracy: 0.691 - ETA: 22s - loss: 5.0124 - accuracy: 0.692 - ETA: 22s - loss: 5.0117 - accuracy: 0.691 - ETA: 22s - loss: 5.0113 - accuracy: 0.691 - ETA: 21s - loss: 5.0108 - accuracy: 0.691 - ETA: 21s - loss: 5.0103 - accuracy: 0.691 - ETA: 21s - loss: 5.0105 - accuracy: 0.691 - ETA: 20s - loss: 5.0102 - accuracy: 0.691 - ETA: 20s - loss: 5.0082 - accuracy: 0.691 - ETA: 20s - loss: 5.0101 - accuracy: 0.691 - ETA: 20s - loss: 5.0087 - accuracy: 0.691 - ETA: 19s - loss: 5.0093 - accuracy: 0.691 - ETA: 19s - loss: 5.0083 - accuracy: 0.691 - ETA: 19s - loss: 5.0089 - accuracy: 0.691 - ETA: 19s - loss: 5.0073 - accuracy: 0.691 - ETA: 18s - loss: 5.0055 - accuracy: 0.691 - ETA: 18s - loss: 5.0062 - accuracy: 0.6916"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - ETA: 18s - loss: 5.0055 - accuracy: 0.691 - ETA: 17s - loss: 5.0061 - accuracy: 0.691 - ETA: 17s - loss: 5.0058 - accuracy: 0.691 - ETA: 17s - loss: 5.0050 - accuracy: 0.691 - ETA: 17s - loss: 5.0045 - accuracy: 0.691 - ETA: 16s - loss: 5.0051 - accuracy: 0.692 - ETA: 16s - loss: 5.0049 - accuracy: 0.692 - ETA: 16s - loss: 5.0036 - accuracy: 0.692 - ETA: 16s - loss: 5.0022 - accuracy: 0.692 - ETA: 15s - loss: 5.0005 - accuracy: 0.692 - ETA: 15s - loss: 4.9999 - accuracy: 0.692 - ETA: 15s - loss: 4.9987 - accuracy: 0.692 - ETA: 14s - loss: 4.9989 - accuracy: 0.692 - ETA: 14s - loss: 4.9971 - accuracy: 0.692 - ETA: 14s - loss: 4.9959 - accuracy: 0.692 - ETA: 14s - loss: 4.9948 - accuracy: 0.692 - ETA: 13s - loss: 4.9941 - accuracy: 0.692 - ETA: 13s - loss: 4.9949 - accuracy: 0.692 - ETA: 13s - loss: 4.9931 - accuracy: 0.693 - ETA: 12s - loss: 4.9931 - accuracy: 0.693 - ETA: 12s - loss: 4.9936 - accuracy: 0.693 - ETA: 12s - loss: 4.9947 - accuracy: 0.692 - ETA: 12s - loss: 4.9944 - accuracy: 0.692 - ETA: 11s - loss: 4.9962 - accuracy: 0.692 - ETA: 11s - loss: 4.9967 - accuracy: 0.692 - ETA: 11s - loss: 4.9977 - accuracy: 0.692 - ETA: 11s - loss: 4.9981 - accuracy: 0.693 - ETA: 10s - loss: 4.9983 - accuracy: 0.692 - ETA: 10s - loss: 4.9988 - accuracy: 0.692 - ETA: 10s - loss: 4.9981 - accuracy: 0.693 - ETA: 9s - loss: 4.9962 - accuracy: 0.693 - ETA: 9s - loss: 4.9951 - accuracy: 0.69 - ETA: 9s - loss: 4.9954 - accuracy: 0.69 - ETA: 9s - loss: 4.9947 - accuracy: 0.69 - ETA: 8s - loss: 4.9943 - accuracy: 0.69 - ETA: 8s - loss: 4.9926 - accuracy: 0.69 - ETA: 8s - loss: 4.9930 - accuracy: 0.69 - ETA: 8s - loss: 4.9922 - accuracy: 0.69 - ETA: 7s - loss: 4.9931 - accuracy: 0.69 - ETA: 7s - loss: 4.9919 - accuracy: 0.69 - ETA: 7s - loss: 4.9931 - accuracy: 0.69 - ETA: 6s - loss: 4.9924 - accuracy: 0.69 - ETA: 6s - loss: 4.9925 - accuracy: 0.69 - ETA: 6s - loss: 4.9909 - accuracy: 0.69 - ETA: 6s - loss: 4.9901 - accuracy: 0.69 - ETA: 5s - loss: 4.9899 - accuracy: 0.69 - ETA: 5s - loss: 4.9905 - accuracy: 0.69 - ETA: 5s - loss: 4.9911 - accuracy: 0.69 - ETA: 4s - loss: 4.9897 - accuracy: 0.69 - ETA: 4s - loss: 4.9888 - accuracy: 0.69 - ETA: 4s - loss: 4.9881 - accuracy: 0.69 - ETA: 4s - loss: 4.9878 - accuracy: 0.69 - ETA: 3s - loss: 4.9860 - accuracy: 0.69 - ETA: 3s - loss: 4.9855 - accuracy: 0.69 - ETA: 3s - loss: 4.9850 - accuracy: 0.69 - ETA: 3s - loss: 4.9830 - accuracy: 0.69 - ETA: 2s - loss: 4.9821 - accuracy: 0.69 - ETA: 2s - loss: 4.9800 - accuracy: 0.69 - ETA: 2s - loss: 4.9802 - accuracy: 0.69 - ETA: 1s - loss: 4.9813 - accuracy: 0.69 - ETA: 1s - loss: 4.9816 - accuracy: 0.69 - ETA: 1s - loss: 4.9823 - accuracy: 0.69 - ETA: 1s - loss: 4.9847 - accuracy: 0.69 - ETA: 0s - loss: 4.9847 - accuracy: 0.69 - ETA: 0s - loss: 4.9846 - accuracy: 0.69 - ETA: 0s - loss: 4.9849 - accuracy: 0.69 - 176s 9ms/step - loss: 4.9839 - accuracy: 0.6937\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5952/20000 [=======>......................] - ETA: 2:51 - loss: 5.8588 - accuracy: 0.68 - ETA: 2:49 - loss: 5.3231 - accuracy: 0.70 - ETA: 2:48 - loss: 5.1494 - accuracy: 0.70 - ETA: 2:48 - loss: 4.8925 - accuracy: 0.68 - ETA: 2:47 - loss: 5.1603 - accuracy: 0.66 - ETA: 2:47 - loss: 5.1705 - accuracy: 0.67 - ETA: 2:46 - loss: 5.0711 - accuracy: 0.69 - ETA: 2:46 - loss: 5.0326 - accuracy: 0.70 - ETA: 2:46 - loss: 5.0167 - accuracy: 0.70 - ETA: 2:45 - loss: 5.0532 - accuracy: 0.70 - ETA: 2:45 - loss: 5.0315 - accuracy: 0.69 - ETA: 3:07 - loss: 5.0308 - accuracy: 0.69 - ETA: 3:05 - loss: 5.0023 - accuracy: 0.68 - ETA: 3:04 - loss: 5.0491 - accuracy: 0.69 - ETA: 3:07 - loss: 4.9827 - accuracy: 0.68 - ETA: 3:05 - loss: 4.9489 - accuracy: 0.69 - ETA: 3:04 - loss: 5.0057 - accuracy: 0.68 - ETA: 3:02 - loss: 4.9676 - accuracy: 0.69 - ETA: 3:01 - loss: 4.9811 - accuracy: 0.68 - ETA: 3:00 - loss: 4.9494 - accuracy: 0.68 - ETA: 2:59 - loss: 4.9386 - accuracy: 0.68 - ETA: 3:00 - loss: 4.9722 - accuracy: 0.69 - ETA: 3:02 - loss: 5.0004 - accuracy: 0.68 - ETA: 3:10 - loss: 4.9644 - accuracy: 0.68 - ETA: 3:08 - loss: 5.0429 - accuracy: 0.68 - ETA: 3:36 - loss: 5.0338 - accuracy: 0.68 - ETA: 3:37 - loss: 5.0140 - accuracy: 0.69 - ETA: 3:34 - loss: 5.0127 - accuracy: 0.69 - ETA: 3:32 - loss: 5.0080 - accuracy: 0.69 - ETA: 3:30 - loss: 5.0426 - accuracy: 0.69 - ETA: 3:28 - loss: 5.0394 - accuracy: 0.69 - ETA: 3:26 - loss: 5.0323 - accuracy: 0.69 - ETA: 3:24 - loss: 5.0276 - accuracy: 0.69 - ETA: 3:23 - loss: 5.0260 - accuracy: 0.69 - ETA: 3:21 - loss: 5.0089 - accuracy: 0.69 - ETA: 3:20 - loss: 5.0030 - accuracy: 0.69 - ETA: 3:18 - loss: 4.9908 - accuracy: 0.69 - ETA: 3:17 - loss: 4.9921 - accuracy: 0.69 - ETA: 3:15 - loss: 4.9844 - accuracy: 0.69 - ETA: 3:14 - loss: 4.9595 - accuracy: 0.69 - ETA: 3:13 - loss: 4.9507 - accuracy: 0.69 - ETA: 3:12 - loss: 4.9309 - accuracy: 0.70 - ETA: 3:10 - loss: 4.9190 - accuracy: 0.70 - ETA: 3:09 - loss: 4.9138 - accuracy: 0.69 - ETA: 3:08 - loss: 4.9164 - accuracy: 0.69 - ETA: 3:07 - loss: 4.9067 - accuracy: 0.69 - ETA: 3:06 - loss: 4.9253 - accuracy: 0.70 - ETA: 3:05 - loss: 4.9217 - accuracy: 0.70 - ETA: 3:04 - loss: 4.9396 - accuracy: 0.70 - ETA: 3:03 - loss: 4.9423 - accuracy: 0.69 - ETA: 3:03 - loss: 4.9464 - accuracy: 0.70 - ETA: 3:02 - loss: 4.9413 - accuracy: 0.70 - ETA: 3:01 - loss: 4.9270 - accuracy: 0.69 - ETA: 3:00 - loss: 4.9220 - accuracy: 0.69 - ETA: 2:59 - loss: 4.9277 - accuracy: 0.69 - ETA: 2:58 - loss: 4.9233 - accuracy: 0.69 - ETA: 2:58 - loss: 4.9147 - accuracy: 0.69 - ETA: 2:57 - loss: 4.9189 - accuracy: 0.69 - ETA: 2:56 - loss: 4.9121 - accuracy: 0.69 - ETA: 2:56 - loss: 4.9245 - accuracy: 0.69 - ETA: 2:55 - loss: 4.9317 - accuracy: 0.69 - ETA: 2:54 - loss: 4.9438 - accuracy: 0.69 - ETA: 2:54 - loss: 4.9467 - accuracy: 0.69 - ETA: 2:53 - loss: 4.9375 - accuracy: 0.69 - ETA: 2:52 - loss: 4.9327 - accuracy: 0.69 - ETA: 2:52 - loss: 4.9330 - accuracy: 0.69 - ETA: 2:51 - loss: 4.9223 - accuracy: 0.69 - ETA: 2:50 - loss: 4.9332 - accuracy: 0.69 - ETA: 2:50 - loss: 4.9298 - accuracy: 0.69 - ETA: 2:49 - loss: 4.9337 - accuracy: 0.68 - ETA: 2:49 - loss: 4.9387 - accuracy: 0.69 - ETA: 2:48 - loss: 4.9316 - accuracy: 0.69 - ETA: 2:47 - loss: 4.9225 - accuracy: 0.69 - ETA: 2:47 - loss: 4.9164 - accuracy: 0.69 - ETA: 2:46 - loss: 4.9226 - accuracy: 0.69 - ETA: 2:46 - loss: 4.9125 - accuracy: 0.69 - ETA: 2:45 - loss: 4.9038 - accuracy: 0.69 - ETA: 2:45 - loss: 4.8978 - accuracy: 0.69 - ETA: 2:44 - loss: 4.9031 - accuracy: 0.69 - ETA: 2:44 - loss: 4.8938 - accuracy: 0.69 - ETA: 2:43 - loss: 4.8912 - accuracy: 0.69 - ETA: 2:43 - loss: 4.8831 - accuracy: 0.69 - ETA: 2:42 - loss: 4.8879 - accuracy: 0.69 - ETA: 2:42 - loss: 4.8864 - accuracy: 0.69 - ETA: 2:41 - loss: 4.8846 - accuracy: 0.69 - ETA: 2:41 - loss: 4.8915 - accuracy: 0.69 - ETA: 2:40 - loss: 4.8842 - accuracy: 0.69 - ETA: 2:40 - loss: 4.8845 - accuracy: 0.69 - ETA: 2:39 - loss: 4.8748 - accuracy: 0.69 - ETA: 2:39 - loss: 4.8736 - accuracy: 0.69 - ETA: 2:38 - loss: 4.8720 - accuracy: 0.69 - ETA: 2:38 - loss: 4.8644 - accuracy: 0.69 - ETA: 2:37 - loss: 4.8606 - accuracy: 0.69 - ETA: 2:37 - loss: 4.8505 - accuracy: 0.69 - ETA: 2:37 - loss: 4.8510 - accuracy: 0.69 - ETA: 2:36 - loss: 4.8470 - accuracy: 0.69 - ETA: 2:36 - loss: 4.8508 - accuracy: 0.69 - ETA: 2:35 - loss: 4.8645 - accuracy: 0.69 - ETA: 2:35 - loss: 4.8735 - accuracy: 0.69 - ETA: 2:34 - loss: 4.8778 - accuracy: 0.69 - ETA: 2:34 - loss: 4.8703 - accuracy: 0.69 - ETA: 2:34 - loss: 4.8615 - accuracy: 0.69 - ETA: 2:33 - loss: 4.8660 - accuracy: 0.69 - ETA: 2:33 - loss: 4.8776 - accuracy: 0.69 - ETA: 2:32 - loss: 4.8781 - accuracy: 0.69 - ETA: 2:32 - loss: 4.8759 - accuracy: 0.69 - ETA: 2:31 - loss: 4.8676 - accuracy: 0.69 - ETA: 2:31 - loss: 4.8591 - accuracy: 0.69 - ETA: 2:31 - loss: 4.8491 - accuracy: 0.69 - ETA: 2:30 - loss: 4.8529 - accuracy: 0.69 - ETA: 2:30 - loss: 4.8612 - accuracy: 0.69 - ETA: 2:29 - loss: 4.8659 - accuracy: 0.69 - ETA: 2:29 - loss: 4.8711 - accuracy: 0.69 - ETA: 2:29 - loss: 4.8680 - accuracy: 0.69 - ETA: 2:28 - loss: 4.8674 - accuracy: 0.69 - ETA: 2:28 - loss: 4.8700 - accuracy: 0.69 - ETA: 2:27 - loss: 4.8700 - accuracy: 0.69 - ETA: 2:27 - loss: 4.8790 - accuracy: 0.68 - ETA: 2:27 - loss: 4.8730 - accuracy: 0.68 - ETA: 2:26 - loss: 4.8705 - accuracy: 0.69 - ETA: 2:26 - loss: 4.8707 - accuracy: 0.69 - ETA: 2:26 - loss: 4.8661 - accuracy: 0.69 - ETA: 2:25 - loss: 4.8779 - accuracy: 0.69 - ETA: 2:25 - loss: 4.8722 - accuracy: 0.69 - ETA: 2:24 - loss: 4.8774 - accuracy: 0.69 - ETA: 2:24 - loss: 4.8739 - accuracy: 0.69 - ETA: 2:24 - loss: 4.8766 - accuracy: 0.69 - ETA: 2:23 - loss: 4.8776 - accuracy: 0.68 - ETA: 2:23 - loss: 4.8796 - accuracy: 0.69 - ETA: 2:23 - loss: 4.8827 - accuracy: 0.69 - ETA: 2:22 - loss: 4.8811 - accuracy: 0.69 - ETA: 2:22 - loss: 4.8827 - accuracy: 0.69 - ETA: 2:22 - loss: 4.8897 - accuracy: 0.69 - ETA: 2:21 - loss: 4.8871 - accuracy: 0.69 - ETA: 2:21 - loss: 4.8795 - accuracy: 0.69 - ETA: 2:20 - loss: 4.8762 - accuracy: 0.68 - ETA: 2:20 - loss: 4.8731 - accuracy: 0.69 - ETA: 2:20 - loss: 4.8702 - accuracy: 0.68 - ETA: 2:19 - loss: 4.8699 - accuracy: 0.69 - ETA: 2:19 - loss: 4.8707 - accuracy: 0.69 - ETA: 2:19 - loss: 4.8695 - accuracy: 0.68 - ETA: 2:18 - loss: 4.8713 - accuracy: 0.68 - ETA: 2:18 - loss: 4.8746 - accuracy: 0.68 - ETA: 2:18 - loss: 4.8726 - accuracy: 0.68 - ETA: 2:17 - loss: 4.8686 - accuracy: 0.68 - ETA: 2:17 - loss: 4.8705 - accuracy: 0.68 - ETA: 2:17 - loss: 4.8698 - accuracy: 0.68 - ETA: 2:16 - loss: 4.8730 - accuracy: 0.68 - ETA: 2:16 - loss: 4.8715 - accuracy: 0.68 - ETA: 2:16 - loss: 4.8727 - accuracy: 0.68 - ETA: 2:15 - loss: 4.8740 - accuracy: 0.68 - ETA: 2:15 - loss: 4.8741 - accuracy: 0.68 - ETA: 2:15 - loss: 4.8661 - accuracy: 0.68 - ETA: 2:14 - loss: 4.8638 - accuracy: 0.68 - ETA: 2:14 - loss: 4.8584 - accuracy: 0.69 - ETA: 2:14 - loss: 4.8624 - accuracy: 0.69 - ETA: 2:13 - loss: 4.8580 - accuracy: 0.69 - ETA: 2:13 - loss: 4.8576 - accuracy: 0.69 - ETA: 2:13 - loss: 4.8621 - accuracy: 0.68 - ETA: 2:12 - loss: 4.8598 - accuracy: 0.69 - ETA: 2:12 - loss: 4.8712 - accuracy: 0.68 - ETA: 2:12 - loss: 4.8667 - accuracy: 0.68 - ETA: 2:11 - loss: 4.8696 - accuracy: 0.68 - ETA: 2:11 - loss: 4.8679 - accuracy: 0.68 - ETA: 2:11 - loss: 4.8646 - accuracy: 0.68 - ETA: 2:10 - loss: 4.8600 - accuracy: 0.68 - ETA: 2:10 - loss: 4.8590 - accuracy: 0.68 - ETA: 2:10 - loss: 4.8547 - accuracy: 0.68 - ETA: 2:09 - loss: 4.8565 - accuracy: 0.68 - ETA: 2:09 - loss: 4.8571 - accuracy: 0.68 - ETA: 2:09 - loss: 4.8611 - accuracy: 0.68 - ETA: 2:08 - loss: 4.8593 - accuracy: 0.68 - ETA: 2:08 - loss: 4.8604 - accuracy: 0.68 - ETA: 2:08 - loss: 4.8557 - accuracy: 0.68 - ETA: 2:07 - loss: 4.8510 - accuracy: 0.69 - ETA: 2:07 - loss: 4.8568 - accuracy: 0.69 - ETA: 2:07 - loss: 4.8587 - accuracy: 0.68 - ETA: 2:06 - loss: 4.8651 - accuracy: 0.68 - ETA: 2:06 - loss: 4.8627 - accuracy: 0.68 - ETA: 2:06 - loss: 4.8618 - accuracy: 0.68 - ETA: 2:05 - loss: 4.8595 - accuracy: 0.68 - ETA: 2:05 - loss: 4.8528 - accuracy: 0.68 - ETA: 2:05 - loss: 4.8572 - accuracy: 0.68 - ETA: 2:05 - loss: 4.8611 - accuracy: 0.68 - ETA: 2:04 - loss: 4.8660 - accuracy: 0.68 - ETA: 2:04 - loss: 4.8688 - accuracy: 0.6865"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/20000 [================>.............] - ETA: 2:04 - loss: 4.8679 - accuracy: 0.68 - ETA: 2:03 - loss: 4.8664 - accuracy: 0.68 - ETA: 2:03 - loss: 4.8612 - accuracy: 0.68 - ETA: 2:03 - loss: 4.8606 - accuracy: 0.68 - ETA: 2:02 - loss: 4.8544 - accuracy: 0.68 - ETA: 2:02 - loss: 4.8536 - accuracy: 0.68 - ETA: 2:02 - loss: 4.8527 - accuracy: 0.68 - ETA: 2:01 - loss: 4.8551 - accuracy: 0.68 - ETA: 2:01 - loss: 4.8557 - accuracy: 0.68 - ETA: 2:01 - loss: 4.8575 - accuracy: 0.68 - ETA: 2:00 - loss: 4.8598 - accuracy: 0.68 - ETA: 2:00 - loss: 4.8643 - accuracy: 0.68 - ETA: 2:00 - loss: 4.8649 - accuracy: 0.68 - ETA: 1:59 - loss: 4.8607 - accuracy: 0.68 - ETA: 1:59 - loss: 4.8608 - accuracy: 0.68 - ETA: 1:59 - loss: 4.8634 - accuracy: 0.68 - ETA: 1:59 - loss: 4.8674 - accuracy: 0.68 - ETA: 1:58 - loss: 4.8744 - accuracy: 0.68 - ETA: 1:58 - loss: 4.8706 - accuracy: 0.68 - ETA: 1:58 - loss: 4.8686 - accuracy: 0.68 - ETA: 1:57 - loss: 4.8692 - accuracy: 0.68 - ETA: 1:57 - loss: 4.8669 - accuracy: 0.68 - ETA: 1:57 - loss: 4.8660 - accuracy: 0.68 - ETA: 1:56 - loss: 4.8678 - accuracy: 0.68 - ETA: 1:56 - loss: 4.8664 - accuracy: 0.68 - ETA: 1:56 - loss: 4.8640 - accuracy: 0.68 - ETA: 1:55 - loss: 4.8615 - accuracy: 0.68 - ETA: 1:55 - loss: 4.8617 - accuracy: 0.68 - ETA: 1:55 - loss: 4.8582 - accuracy: 0.68 - ETA: 1:55 - loss: 4.8603 - accuracy: 0.68 - ETA: 1:54 - loss: 4.8625 - accuracy: 0.68 - ETA: 1:54 - loss: 4.8671 - accuracy: 0.68 - ETA: 1:54 - loss: 4.8666 - accuracy: 0.68 - ETA: 1:53 - loss: 4.8642 - accuracy: 0.68 - ETA: 1:53 - loss: 4.8595 - accuracy: 0.68 - ETA: 1:53 - loss: 4.8586 - accuracy: 0.68 - ETA: 1:52 - loss: 4.8576 - accuracy: 0.68 - ETA: 1:52 - loss: 4.8582 - accuracy: 0.68 - ETA: 1:52 - loss: 4.8640 - accuracy: 0.69 - ETA: 1:52 - loss: 4.8651 - accuracy: 0.68 - ETA: 1:51 - loss: 4.8655 - accuracy: 0.68 - ETA: 1:51 - loss: 4.8669 - accuracy: 0.68 - ETA: 1:51 - loss: 4.8658 - accuracy: 0.68 - ETA: 1:50 - loss: 4.8643 - accuracy: 0.68 - ETA: 1:50 - loss: 4.8664 - accuracy: 0.68 - ETA: 1:50 - loss: 4.8642 - accuracy: 0.68 - ETA: 1:49 - loss: 4.8632 - accuracy: 0.68 - ETA: 1:49 - loss: 4.8642 - accuracy: 0.68 - ETA: 1:49 - loss: 4.8612 - accuracy: 0.68 - ETA: 1:49 - loss: 4.8632 - accuracy: 0.68 - ETA: 1:48 - loss: 4.8607 - accuracy: 0.68 - ETA: 1:48 - loss: 4.8613 - accuracy: 0.68 - ETA: 1:48 - loss: 4.8599 - accuracy: 0.68 - ETA: 1:47 - loss: 4.8614 - accuracy: 0.68 - ETA: 1:47 - loss: 4.8592 - accuracy: 0.68 - ETA: 1:47 - loss: 4.8555 - accuracy: 0.68 - ETA: 1:46 - loss: 4.8557 - accuracy: 0.68 - ETA: 1:46 - loss: 4.8568 - accuracy: 0.68 - ETA: 1:46 - loss: 4.8586 - accuracy: 0.68 - ETA: 1:46 - loss: 4.8602 - accuracy: 0.68 - ETA: 1:45 - loss: 4.8602 - accuracy: 0.68 - ETA: 1:45 - loss: 4.8623 - accuracy: 0.68 - ETA: 1:45 - loss: 4.8643 - accuracy: 0.68 - ETA: 1:44 - loss: 4.8644 - accuracy: 0.68 - ETA: 1:44 - loss: 4.8603 - accuracy: 0.68 - ETA: 1:44 - loss: 4.8608 - accuracy: 0.69 - ETA: 1:44 - loss: 4.8608 - accuracy: 0.69 - ETA: 1:43 - loss: 4.8585 - accuracy: 0.69 - ETA: 1:43 - loss: 4.8614 - accuracy: 0.69 - ETA: 1:43 - loss: 4.8584 - accuracy: 0.69 - ETA: 1:42 - loss: 4.8581 - accuracy: 0.69 - ETA: 1:42 - loss: 4.8600 - accuracy: 0.69 - ETA: 1:42 - loss: 4.8591 - accuracy: 0.69 - ETA: 1:41 - loss: 4.8569 - accuracy: 0.69 - ETA: 1:41 - loss: 4.8568 - accuracy: 0.69 - ETA: 1:41 - loss: 4.8557 - accuracy: 0.69 - ETA: 1:41 - loss: 4.8547 - accuracy: 0.69 - ETA: 1:40 - loss: 4.8538 - accuracy: 0.69 - ETA: 1:40 - loss: 4.8539 - accuracy: 0.69 - ETA: 1:40 - loss: 4.8502 - accuracy: 0.69 - ETA: 1:39 - loss: 4.8486 - accuracy: 0.69 - ETA: 1:39 - loss: 4.8469 - accuracy: 0.69 - ETA: 1:39 - loss: 4.8479 - accuracy: 0.69 - ETA: 1:39 - loss: 4.8514 - accuracy: 0.69 - ETA: 1:38 - loss: 4.8511 - accuracy: 0.69 - ETA: 1:38 - loss: 4.8497 - accuracy: 0.69 - ETA: 1:38 - loss: 4.8496 - accuracy: 0.69 - ETA: 1:37 - loss: 4.8482 - accuracy: 0.69 - ETA: 1:37 - loss: 4.8497 - accuracy: 0.69 - ETA: 1:37 - loss: 4.8480 - accuracy: 0.69 - ETA: 1:37 - loss: 4.8459 - accuracy: 0.69 - ETA: 1:36 - loss: 4.8495 - accuracy: 0.69 - ETA: 1:36 - loss: 4.8479 - accuracy: 0.69 - ETA: 1:36 - loss: 4.8489 - accuracy: 0.69 - ETA: 1:35 - loss: 4.8495 - accuracy: 0.69 - ETA: 1:35 - loss: 4.8531 - accuracy: 0.69 - ETA: 1:35 - loss: 4.8533 - accuracy: 0.69 - ETA: 1:35 - loss: 4.8559 - accuracy: 0.69 - ETA: 1:34 - loss: 4.8576 - accuracy: 0.69 - ETA: 1:34 - loss: 4.8578 - accuracy: 0.69 - ETA: 1:34 - loss: 4.8557 - accuracy: 0.69 - ETA: 1:33 - loss: 4.8551 - accuracy: 0.69 - ETA: 1:33 - loss: 4.8540 - accuracy: 0.69 - ETA: 1:33 - loss: 4.8505 - accuracy: 0.69 - ETA: 1:32 - loss: 4.8474 - accuracy: 0.69 - ETA: 1:32 - loss: 4.8472 - accuracy: 0.69 - ETA: 1:32 - loss: 4.8479 - accuracy: 0.69 - ETA: 1:32 - loss: 4.8482 - accuracy: 0.69 - ETA: 1:31 - loss: 4.8461 - accuracy: 0.69 - ETA: 1:31 - loss: 4.8516 - accuracy: 0.69 - ETA: 1:31 - loss: 4.8487 - accuracy: 0.69 - ETA: 1:30 - loss: 4.8469 - accuracy: 0.69 - ETA: 1:30 - loss: 4.8476 - accuracy: 0.69 - ETA: 1:30 - loss: 4.8458 - accuracy: 0.69 - ETA: 1:30 - loss: 4.8441 - accuracy: 0.69 - ETA: 1:29 - loss: 4.8436 - accuracy: 0.69 - ETA: 1:29 - loss: 4.8428 - accuracy: 0.69 - ETA: 1:29 - loss: 4.8416 - accuracy: 0.69 - ETA: 1:28 - loss: 4.8425 - accuracy: 0.69 - ETA: 1:28 - loss: 4.8401 - accuracy: 0.69 - ETA: 1:28 - loss: 4.8406 - accuracy: 0.69 - ETA: 1:28 - loss: 4.8374 - accuracy: 0.69 - ETA: 1:27 - loss: 4.8382 - accuracy: 0.69 - ETA: 1:27 - loss: 4.8407 - accuracy: 0.69 - ETA: 1:27 - loss: 4.8394 - accuracy: 0.69 - ETA: 1:26 - loss: 4.8399 - accuracy: 0.69 - ETA: 1:26 - loss: 4.8379 - accuracy: 0.69 - ETA: 1:26 - loss: 4.8357 - accuracy: 0.69 - ETA: 1:26 - loss: 4.8351 - accuracy: 0.69 - ETA: 1:25 - loss: 4.8323 - accuracy: 0.69 - ETA: 1:25 - loss: 4.8320 - accuracy: 0.69 - ETA: 1:25 - loss: 4.8321 - accuracy: 0.69 - ETA: 1:24 - loss: 4.8309 - accuracy: 0.69 - ETA: 1:24 - loss: 4.8315 - accuracy: 0.69 - ETA: 1:24 - loss: 4.8323 - accuracy: 0.69 - ETA: 1:24 - loss: 4.8327 - accuracy: 0.69 - ETA: 1:23 - loss: 4.8339 - accuracy: 0.69 - ETA: 1:23 - loss: 4.8334 - accuracy: 0.69 - ETA: 1:23 - loss: 4.8327 - accuracy: 0.69 - ETA: 1:22 - loss: 4.8320 - accuracy: 0.69 - ETA: 1:22 - loss: 4.8323 - accuracy: 0.69 - ETA: 1:22 - loss: 4.8324 - accuracy: 0.69 - ETA: 1:22 - loss: 4.8322 - accuracy: 0.69 - ETA: 1:21 - loss: 4.8296 - accuracy: 0.69 - ETA: 1:21 - loss: 4.8308 - accuracy: 0.69 - ETA: 1:21 - loss: 4.8305 - accuracy: 0.69 - ETA: 1:20 - loss: 4.8304 - accuracy: 0.69 - ETA: 1:20 - loss: 4.8286 - accuracy: 0.69 - ETA: 1:20 - loss: 4.8275 - accuracy: 0.69 - ETA: 1:20 - loss: 4.8239 - accuracy: 0.69 - ETA: 1:19 - loss: 4.8261 - accuracy: 0.69 - ETA: 1:19 - loss: 4.8264 - accuracy: 0.69 - ETA: 1:19 - loss: 4.8256 - accuracy: 0.69 - ETA: 1:18 - loss: 4.8228 - accuracy: 0.69 - ETA: 1:18 - loss: 4.8227 - accuracy: 0.69 - ETA: 1:18 - loss: 4.8321 - accuracy: 0.69 - ETA: 1:18 - loss: 4.8326 - accuracy: 0.69 - ETA: 1:17 - loss: 4.8312 - accuracy: 0.69 - ETA: 1:17 - loss: 4.8288 - accuracy: 0.69 - ETA: 1:17 - loss: 4.8297 - accuracy: 0.69 - ETA: 1:16 - loss: 4.8297 - accuracy: 0.69 - ETA: 1:16 - loss: 4.8302 - accuracy: 0.69 - ETA: 1:16 - loss: 4.8335 - accuracy: 0.69 - ETA: 1:16 - loss: 4.8343 - accuracy: 0.69 - ETA: 1:15 - loss: 4.8354 - accuracy: 0.69 - ETA: 1:15 - loss: 4.8347 - accuracy: 0.69 - ETA: 1:15 - loss: 4.8329 - accuracy: 0.69 - ETA: 1:15 - loss: 4.8342 - accuracy: 0.69 - ETA: 1:14 - loss: 4.8334 - accuracy: 0.69 - ETA: 1:14 - loss: 4.8317 - accuracy: 0.69 - ETA: 1:14 - loss: 4.8300 - accuracy: 0.69 - ETA: 1:13 - loss: 4.8304 - accuracy: 0.69 - ETA: 1:13 - loss: 4.8272 - accuracy: 0.69 - ETA: 1:13 - loss: 4.8266 - accuracy: 0.69 - ETA: 1:13 - loss: 4.8242 - accuracy: 0.69 - ETA: 1:12 - loss: 4.8264 - accuracy: 0.69 - ETA: 1:12 - loss: 4.8271 - accuracy: 0.69 - ETA: 1:12 - loss: 4.8269 - accuracy: 0.69 - ETA: 1:11 - loss: 4.8285 - accuracy: 0.69 - ETA: 1:11 - loss: 4.8272 - accuracy: 0.69 - ETA: 1:11 - loss: 4.8256 - accuracy: 0.69 - ETA: 1:11 - loss: 4.8260 - accuracy: 0.69 - ETA: 1:10 - loss: 4.8253 - accuracy: 0.69 - ETA: 1:10 - loss: 4.8300 - accuracy: 0.69 - ETA: 1:10 - loss: 4.8293 - accuracy: 0.69 - ETA: 1:09 - loss: 4.8290 - accuracy: 0.6949"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17856/20000 [=========================>....] - ETA: 1:09 - loss: 4.8289 - accuracy: 0.69 - ETA: 1:09 - loss: 4.8303 - accuracy: 0.69 - ETA: 1:09 - loss: 4.8290 - accuracy: 0.69 - ETA: 1:08 - loss: 4.8275 - accuracy: 0.69 - ETA: 1:08 - loss: 4.8272 - accuracy: 0.69 - ETA: 1:08 - loss: 4.8287 - accuracy: 0.69 - ETA: 1:07 - loss: 4.8292 - accuracy: 0.69 - ETA: 1:07 - loss: 4.8325 - accuracy: 0.69 - ETA: 1:07 - loss: 4.8308 - accuracy: 0.69 - ETA: 1:07 - loss: 4.8309 - accuracy: 0.69 - ETA: 1:06 - loss: 4.8304 - accuracy: 0.69 - ETA: 1:06 - loss: 4.8297 - accuracy: 0.69 - ETA: 1:06 - loss: 4.8296 - accuracy: 0.69 - ETA: 1:06 - loss: 4.8293 - accuracy: 0.69 - ETA: 1:05 - loss: 4.8298 - accuracy: 0.69 - ETA: 1:05 - loss: 4.8316 - accuracy: 0.69 - ETA: 1:05 - loss: 4.8292 - accuracy: 0.69 - ETA: 1:04 - loss: 4.8282 - accuracy: 0.69 - ETA: 1:04 - loss: 4.8309 - accuracy: 0.69 - ETA: 1:04 - loss: 4.8302 - accuracy: 0.69 - ETA: 1:04 - loss: 4.8291 - accuracy: 0.69 - ETA: 1:03 - loss: 4.8275 - accuracy: 0.69 - ETA: 1:03 - loss: 4.8274 - accuracy: 0.69 - ETA: 1:03 - loss: 4.8289 - accuracy: 0.69 - ETA: 1:02 - loss: 4.8286 - accuracy: 0.69 - ETA: 1:02 - loss: 4.8291 - accuracy: 0.69 - ETA: 1:02 - loss: 4.8270 - accuracy: 0.69 - ETA: 1:02 - loss: 4.8274 - accuracy: 0.69 - ETA: 1:01 - loss: 4.8256 - accuracy: 0.69 - ETA: 1:01 - loss: 4.8255 - accuracy: 0.69 - ETA: 1:01 - loss: 4.8226 - accuracy: 0.69 - ETA: 1:00 - loss: 4.8231 - accuracy: 0.69 - ETA: 1:00 - loss: 4.8221 - accuracy: 0.69 - ETA: 1:00 - loss: 4.8192 - accuracy: 0.69 - ETA: 1:00 - loss: 4.8192 - accuracy: 0.69 - ETA: 59s - loss: 4.8182 - accuracy: 0.6956 - ETA: 59s - loss: 4.8174 - accuracy: 0.695 - ETA: 59s - loss: 4.8179 - accuracy: 0.695 - ETA: 59s - loss: 4.8177 - accuracy: 0.695 - ETA: 58s - loss: 4.8176 - accuracy: 0.695 - ETA: 58s - loss: 4.8208 - accuracy: 0.695 - ETA: 58s - loss: 4.8206 - accuracy: 0.695 - ETA: 57s - loss: 4.8197 - accuracy: 0.696 - ETA: 57s - loss: 4.8188 - accuracy: 0.695 - ETA: 57s - loss: 4.8180 - accuracy: 0.695 - ETA: 57s - loss: 4.8170 - accuracy: 0.695 - ETA: 56s - loss: 4.8162 - accuracy: 0.695 - ETA: 56s - loss: 4.8168 - accuracy: 0.695 - ETA: 56s - loss: 4.8144 - accuracy: 0.695 - ETA: 55s - loss: 4.8140 - accuracy: 0.695 - ETA: 55s - loss: 4.8145 - accuracy: 0.695 - ETA: 55s - loss: 4.8139 - accuracy: 0.695 - ETA: 55s - loss: 4.8138 - accuracy: 0.695 - ETA: 54s - loss: 4.8147 - accuracy: 0.695 - ETA: 54s - loss: 4.8153 - accuracy: 0.696 - ETA: 54s - loss: 4.8146 - accuracy: 0.696 - ETA: 54s - loss: 4.8149 - accuracy: 0.695 - ETA: 53s - loss: 4.8147 - accuracy: 0.695 - ETA: 53s - loss: 4.8145 - accuracy: 0.695 - ETA: 53s - loss: 4.8176 - accuracy: 0.695 - ETA: 52s - loss: 4.8167 - accuracy: 0.695 - ETA: 52s - loss: 4.8170 - accuracy: 0.695 - ETA: 52s - loss: 4.8173 - accuracy: 0.695 - ETA: 52s - loss: 4.8159 - accuracy: 0.694 - ETA: 51s - loss: 4.8175 - accuracy: 0.695 - ETA: 51s - loss: 4.8168 - accuracy: 0.694 - ETA: 51s - loss: 4.8157 - accuracy: 0.694 - ETA: 50s - loss: 4.8134 - accuracy: 0.694 - ETA: 50s - loss: 4.8128 - accuracy: 0.694 - ETA: 50s - loss: 4.8117 - accuracy: 0.694 - ETA: 50s - loss: 4.8120 - accuracy: 0.694 - ETA: 49s - loss: 4.8134 - accuracy: 0.693 - ETA: 49s - loss: 4.8158 - accuracy: 0.693 - ETA: 49s - loss: 4.8170 - accuracy: 0.693 - ETA: 49s - loss: 4.8167 - accuracy: 0.693 - ETA: 48s - loss: 4.8154 - accuracy: 0.693 - ETA: 48s - loss: 4.8177 - accuracy: 0.693 - ETA: 48s - loss: 4.8173 - accuracy: 0.693 - ETA: 47s - loss: 4.8186 - accuracy: 0.693 - ETA: 47s - loss: 4.8230 - accuracy: 0.693 - ETA: 47s - loss: 4.8239 - accuracy: 0.692 - ETA: 47s - loss: 4.8232 - accuracy: 0.693 - ETA: 46s - loss: 4.8220 - accuracy: 0.693 - ETA: 46s - loss: 4.8228 - accuracy: 0.693 - ETA: 46s - loss: 4.8235 - accuracy: 0.693 - ETA: 45s - loss: 4.8218 - accuracy: 0.693 - ETA: 45s - loss: 4.8226 - accuracy: 0.693 - ETA: 45s - loss: 4.8249 - accuracy: 0.693 - ETA: 45s - loss: 4.8239 - accuracy: 0.693 - ETA: 44s - loss: 4.8237 - accuracy: 0.693 - ETA: 44s - loss: 4.8235 - accuracy: 0.693 - ETA: 44s - loss: 4.8229 - accuracy: 0.693 - ETA: 44s - loss: 4.8230 - accuracy: 0.693 - ETA: 43s - loss: 4.8226 - accuracy: 0.693 - ETA: 43s - loss: 4.8213 - accuracy: 0.693 - ETA: 43s - loss: 4.8225 - accuracy: 0.693 - ETA: 42s - loss: 4.8236 - accuracy: 0.694 - ETA: 42s - loss: 4.8240 - accuracy: 0.693 - ETA: 42s - loss: 4.8256 - accuracy: 0.693 - ETA: 42s - loss: 4.8259 - accuracy: 0.693 - ETA: 41s - loss: 4.8292 - accuracy: 0.693 - ETA: 41s - loss: 4.8306 - accuracy: 0.693 - ETA: 41s - loss: 4.8310 - accuracy: 0.693 - ETA: 40s - loss: 4.8331 - accuracy: 0.693 - ETA: 40s - loss: 4.8349 - accuracy: 0.693 - ETA: 40s - loss: 4.8347 - accuracy: 0.693 - ETA: 40s - loss: 4.8345 - accuracy: 0.693 - ETA: 39s - loss: 4.8351 - accuracy: 0.693 - ETA: 39s - loss: 4.8343 - accuracy: 0.693 - ETA: 39s - loss: 4.8347 - accuracy: 0.693 - ETA: 39s - loss: 4.8342 - accuracy: 0.693 - ETA: 38s - loss: 4.8337 - accuracy: 0.693 - ETA: 38s - loss: 4.8329 - accuracy: 0.693 - ETA: 38s - loss: 4.8368 - accuracy: 0.693 - ETA: 37s - loss: 4.8374 - accuracy: 0.693 - ETA: 37s - loss: 4.8373 - accuracy: 0.693 - ETA: 37s - loss: 4.8384 - accuracy: 0.694 - ETA: 37s - loss: 4.8382 - accuracy: 0.694 - ETA: 36s - loss: 4.8376 - accuracy: 0.694 - ETA: 36s - loss: 4.8360 - accuracy: 0.694 - ETA: 36s - loss: 4.8361 - accuracy: 0.694 - ETA: 36s - loss: 4.8353 - accuracy: 0.694 - ETA: 35s - loss: 4.8352 - accuracy: 0.694 - ETA: 35s - loss: 4.8361 - accuracy: 0.694 - ETA: 35s - loss: 4.8341 - accuracy: 0.694 - ETA: 34s - loss: 4.8324 - accuracy: 0.694 - ETA: 34s - loss: 4.8326 - accuracy: 0.694 - ETA: 34s - loss: 4.8328 - accuracy: 0.694 - ETA: 34s - loss: 4.8332 - accuracy: 0.694 - ETA: 33s - loss: 4.8341 - accuracy: 0.694 - ETA: 33s - loss: 4.8356 - accuracy: 0.694 - ETA: 33s - loss: 4.8352 - accuracy: 0.693 - ETA: 32s - loss: 4.8355 - accuracy: 0.693 - ETA: 32s - loss: 4.8383 - accuracy: 0.694 - ETA: 32s - loss: 4.8400 - accuracy: 0.694 - ETA: 32s - loss: 4.8406 - accuracy: 0.694 - ETA: 31s - loss: 4.8412 - accuracy: 0.693 - ETA: 31s - loss: 4.8409 - accuracy: 0.693 - ETA: 31s - loss: 4.8400 - accuracy: 0.693 - ETA: 31s - loss: 4.8394 - accuracy: 0.693 - ETA: 30s - loss: 4.8380 - accuracy: 0.693 - ETA: 30s - loss: 4.8390 - accuracy: 0.693 - ETA: 30s - loss: 4.8396 - accuracy: 0.693 - ETA: 29s - loss: 4.8404 - accuracy: 0.693 - ETA: 29s - loss: 4.8398 - accuracy: 0.693 - ETA: 29s - loss: 4.8409 - accuracy: 0.693 - ETA: 29s - loss: 4.8398 - accuracy: 0.694 - ETA: 28s - loss: 4.8405 - accuracy: 0.694 - ETA: 28s - loss: 4.8399 - accuracy: 0.694 - ETA: 28s - loss: 4.8392 - accuracy: 0.694 - ETA: 28s - loss: 4.8393 - accuracy: 0.694 - ETA: 27s - loss: 4.8372 - accuracy: 0.694 - ETA: 27s - loss: 4.8365 - accuracy: 0.694 - ETA: 27s - loss: 4.8382 - accuracy: 0.694 - ETA: 26s - loss: 4.8370 - accuracy: 0.694 - ETA: 26s - loss: 4.8363 - accuracy: 0.694 - ETA: 26s - loss: 4.8341 - accuracy: 0.695 - ETA: 26s - loss: 4.8343 - accuracy: 0.695 - ETA: 25s - loss: 4.8339 - accuracy: 0.695 - ETA: 25s - loss: 4.8338 - accuracy: 0.695 - ETA: 25s - loss: 4.8307 - accuracy: 0.695 - ETA: 24s - loss: 4.8298 - accuracy: 0.695 - ETA: 24s - loss: 4.8316 - accuracy: 0.695 - ETA: 24s - loss: 4.8337 - accuracy: 0.695 - ETA: 24s - loss: 4.8331 - accuracy: 0.694 - ETA: 23s - loss: 4.8321 - accuracy: 0.694 - ETA: 23s - loss: 4.8301 - accuracy: 0.694 - ETA: 23s - loss: 4.8308 - accuracy: 0.694 - ETA: 23s - loss: 4.8312 - accuracy: 0.694 - ETA: 22s - loss: 4.8298 - accuracy: 0.695 - ETA: 22s - loss: 4.8298 - accuracy: 0.694 - ETA: 22s - loss: 4.8290 - accuracy: 0.694 - ETA: 21s - loss: 4.8305 - accuracy: 0.694 - ETA: 21s - loss: 4.8292 - accuracy: 0.694 - ETA: 21s - loss: 4.8284 - accuracy: 0.694 - ETA: 21s - loss: 4.8268 - accuracy: 0.694 - ETA: 20s - loss: 4.8251 - accuracy: 0.695 - ETA: 20s - loss: 4.8266 - accuracy: 0.695 - ETA: 20s - loss: 4.8266 - accuracy: 0.695 - ETA: 20s - loss: 4.8268 - accuracy: 0.694 - ETA: 19s - loss: 4.8278 - accuracy: 0.695 - ETA: 19s - loss: 4.8291 - accuracy: 0.694 - ETA: 19s - loss: 4.8269 - accuracy: 0.695 - ETA: 18s - loss: 4.8270 - accuracy: 0.695 - ETA: 18s - loss: 4.8276 - accuracy: 0.694 - ETA: 18s - loss: 4.8265 - accuracy: 0.6950"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - ETA: 18s - loss: 4.8256 - accuracy: 0.695 - ETA: 17s - loss: 4.8244 - accuracy: 0.694 - ETA: 17s - loss: 4.8260 - accuracy: 0.695 - ETA: 17s - loss: 4.8259 - accuracy: 0.694 - ETA: 17s - loss: 4.8263 - accuracy: 0.695 - ETA: 16s - loss: 4.8267 - accuracy: 0.694 - ETA: 16s - loss: 4.8259 - accuracy: 0.694 - ETA: 16s - loss: 4.8250 - accuracy: 0.694 - ETA: 15s - loss: 4.8252 - accuracy: 0.694 - ETA: 15s - loss: 4.8253 - accuracy: 0.694 - ETA: 15s - loss: 4.8247 - accuracy: 0.694 - ETA: 15s - loss: 4.8245 - accuracy: 0.694 - ETA: 14s - loss: 4.8249 - accuracy: 0.694 - ETA: 14s - loss: 4.8231 - accuracy: 0.694 - ETA: 14s - loss: 4.8218 - accuracy: 0.694 - ETA: 13s - loss: 4.8203 - accuracy: 0.694 - ETA: 13s - loss: 4.8187 - accuracy: 0.694 - ETA: 13s - loss: 4.8175 - accuracy: 0.693 - ETA: 13s - loss: 4.8160 - accuracy: 0.693 - ETA: 12s - loss: 4.8145 - accuracy: 0.694 - ETA: 12s - loss: 4.8135 - accuracy: 0.694 - ETA: 12s - loss: 4.8130 - accuracy: 0.694 - ETA: 12s - loss: 4.8110 - accuracy: 0.694 - ETA: 11s - loss: 4.8094 - accuracy: 0.694 - ETA: 11s - loss: 4.8106 - accuracy: 0.694 - ETA: 11s - loss: 4.8110 - accuracy: 0.694 - ETA: 10s - loss: 4.8095 - accuracy: 0.694 - ETA: 10s - loss: 4.8102 - accuracy: 0.694 - ETA: 10s - loss: 4.8097 - accuracy: 0.694 - ETA: 10s - loss: 4.8084 - accuracy: 0.694 - ETA: 9s - loss: 4.8083 - accuracy: 0.694 - ETA: 9s - loss: 4.8096 - accuracy: 0.69 - ETA: 9s - loss: 4.8096 - accuracy: 0.69 - ETA: 9s - loss: 4.8122 - accuracy: 0.69 - ETA: 8s - loss: 4.8118 - accuracy: 0.69 - ETA: 8s - loss: 4.8109 - accuracy: 0.69 - ETA: 8s - loss: 4.8121 - accuracy: 0.69 - ETA: 7s - loss: 4.8121 - accuracy: 0.69 - ETA: 7s - loss: 4.8137 - accuracy: 0.69 - ETA: 7s - loss: 4.8153 - accuracy: 0.69 - ETA: 7s - loss: 4.8160 - accuracy: 0.69 - ETA: 6s - loss: 4.8166 - accuracy: 0.69 - ETA: 6s - loss: 4.8166 - accuracy: 0.69 - ETA: 6s - loss: 4.8159 - accuracy: 0.69 - ETA: 6s - loss: 4.8161 - accuracy: 0.69 - ETA: 5s - loss: 4.8156 - accuracy: 0.69 - ETA: 5s - loss: 4.8163 - accuracy: 0.69 - ETA: 5s - loss: 4.8165 - accuracy: 0.69 - ETA: 4s - loss: 4.8158 - accuracy: 0.69 - ETA: 4s - loss: 4.8163 - accuracy: 0.69 - ETA: 4s - loss: 4.8169 - accuracy: 0.69 - ETA: 4s - loss: 4.8180 - accuracy: 0.69 - ETA: 3s - loss: 4.8164 - accuracy: 0.69 - ETA: 3s - loss: 4.8147 - accuracy: 0.69 - ETA: 3s - loss: 4.8137 - accuracy: 0.69 - ETA: 3s - loss: 4.8137 - accuracy: 0.69 - ETA: 2s - loss: 4.8118 - accuracy: 0.69 - ETA: 2s - loss: 4.8127 - accuracy: 0.69 - ETA: 2s - loss: 4.8131 - accuracy: 0.69 - ETA: 1s - loss: 4.8128 - accuracy: 0.69 - ETA: 1s - loss: 4.8129 - accuracy: 0.69 - ETA: 1s - loss: 4.8121 - accuracy: 0.69 - ETA: 1s - loss: 4.8136 - accuracy: 0.69 - ETA: 0s - loss: 4.8158 - accuracy: 0.69 - ETA: 0s - loss: 4.8164 - accuracy: 0.69 - ETA: 0s - loss: 4.8163 - accuracy: 0.69 - 171s 9ms/step - loss: 4.8170 - accuracy: 0.6923\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5952/20000 [=======>......................] - ETA: 2:51 - loss: 5.2402 - accuracy: 0.71 - ETA: 2:49 - loss: 4.7774 - accuracy: 0.60 - ETA: 2:48 - loss: 4.9516 - accuracy: 0.61 - ETA: 2:47 - loss: 4.7833 - accuracy: 0.63 - ETA: 2:47 - loss: 4.7163 - accuracy: 0.64 - ETA: 2:47 - loss: 4.6939 - accuracy: 0.64 - ETA: 2:46 - loss: 4.6074 - accuracy: 0.65 - ETA: 2:46 - loss: 4.6293 - accuracy: 0.67 - ETA: 2:46 - loss: 4.5827 - accuracy: 0.65 - ETA: 2:47 - loss: 4.6599 - accuracy: 0.66 - ETA: 2:46 - loss: 4.6289 - accuracy: 0.67 - ETA: 2:46 - loss: 4.6616 - accuracy: 0.67 - ETA: 2:45 - loss: 4.6383 - accuracy: 0.67 - ETA: 2:45 - loss: 4.5712 - accuracy: 0.68 - ETA: 2:45 - loss: 4.5658 - accuracy: 0.68 - ETA: 2:45 - loss: 4.6299 - accuracy: 0.69 - ETA: 2:44 - loss: 4.6951 - accuracy: 0.68 - ETA: 2:44 - loss: 4.6732 - accuracy: 0.69 - ETA: 2:44 - loss: 4.6358 - accuracy: 0.68 - ETA: 2:43 - loss: 4.7020 - accuracy: 0.68 - ETA: 2:43 - loss: 4.7397 - accuracy: 0.69 - ETA: 2:43 - loss: 4.7377 - accuracy: 0.69 - ETA: 2:43 - loss: 4.7494 - accuracy: 0.69 - ETA: 2:42 - loss: 4.7489 - accuracy: 0.69 - ETA: 2:42 - loss: 4.7329 - accuracy: 0.69 - ETA: 2:42 - loss: 4.7319 - accuracy: 0.69 - ETA: 2:41 - loss: 4.7812 - accuracy: 0.69 - ETA: 2:41 - loss: 4.7750 - accuracy: 0.69 - ETA: 2:41 - loss: 4.7642 - accuracy: 0.69 - ETA: 2:41 - loss: 4.7803 - accuracy: 0.69 - ETA: 2:40 - loss: 4.7883 - accuracy: 0.69 - ETA: 2:40 - loss: 4.7929 - accuracy: 0.69 - ETA: 2:40 - loss: 4.7952 - accuracy: 0.69 - ETA: 2:40 - loss: 4.7929 - accuracy: 0.69 - ETA: 2:39 - loss: 4.8063 - accuracy: 0.69 - ETA: 2:39 - loss: 4.7812 - accuracy: 0.69 - ETA: 2:39 - loss: 4.7822 - accuracy: 0.69 - ETA: 2:38 - loss: 4.7420 - accuracy: 0.69 - ETA: 2:38 - loss: 4.7166 - accuracy: 0.69 - ETA: 2:38 - loss: 4.7140 - accuracy: 0.69 - ETA: 2:38 - loss: 4.7044 - accuracy: 0.69 - ETA: 2:37 - loss: 4.6963 - accuracy: 0.69 - ETA: 2:37 - loss: 4.6996 - accuracy: 0.68 - ETA: 2:37 - loss: 4.7097 - accuracy: 0.68 - ETA: 2:37 - loss: 4.6865 - accuracy: 0.68 - ETA: 2:36 - loss: 4.7015 - accuracy: 0.68 - ETA: 2:36 - loss: 4.6939 - accuracy: 0.68 - ETA: 2:36 - loss: 4.6864 - accuracy: 0.68 - ETA: 2:35 - loss: 4.7041 - accuracy: 0.68 - ETA: 2:35 - loss: 4.7038 - accuracy: 0.68 - ETA: 2:35 - loss: 4.6999 - accuracy: 0.68 - ETA: 2:34 - loss: 4.7135 - accuracy: 0.68 - ETA: 2:34 - loss: 4.6959 - accuracy: 0.68 - ETA: 2:34 - loss: 4.6977 - accuracy: 0.68 - ETA: 2:34 - loss: 4.6740 - accuracy: 0.68 - ETA: 2:33 - loss: 4.6694 - accuracy: 0.69 - ETA: 2:33 - loss: 4.6882 - accuracy: 0.69 - ETA: 2:33 - loss: 4.6846 - accuracy: 0.68 - ETA: 2:32 - loss: 4.7157 - accuracy: 0.68 - ETA: 2:32 - loss: 4.7131 - accuracy: 0.69 - ETA: 2:32 - loss: 4.7164 - accuracy: 0.69 - ETA: 2:32 - loss: 4.7263 - accuracy: 0.69 - ETA: 2:31 - loss: 4.7228 - accuracy: 0.68 - ETA: 2:31 - loss: 4.7073 - accuracy: 0.68 - ETA: 2:31 - loss: 4.7163 - accuracy: 0.69 - ETA: 2:30 - loss: 4.7209 - accuracy: 0.68 - ETA: 2:30 - loss: 4.7200 - accuracy: 0.68 - ETA: 2:30 - loss: 4.7371 - accuracy: 0.68 - ETA: 2:30 - loss: 4.7337 - accuracy: 0.68 - ETA: 2:29 - loss: 4.7326 - accuracy: 0.68 - ETA: 2:29 - loss: 4.7301 - accuracy: 0.68 - ETA: 2:29 - loss: 4.7352 - accuracy: 0.68 - ETA: 2:29 - loss: 4.7327 - accuracy: 0.68 - ETA: 2:28 - loss: 4.7274 - accuracy: 0.68 - ETA: 2:28 - loss: 4.7241 - accuracy: 0.68 - ETA: 2:28 - loss: 4.7152 - accuracy: 0.69 - ETA: 2:27 - loss: 4.7150 - accuracy: 0.69 - ETA: 2:27 - loss: 4.7421 - accuracy: 0.69 - ETA: 2:27 - loss: 4.7410 - accuracy: 0.69 - ETA: 2:27 - loss: 4.7532 - accuracy: 0.69 - ETA: 2:26 - loss: 4.7583 - accuracy: 0.69 - ETA: 2:26 - loss: 4.7497 - accuracy: 0.69 - ETA: 2:26 - loss: 4.7470 - accuracy: 0.69 - ETA: 2:26 - loss: 4.7465 - accuracy: 0.69 - ETA: 2:25 - loss: 4.7379 - accuracy: 0.69 - ETA: 2:25 - loss: 4.7382 - accuracy: 0.69 - ETA: 2:25 - loss: 4.7354 - accuracy: 0.69 - ETA: 2:25 - loss: 4.7272 - accuracy: 0.69 - ETA: 2:24 - loss: 4.7203 - accuracy: 0.69 - ETA: 2:24 - loss: 4.7360 - accuracy: 0.69 - ETA: 2:24 - loss: 4.7393 - accuracy: 0.69 - ETA: 2:24 - loss: 4.7428 - accuracy: 0.69 - ETA: 2:23 - loss: 4.7539 - accuracy: 0.69 - ETA: 2:23 - loss: 4.7527 - accuracy: 0.69 - ETA: 2:23 - loss: 4.7495 - accuracy: 0.69 - ETA: 2:23 - loss: 4.7540 - accuracy: 0.69 - ETA: 2:22 - loss: 4.7582 - accuracy: 0.69 - ETA: 2:22 - loss: 4.7608 - accuracy: 0.69 - ETA: 2:22 - loss: 4.7576 - accuracy: 0.69 - ETA: 2:22 - loss: 4.7547 - accuracy: 0.69 - ETA: 2:21 - loss: 4.7543 - accuracy: 0.69 - ETA: 2:21 - loss: 4.7536 - accuracy: 0.69 - ETA: 2:21 - loss: 4.7614 - accuracy: 0.69 - ETA: 2:21 - loss: 4.7579 - accuracy: 0.69 - ETA: 2:20 - loss: 4.7608 - accuracy: 0.69 - ETA: 2:20 - loss: 4.7562 - accuracy: 0.69 - ETA: 2:20 - loss: 4.7591 - accuracy: 0.69 - ETA: 2:20 - loss: 4.7667 - accuracy: 0.68 - ETA: 2:19 - loss: 4.7603 - accuracy: 0.68 - ETA: 2:19 - loss: 4.7575 - accuracy: 0.68 - ETA: 2:19 - loss: 4.7572 - accuracy: 0.68 - ETA: 2:19 - loss: 4.7566 - accuracy: 0.68 - ETA: 2:18 - loss: 4.7520 - accuracy: 0.68 - ETA: 2:18 - loss: 4.7484 - accuracy: 0.68 - ETA: 2:18 - loss: 4.7397 - accuracy: 0.68 - ETA: 2:17 - loss: 4.7395 - accuracy: 0.68 - ETA: 2:17 - loss: 4.7405 - accuracy: 0.68 - ETA: 2:17 - loss: 4.7467 - accuracy: 0.68 - ETA: 2:17 - loss: 4.7478 - accuracy: 0.68 - ETA: 2:16 - loss: 4.7506 - accuracy: 0.68 - ETA: 2:16 - loss: 4.7393 - accuracy: 0.69 - ETA: 2:16 - loss: 4.7315 - accuracy: 0.69 - ETA: 2:16 - loss: 4.7336 - accuracy: 0.69 - ETA: 2:15 - loss: 4.7355 - accuracy: 0.68 - ETA: 2:15 - loss: 4.7358 - accuracy: 0.68 - ETA: 2:15 - loss: 4.7318 - accuracy: 0.68 - ETA: 2:15 - loss: 4.7242 - accuracy: 0.68 - ETA: 2:14 - loss: 4.7258 - accuracy: 0.68 - ETA: 2:14 - loss: 4.7163 - accuracy: 0.68 - ETA: 2:14 - loss: 4.7264 - accuracy: 0.68 - ETA: 2:13 - loss: 4.7275 - accuracy: 0.68 - ETA: 2:13 - loss: 4.7335 - accuracy: 0.68 - ETA: 2:13 - loss: 4.7363 - accuracy: 0.68 - ETA: 2:13 - loss: 4.7417 - accuracy: 0.68 - ETA: 2:12 - loss: 4.7379 - accuracy: 0.68 - ETA: 2:12 - loss: 4.7427 - accuracy: 0.68 - ETA: 2:12 - loss: 4.7462 - accuracy: 0.68 - ETA: 2:12 - loss: 4.7438 - accuracy: 0.68 - ETA: 2:11 - loss: 4.7387 - accuracy: 0.68 - ETA: 2:11 - loss: 4.7347 - accuracy: 0.68 - ETA: 2:11 - loss: 4.7331 - accuracy: 0.68 - ETA: 2:11 - loss: 4.7313 - accuracy: 0.68 - ETA: 2:10 - loss: 4.7292 - accuracy: 0.68 - ETA: 2:10 - loss: 4.7359 - accuracy: 0.68 - ETA: 2:10 - loss: 4.7395 - accuracy: 0.68 - ETA: 2:09 - loss: 4.7343 - accuracy: 0.68 - ETA: 2:09 - loss: 4.7315 - accuracy: 0.68 - ETA: 2:09 - loss: 4.7291 - accuracy: 0.68 - ETA: 2:09 - loss: 4.7297 - accuracy: 0.68 - ETA: 2:08 - loss: 4.7307 - accuracy: 0.68 - ETA: 2:08 - loss: 4.7257 - accuracy: 0.68 - ETA: 2:08 - loss: 4.7227 - accuracy: 0.68 - ETA: 2:08 - loss: 4.7236 - accuracy: 0.68 - ETA: 2:07 - loss: 4.7269 - accuracy: 0.68 - ETA: 2:07 - loss: 4.7217 - accuracy: 0.68 - ETA: 2:07 - loss: 4.7206 - accuracy: 0.68 - ETA: 2:07 - loss: 4.7188 - accuracy: 0.68 - ETA: 2:06 - loss: 4.7234 - accuracy: 0.68 - ETA: 2:06 - loss: 4.7247 - accuracy: 0.68 - ETA: 2:06 - loss: 4.7277 - accuracy: 0.68 - ETA: 2:05 - loss: 4.7311 - accuracy: 0.68 - ETA: 2:05 - loss: 4.7308 - accuracy: 0.68 - ETA: 2:05 - loss: 4.7325 - accuracy: 0.68 - ETA: 2:05 - loss: 4.7309 - accuracy: 0.68 - ETA: 2:04 - loss: 4.7270 - accuracy: 0.68 - ETA: 2:04 - loss: 4.7298 - accuracy: 0.68 - ETA: 2:04 - loss: 4.7319 - accuracy: 0.68 - ETA: 2:04 - loss: 4.7281 - accuracy: 0.68 - ETA: 2:03 - loss: 4.7341 - accuracy: 0.68 - ETA: 2:03 - loss: 4.7318 - accuracy: 0.68 - ETA: 2:03 - loss: 4.7356 - accuracy: 0.68 - ETA: 2:03 - loss: 4.7324 - accuracy: 0.68 - ETA: 2:02 - loss: 4.7300 - accuracy: 0.68 - ETA: 2:02 - loss: 4.7357 - accuracy: 0.68 - ETA: 2:02 - loss: 4.7350 - accuracy: 0.68 - ETA: 2:01 - loss: 4.7382 - accuracy: 0.68 - ETA: 2:01 - loss: 4.7381 - accuracy: 0.68 - ETA: 2:01 - loss: 4.7420 - accuracy: 0.68 - ETA: 2:01 - loss: 4.7498 - accuracy: 0.68 - ETA: 2:00 - loss: 4.7520 - accuracy: 0.68 - ETA: 2:00 - loss: 4.7462 - accuracy: 0.68 - ETA: 2:00 - loss: 4.7458 - accuracy: 0.68 - ETA: 2:00 - loss: 4.7469 - accuracy: 0.68 - ETA: 1:59 - loss: 4.7453 - accuracy: 0.68 - ETA: 1:59 - loss: 4.7537 - accuracy: 0.68 - ETA: 1:59 - loss: 4.7532 - accuracy: 0.6868"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/20000 [================>.............] - ETA: 1:59 - loss: 4.7558 - accuracy: 0.68 - ETA: 1:58 - loss: 4.7573 - accuracy: 0.68 - ETA: 1:58 - loss: 4.7554 - accuracy: 0.68 - ETA: 1:58 - loss: 4.7547 - accuracy: 0.68 - ETA: 1:57 - loss: 4.7569 - accuracy: 0.68 - ETA: 1:57 - loss: 4.7588 - accuracy: 0.68 - ETA: 1:57 - loss: 4.7546 - accuracy: 0.68 - ETA: 1:57 - loss: 4.7561 - accuracy: 0.68 - ETA: 1:56 - loss: 4.7587 - accuracy: 0.68 - ETA: 1:56 - loss: 4.7548 - accuracy: 0.68 - ETA: 1:56 - loss: 4.7555 - accuracy: 0.68 - ETA: 1:56 - loss: 4.7617 - accuracy: 0.68 - ETA: 1:55 - loss: 4.7668 - accuracy: 0.68 - ETA: 1:55 - loss: 4.7609 - accuracy: 0.68 - ETA: 1:55 - loss: 4.7617 - accuracy: 0.68 - ETA: 1:54 - loss: 4.7612 - accuracy: 0.68 - ETA: 1:54 - loss: 4.7600 - accuracy: 0.68 - ETA: 1:54 - loss: 4.7606 - accuracy: 0.68 - ETA: 1:54 - loss: 4.7579 - accuracy: 0.68 - ETA: 1:53 - loss: 4.7571 - accuracy: 0.68 - ETA: 1:53 - loss: 4.7531 - accuracy: 0.68 - ETA: 1:53 - loss: 4.7489 - accuracy: 0.68 - ETA: 1:53 - loss: 4.7511 - accuracy: 0.68 - ETA: 1:52 - loss: 4.7505 - accuracy: 0.68 - ETA: 1:52 - loss: 4.7573 - accuracy: 0.68 - ETA: 1:52 - loss: 4.7544 - accuracy: 0.68 - ETA: 1:51 - loss: 4.7574 - accuracy: 0.68 - ETA: 1:51 - loss: 4.7599 - accuracy: 0.68 - ETA: 1:51 - loss: 4.7577 - accuracy: 0.68 - ETA: 1:51 - loss: 4.7537 - accuracy: 0.68 - ETA: 1:50 - loss: 4.7543 - accuracy: 0.68 - ETA: 1:50 - loss: 4.7552 - accuracy: 0.68 - ETA: 1:50 - loss: 4.7565 - accuracy: 0.68 - ETA: 1:50 - loss: 4.7623 - accuracy: 0.68 - ETA: 1:49 - loss: 4.7604 - accuracy: 0.68 - ETA: 1:49 - loss: 4.7629 - accuracy: 0.68 - ETA: 1:49 - loss: 4.7660 - accuracy: 0.68 - ETA: 1:48 - loss: 4.7643 - accuracy: 0.68 - ETA: 1:48 - loss: 4.7630 - accuracy: 0.68 - ETA: 1:48 - loss: 4.7661 - accuracy: 0.68 - ETA: 1:48 - loss: 4.7630 - accuracy: 0.68 - ETA: 1:47 - loss: 4.7671 - accuracy: 0.68 - ETA: 1:47 - loss: 4.7699 - accuracy: 0.68 - ETA: 1:47 - loss: 4.7673 - accuracy: 0.68 - ETA: 1:47 - loss: 4.7669 - accuracy: 0.68 - ETA: 1:46 - loss: 4.7639 - accuracy: 0.68 - ETA: 1:46 - loss: 4.7673 - accuracy: 0.68 - ETA: 1:46 - loss: 4.7670 - accuracy: 0.68 - ETA: 1:45 - loss: 4.7651 - accuracy: 0.68 - ETA: 1:45 - loss: 4.7609 - accuracy: 0.68 - ETA: 1:45 - loss: 4.7603 - accuracy: 0.68 - ETA: 1:45 - loss: 4.7623 - accuracy: 0.68 - ETA: 1:44 - loss: 4.7596 - accuracy: 0.68 - ETA: 1:44 - loss: 4.7631 - accuracy: 0.68 - ETA: 1:44 - loss: 4.7664 - accuracy: 0.68 - ETA: 1:44 - loss: 4.7624 - accuracy: 0.68 - ETA: 1:43 - loss: 4.7615 - accuracy: 0.68 - ETA: 1:43 - loss: 4.7651 - accuracy: 0.68 - ETA: 1:43 - loss: 4.7593 - accuracy: 0.68 - ETA: 1:42 - loss: 4.7575 - accuracy: 0.68 - ETA: 1:42 - loss: 4.7555 - accuracy: 0.68 - ETA: 1:42 - loss: 4.7586 - accuracy: 0.68 - ETA: 1:42 - loss: 4.7568 - accuracy: 0.68 - ETA: 1:41 - loss: 4.7572 - accuracy: 0.68 - ETA: 1:41 - loss: 4.7618 - accuracy: 0.68 - ETA: 1:41 - loss: 4.7597 - accuracy: 0.68 - ETA: 1:41 - loss: 4.7632 - accuracy: 0.68 - ETA: 1:40 - loss: 4.7615 - accuracy: 0.68 - ETA: 1:40 - loss: 4.7609 - accuracy: 0.68 - ETA: 1:40 - loss: 4.7572 - accuracy: 0.68 - ETA: 1:40 - loss: 4.7554 - accuracy: 0.68 - ETA: 1:39 - loss: 4.7537 - accuracy: 0.68 - ETA: 1:39 - loss: 4.7522 - accuracy: 0.68 - ETA: 1:39 - loss: 4.7580 - accuracy: 0.68 - ETA: 1:38 - loss: 4.7603 - accuracy: 0.68 - ETA: 1:38 - loss: 4.7566 - accuracy: 0.68 - ETA: 1:38 - loss: 4.7548 - accuracy: 0.68 - ETA: 1:38 - loss: 4.7593 - accuracy: 0.68 - ETA: 1:37 - loss: 4.7579 - accuracy: 0.68 - ETA: 1:37 - loss: 4.7585 - accuracy: 0.68 - ETA: 1:37 - loss: 4.7593 - accuracy: 0.68 - ETA: 1:37 - loss: 4.7550 - accuracy: 0.68 - ETA: 1:36 - loss: 4.7556 - accuracy: 0.68 - ETA: 1:36 - loss: 4.7564 - accuracy: 0.68 - ETA: 1:36 - loss: 4.7599 - accuracy: 0.68 - ETA: 1:35 - loss: 4.7603 - accuracy: 0.68 - ETA: 1:35 - loss: 4.7624 - accuracy: 0.68 - ETA: 1:35 - loss: 4.7616 - accuracy: 0.68 - ETA: 1:35 - loss: 4.7616 - accuracy: 0.68 - ETA: 1:34 - loss: 4.7626 - accuracy: 0.68 - ETA: 1:34 - loss: 4.7668 - accuracy: 0.68 - ETA: 1:34 - loss: 4.7661 - accuracy: 0.68 - ETA: 1:34 - loss: 4.7662 - accuracy: 0.68 - ETA: 1:33 - loss: 4.7647 - accuracy: 0.68 - ETA: 1:33 - loss: 4.7668 - accuracy: 0.68 - ETA: 1:33 - loss: 4.7664 - accuracy: 0.68 - ETA: 1:32 - loss: 4.7668 - accuracy: 0.68 - ETA: 1:32 - loss: 4.7658 - accuracy: 0.68 - ETA: 1:32 - loss: 4.7627 - accuracy: 0.68 - ETA: 1:32 - loss: 4.7677 - accuracy: 0.68 - ETA: 1:31 - loss: 4.7663 - accuracy: 0.68 - ETA: 1:31 - loss: 4.7686 - accuracy: 0.68 - ETA: 1:31 - loss: 4.7644 - accuracy: 0.68 - ETA: 1:31 - loss: 4.7623 - accuracy: 0.68 - ETA: 1:30 - loss: 4.7642 - accuracy: 0.68 - ETA: 1:30 - loss: 4.7634 - accuracy: 0.68 - ETA: 1:30 - loss: 4.7676 - accuracy: 0.68 - ETA: 1:29 - loss: 4.7670 - accuracy: 0.68 - ETA: 1:29 - loss: 4.7673 - accuracy: 0.68 - ETA: 1:29 - loss: 4.7708 - accuracy: 0.68 - ETA: 1:29 - loss: 4.7696 - accuracy: 0.68 - ETA: 1:28 - loss: 4.7701 - accuracy: 0.68 - ETA: 1:28 - loss: 4.7675 - accuracy: 0.68 - ETA: 1:28 - loss: 4.7632 - accuracy: 0.68 - ETA: 1:28 - loss: 4.7627 - accuracy: 0.68 - ETA: 1:27 - loss: 4.7633 - accuracy: 0.68 - ETA: 1:27 - loss: 4.7638 - accuracy: 0.68 - ETA: 1:27 - loss: 4.7639 - accuracy: 0.68 - ETA: 1:27 - loss: 4.7667 - accuracy: 0.68 - ETA: 1:26 - loss: 4.7652 - accuracy: 0.68 - ETA: 1:26 - loss: 4.7612 - accuracy: 0.68 - ETA: 1:26 - loss: 4.7584 - accuracy: 0.68 - ETA: 1:25 - loss: 4.7622 - accuracy: 0.68 - ETA: 1:25 - loss: 4.7628 - accuracy: 0.68 - ETA: 1:25 - loss: 4.7608 - accuracy: 0.68 - ETA: 1:25 - loss: 4.7593 - accuracy: 0.68 - ETA: 1:24 - loss: 4.7581 - accuracy: 0.68 - ETA: 1:24 - loss: 4.7558 - accuracy: 0.68 - ETA: 1:24 - loss: 4.7538 - accuracy: 0.68 - ETA: 1:24 - loss: 4.7527 - accuracy: 0.68 - ETA: 1:23 - loss: 4.7508 - accuracy: 0.68 - ETA: 1:23 - loss: 4.7502 - accuracy: 0.68 - ETA: 1:23 - loss: 4.7489 - accuracy: 0.68 - ETA: 1:22 - loss: 4.7519 - accuracy: 0.68 - ETA: 1:22 - loss: 4.7538 - accuracy: 0.68 - ETA: 1:22 - loss: 4.7563 - accuracy: 0.68 - ETA: 1:22 - loss: 4.7548 - accuracy: 0.68 - ETA: 1:21 - loss: 4.7527 - accuracy: 0.68 - ETA: 1:21 - loss: 4.7511 - accuracy: 0.68 - ETA: 1:21 - loss: 4.7489 - accuracy: 0.68 - ETA: 1:21 - loss: 4.7480 - accuracy: 0.68 - ETA: 1:20 - loss: 4.7483 - accuracy: 0.68 - ETA: 1:20 - loss: 4.7487 - accuracy: 0.68 - ETA: 1:20 - loss: 4.7494 - accuracy: 0.68 - ETA: 1:19 - loss: 4.7516 - accuracy: 0.68 - ETA: 1:19 - loss: 4.7500 - accuracy: 0.68 - ETA: 1:19 - loss: 4.7496 - accuracy: 0.68 - ETA: 1:19 - loss: 4.7515 - accuracy: 0.68 - ETA: 1:18 - loss: 4.7509 - accuracy: 0.68 - ETA: 1:18 - loss: 4.7502 - accuracy: 0.68 - ETA: 1:18 - loss: 4.7507 - accuracy: 0.68 - ETA: 1:18 - loss: 4.7523 - accuracy: 0.68 - ETA: 1:17 - loss: 4.7513 - accuracy: 0.68 - ETA: 1:17 - loss: 4.7475 - accuracy: 0.68 - ETA: 1:17 - loss: 4.7454 - accuracy: 0.68 - ETA: 1:16 - loss: 4.7460 - accuracy: 0.68 - ETA: 1:16 - loss: 4.7480 - accuracy: 0.68 - ETA: 1:16 - loss: 4.7469 - accuracy: 0.68 - ETA: 1:16 - loss: 4.7459 - accuracy: 0.68 - ETA: 1:15 - loss: 4.7443 - accuracy: 0.68 - ETA: 1:15 - loss: 4.7434 - accuracy: 0.68 - ETA: 1:15 - loss: 4.7434 - accuracy: 0.68 - ETA: 1:15 - loss: 4.7452 - accuracy: 0.68 - ETA: 1:14 - loss: 4.7455 - accuracy: 0.68 - ETA: 1:14 - loss: 4.7440 - accuracy: 0.68 - ETA: 1:14 - loss: 4.7416 - accuracy: 0.68 - ETA: 1:13 - loss: 4.7404 - accuracy: 0.68 - ETA: 1:13 - loss: 4.7390 - accuracy: 0.68 - ETA: 1:13 - loss: 4.7389 - accuracy: 0.68 - ETA: 1:13 - loss: 4.7362 - accuracy: 0.68 - ETA: 1:12 - loss: 4.7371 - accuracy: 0.68 - ETA: 1:12 - loss: 4.7378 - accuracy: 0.68 - ETA: 1:12 - loss: 4.7395 - accuracy: 0.68 - ETA: 1:12 - loss: 4.7367 - accuracy: 0.68 - ETA: 1:11 - loss: 4.7355 - accuracy: 0.68 - ETA: 1:11 - loss: 4.7360 - accuracy: 0.68 - ETA: 1:11 - loss: 4.7383 - accuracy: 0.68 - ETA: 1:10 - loss: 4.7373 - accuracy: 0.68 - ETA: 1:10 - loss: 4.7374 - accuracy: 0.68 - ETA: 1:10 - loss: 4.7374 - accuracy: 0.68 - ETA: 1:10 - loss: 4.7364 - accuracy: 0.68 - ETA: 1:09 - loss: 4.7352 - accuracy: 0.68 - ETA: 1:09 - loss: 4.7330 - accuracy: 0.68 - ETA: 1:09 - loss: 4.7333 - accuracy: 0.68 - ETA: 1:09 - loss: 4.7305 - accuracy: 0.68 - ETA: 1:08 - loss: 4.7314 - accuracy: 0.6902"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17856/20000 [=========================>....] - ETA: 1:08 - loss: 4.7316 - accuracy: 0.69 - ETA: 1:08 - loss: 4.7350 - accuracy: 0.69 - ETA: 1:07 - loss: 4.7387 - accuracy: 0.68 - ETA: 1:07 - loss: 4.7350 - accuracy: 0.69 - ETA: 1:07 - loss: 4.7333 - accuracy: 0.69 - ETA: 1:07 - loss: 4.7317 - accuracy: 0.69 - ETA: 1:06 - loss: 4.7296 - accuracy: 0.69 - ETA: 1:06 - loss: 4.7280 - accuracy: 0.69 - ETA: 1:06 - loss: 4.7308 - accuracy: 0.68 - ETA: 1:06 - loss: 4.7308 - accuracy: 0.69 - ETA: 1:05 - loss: 4.7321 - accuracy: 0.69 - ETA: 1:05 - loss: 4.7319 - accuracy: 0.69 - ETA: 1:05 - loss: 4.7303 - accuracy: 0.69 - ETA: 1:04 - loss: 4.7327 - accuracy: 0.69 - ETA: 1:04 - loss: 4.7327 - accuracy: 0.69 - ETA: 1:04 - loss: 4.7346 - accuracy: 0.68 - ETA: 1:04 - loss: 4.7338 - accuracy: 0.68 - ETA: 1:03 - loss: 4.7343 - accuracy: 0.68 - ETA: 1:03 - loss: 4.7331 - accuracy: 0.68 - ETA: 1:03 - loss: 4.7320 - accuracy: 0.68 - ETA: 1:03 - loss: 4.7304 - accuracy: 0.68 - ETA: 1:02 - loss: 4.7297 - accuracy: 0.68 - ETA: 1:02 - loss: 4.7281 - accuracy: 0.68 - ETA: 1:02 - loss: 4.7268 - accuracy: 0.68 - ETA: 1:01 - loss: 4.7251 - accuracy: 0.69 - ETA: 1:01 - loss: 4.7260 - accuracy: 0.69 - ETA: 1:01 - loss: 4.7257 - accuracy: 0.69 - ETA: 1:01 - loss: 4.7294 - accuracy: 0.69 - ETA: 1:00 - loss: 4.7304 - accuracy: 0.69 - ETA: 1:00 - loss: 4.7302 - accuracy: 0.69 - ETA: 1:00 - loss: 4.7289 - accuracy: 0.69 - ETA: 1:00 - loss: 4.7282 - accuracy: 0.69 - ETA: 59s - loss: 4.7309 - accuracy: 0.6909 - ETA: 59s - loss: 4.7311 - accuracy: 0.690 - ETA: 59s - loss: 4.7296 - accuracy: 0.690 - ETA: 58s - loss: 4.7323 - accuracy: 0.690 - ETA: 58s - loss: 4.7297 - accuracy: 0.690 - ETA: 58s - loss: 4.7296 - accuracy: 0.690 - ETA: 58s - loss: 4.7300 - accuracy: 0.689 - ETA: 57s - loss: 4.7302 - accuracy: 0.689 - ETA: 57s - loss: 4.7314 - accuracy: 0.689 - ETA: 57s - loss: 4.7299 - accuracy: 0.689 - ETA: 57s - loss: 4.7286 - accuracy: 0.689 - ETA: 56s - loss: 4.7284 - accuracy: 0.690 - ETA: 56s - loss: 4.7294 - accuracy: 0.690 - ETA: 56s - loss: 4.7307 - accuracy: 0.690 - ETA: 55s - loss: 4.7312 - accuracy: 0.690 - ETA: 55s - loss: 4.7302 - accuracy: 0.690 - ETA: 55s - loss: 4.7289 - accuracy: 0.690 - ETA: 55s - loss: 4.7274 - accuracy: 0.690 - ETA: 54s - loss: 4.7270 - accuracy: 0.690 - ETA: 54s - loss: 4.7265 - accuracy: 0.690 - ETA: 54s - loss: 4.7255 - accuracy: 0.690 - ETA: 54s - loss: 4.7258 - accuracy: 0.690 - ETA: 53s - loss: 4.7228 - accuracy: 0.690 - ETA: 53s - loss: 4.7220 - accuracy: 0.690 - ETA: 53s - loss: 4.7225 - accuracy: 0.690 - ETA: 52s - loss: 4.7224 - accuracy: 0.690 - ETA: 52s - loss: 4.7209 - accuracy: 0.690 - ETA: 52s - loss: 4.7187 - accuracy: 0.690 - ETA: 52s - loss: 4.7183 - accuracy: 0.690 - ETA: 51s - loss: 4.7182 - accuracy: 0.689 - ETA: 51s - loss: 4.7218 - accuracy: 0.689 - ETA: 51s - loss: 4.7207 - accuracy: 0.689 - ETA: 51s - loss: 4.7183 - accuracy: 0.689 - ETA: 50s - loss: 4.7197 - accuracy: 0.689 - ETA: 50s - loss: 4.7195 - accuracy: 0.689 - ETA: 50s - loss: 4.7181 - accuracy: 0.689 - ETA: 49s - loss: 4.7166 - accuracy: 0.689 - ETA: 49s - loss: 4.7154 - accuracy: 0.689 - ETA: 49s - loss: 4.7143 - accuracy: 0.690 - ETA: 49s - loss: 4.7138 - accuracy: 0.690 - ETA: 48s - loss: 4.7132 - accuracy: 0.690 - ETA: 48s - loss: 4.7136 - accuracy: 0.690 - ETA: 48s - loss: 4.7137 - accuracy: 0.690 - ETA: 48s - loss: 4.7153 - accuracy: 0.690 - ETA: 47s - loss: 4.7128 - accuracy: 0.689 - ETA: 47s - loss: 4.7152 - accuracy: 0.690 - ETA: 47s - loss: 4.7153 - accuracy: 0.690 - ETA: 46s - loss: 4.7147 - accuracy: 0.690 - ETA: 46s - loss: 4.7145 - accuracy: 0.690 - ETA: 46s - loss: 4.7157 - accuracy: 0.690 - ETA: 46s - loss: 4.7161 - accuracy: 0.690 - ETA: 45s - loss: 4.7192 - accuracy: 0.690 - ETA: 45s - loss: 4.7198 - accuracy: 0.690 - ETA: 45s - loss: 4.7187 - accuracy: 0.691 - ETA: 45s - loss: 4.7179 - accuracy: 0.691 - ETA: 44s - loss: 4.7183 - accuracy: 0.691 - ETA: 44s - loss: 4.7186 - accuracy: 0.692 - ETA: 44s - loss: 4.7191 - accuracy: 0.691 - ETA: 44s - loss: 4.7205 - accuracy: 0.692 - ETA: 43s - loss: 4.7219 - accuracy: 0.692 - ETA: 43s - loss: 4.7221 - accuracy: 0.692 - ETA: 43s - loss: 4.7214 - accuracy: 0.692 - ETA: 42s - loss: 4.7205 - accuracy: 0.692 - ETA: 42s - loss: 4.7203 - accuracy: 0.692 - ETA: 42s - loss: 4.7220 - accuracy: 0.692 - ETA: 42s - loss: 4.7234 - accuracy: 0.691 - ETA: 41s - loss: 4.7222 - accuracy: 0.691 - ETA: 41s - loss: 4.7235 - accuracy: 0.692 - ETA: 41s - loss: 4.7222 - accuracy: 0.692 - ETA: 41s - loss: 4.7244 - accuracy: 0.691 - ETA: 40s - loss: 4.7254 - accuracy: 0.691 - ETA: 40s - loss: 4.7251 - accuracy: 0.691 - ETA: 40s - loss: 4.7262 - accuracy: 0.692 - ETA: 39s - loss: 4.7257 - accuracy: 0.692 - ETA: 39s - loss: 4.7251 - accuracy: 0.692 - ETA: 39s - loss: 4.7251 - accuracy: 0.692 - ETA: 39s - loss: 4.7249 - accuracy: 0.692 - ETA: 38s - loss: 4.7231 - accuracy: 0.692 - ETA: 38s - loss: 4.7229 - accuracy: 0.692 - ETA: 38s - loss: 4.7225 - accuracy: 0.692 - ETA: 38s - loss: 4.7215 - accuracy: 0.692 - ETA: 37s - loss: 4.7212 - accuracy: 0.692 - ETA: 37s - loss: 4.7205 - accuracy: 0.692 - ETA: 37s - loss: 4.7214 - accuracy: 0.692 - ETA: 36s - loss: 4.7211 - accuracy: 0.692 - ETA: 36s - loss: 4.7191 - accuracy: 0.692 - ETA: 36s - loss: 4.7191 - accuracy: 0.692 - ETA: 36s - loss: 4.7179 - accuracy: 0.692 - ETA: 35s - loss: 4.7170 - accuracy: 0.692 - ETA: 35s - loss: 4.7167 - accuracy: 0.692 - ETA: 35s - loss: 4.7170 - accuracy: 0.692 - ETA: 35s - loss: 4.7183 - accuracy: 0.692 - ETA: 34s - loss: 4.7179 - accuracy: 0.692 - ETA: 34s - loss: 4.7182 - accuracy: 0.692 - ETA: 34s - loss: 4.7171 - accuracy: 0.692 - ETA: 33s - loss: 4.7188 - accuracy: 0.692 - ETA: 33s - loss: 4.7185 - accuracy: 0.692 - ETA: 33s - loss: 4.7157 - accuracy: 0.692 - ETA: 33s - loss: 4.7139 - accuracy: 0.692 - ETA: 32s - loss: 4.7136 - accuracy: 0.692 - ETA: 32s - loss: 4.7154 - accuracy: 0.692 - ETA: 32s - loss: 4.7157 - accuracy: 0.692 - ETA: 32s - loss: 4.7153 - accuracy: 0.693 - ETA: 31s - loss: 4.7158 - accuracy: 0.693 - ETA: 31s - loss: 4.7136 - accuracy: 0.693 - ETA: 31s - loss: 4.7166 - accuracy: 0.693 - ETA: 30s - loss: 4.7152 - accuracy: 0.692 - ETA: 30s - loss: 4.7165 - accuracy: 0.693 - ETA: 30s - loss: 4.7170 - accuracy: 0.693 - ETA: 30s - loss: 4.7157 - accuracy: 0.693 - ETA: 29s - loss: 4.7168 - accuracy: 0.693 - ETA: 29s - loss: 4.7161 - accuracy: 0.693 - ETA: 29s - loss: 4.7148 - accuracy: 0.693 - ETA: 29s - loss: 4.7143 - accuracy: 0.693 - ETA: 28s - loss: 4.7144 - accuracy: 0.693 - ETA: 28s - loss: 4.7172 - accuracy: 0.694 - ETA: 28s - loss: 4.7167 - accuracy: 0.693 - ETA: 27s - loss: 4.7162 - accuracy: 0.693 - ETA: 27s - loss: 4.7155 - accuracy: 0.693 - ETA: 27s - loss: 4.7157 - accuracy: 0.693 - ETA: 27s - loss: 4.7147 - accuracy: 0.693 - ETA: 26s - loss: 4.7132 - accuracy: 0.693 - ETA: 26s - loss: 4.7149 - accuracy: 0.693 - ETA: 26s - loss: 4.7158 - accuracy: 0.692 - ETA: 26s - loss: 4.7136 - accuracy: 0.692 - ETA: 25s - loss: 4.7132 - accuracy: 0.692 - ETA: 25s - loss: 4.7142 - accuracy: 0.692 - ETA: 25s - loss: 4.7137 - accuracy: 0.692 - ETA: 24s - loss: 4.7130 - accuracy: 0.692 - ETA: 24s - loss: 4.7139 - accuracy: 0.692 - ETA: 24s - loss: 4.7140 - accuracy: 0.692 - ETA: 24s - loss: 4.7172 - accuracy: 0.693 - ETA: 23s - loss: 4.7161 - accuracy: 0.693 - ETA: 23s - loss: 4.7162 - accuracy: 0.693 - ETA: 23s - loss: 4.7166 - accuracy: 0.692 - ETA: 23s - loss: 4.7159 - accuracy: 0.692 - ETA: 22s - loss: 4.7145 - accuracy: 0.693 - ETA: 22s - loss: 4.7173 - accuracy: 0.693 - ETA: 22s - loss: 4.7196 - accuracy: 0.692 - ETA: 21s - loss: 4.7194 - accuracy: 0.693 - ETA: 21s - loss: 4.7193 - accuracy: 0.693 - ETA: 21s - loss: 4.7177 - accuracy: 0.693 - ETA: 21s - loss: 4.7186 - accuracy: 0.693 - ETA: 20s - loss: 4.7195 - accuracy: 0.693 - ETA: 20s - loss: 4.7189 - accuracy: 0.693 - ETA: 20s - loss: 4.7180 - accuracy: 0.693 - ETA: 20s - loss: 4.7166 - accuracy: 0.693 - ETA: 19s - loss: 4.7178 - accuracy: 0.693 - ETA: 19s - loss: 4.7179 - accuracy: 0.693 - ETA: 19s - loss: 4.7187 - accuracy: 0.693 - ETA: 18s - loss: 4.7169 - accuracy: 0.693 - ETA: 18s - loss: 4.7157 - accuracy: 0.693 - ETA: 18s - loss: 4.7144 - accuracy: 0.693 - ETA: 18s - loss: 4.7135 - accuracy: 0.6937"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - ETA: 17s - loss: 4.7156 - accuracy: 0.693 - ETA: 17s - loss: 4.7145 - accuracy: 0.693 - ETA: 17s - loss: 4.7168 - accuracy: 0.693 - ETA: 17s - loss: 4.7164 - accuracy: 0.693 - ETA: 16s - loss: 4.7152 - accuracy: 0.693 - ETA: 16s - loss: 4.7161 - accuracy: 0.694 - ETA: 16s - loss: 4.7172 - accuracy: 0.694 - ETA: 16s - loss: 4.7155 - accuracy: 0.694 - ETA: 15s - loss: 4.7166 - accuracy: 0.694 - ETA: 15s - loss: 4.7151 - accuracy: 0.694 - ETA: 15s - loss: 4.7167 - accuracy: 0.694 - ETA: 14s - loss: 4.7155 - accuracy: 0.694 - ETA: 14s - loss: 4.7144 - accuracy: 0.694 - ETA: 14s - loss: 4.7140 - accuracy: 0.693 - ETA: 14s - loss: 4.7140 - accuracy: 0.694 - ETA: 13s - loss: 4.7131 - accuracy: 0.694 - ETA: 13s - loss: 4.7139 - accuracy: 0.694 - ETA: 13s - loss: 4.7148 - accuracy: 0.694 - ETA: 13s - loss: 4.7143 - accuracy: 0.693 - ETA: 12s - loss: 4.7147 - accuracy: 0.693 - ETA: 12s - loss: 4.7149 - accuracy: 0.693 - ETA: 12s - loss: 4.7145 - accuracy: 0.693 - ETA: 11s - loss: 4.7126 - accuracy: 0.693 - ETA: 11s - loss: 4.7121 - accuracy: 0.693 - ETA: 11s - loss: 4.7108 - accuracy: 0.693 - ETA: 11s - loss: 4.7101 - accuracy: 0.693 - ETA: 10s - loss: 4.7095 - accuracy: 0.694 - ETA: 10s - loss: 4.7084 - accuracy: 0.694 - ETA: 10s - loss: 4.7090 - accuracy: 0.694 - ETA: 10s - loss: 4.7097 - accuracy: 0.694 - ETA: 9s - loss: 4.7089 - accuracy: 0.694 - ETA: 9s - loss: 4.7104 - accuracy: 0.69 - ETA: 9s - loss: 4.7091 - accuracy: 0.69 - ETA: 8s - loss: 4.7090 - accuracy: 0.69 - ETA: 8s - loss: 4.7107 - accuracy: 0.69 - ETA: 8s - loss: 4.7115 - accuracy: 0.69 - ETA: 8s - loss: 4.7122 - accuracy: 0.69 - ETA: 7s - loss: 4.7131 - accuracy: 0.69 - ETA: 7s - loss: 4.7122 - accuracy: 0.69 - ETA: 7s - loss: 4.7125 - accuracy: 0.69 - ETA: 7s - loss: 4.7125 - accuracy: 0.69 - ETA: 6s - loss: 4.7128 - accuracy: 0.69 - ETA: 6s - loss: 4.7124 - accuracy: 0.69 - ETA: 6s - loss: 4.7128 - accuracy: 0.69 - ETA: 5s - loss: 4.7116 - accuracy: 0.69 - ETA: 5s - loss: 4.7132 - accuracy: 0.69 - ETA: 5s - loss: 4.7136 - accuracy: 0.69 - ETA: 5s - loss: 4.7131 - accuracy: 0.69 - ETA: 4s - loss: 4.7118 - accuracy: 0.69 - ETA: 4s - loss: 4.7119 - accuracy: 0.69 - ETA: 4s - loss: 4.7131 - accuracy: 0.69 - ETA: 4s - loss: 4.7142 - accuracy: 0.69 - ETA: 3s - loss: 4.7138 - accuracy: 0.69 - ETA: 3s - loss: 4.7153 - accuracy: 0.69 - ETA: 3s - loss: 4.7139 - accuracy: 0.69 - ETA: 2s - loss: 4.7127 - accuracy: 0.69 - ETA: 2s - loss: 4.7132 - accuracy: 0.69 - ETA: 2s - loss: 4.7133 - accuracy: 0.69 - ETA: 2s - loss: 4.7139 - accuracy: 0.69 - ETA: 1s - loss: 4.7134 - accuracy: 0.69 - ETA: 1s - loss: 4.7130 - accuracy: 0.69 - ETA: 1s - loss: 4.7129 - accuracy: 0.69 - ETA: 1s - loss: 4.7145 - accuracy: 0.69 - ETA: 0s - loss: 4.7136 - accuracy: 0.69 - ETA: 0s - loss: 4.7128 - accuracy: 0.69 - ETA: 0s - loss: 4.7131 - accuracy: 0.69 - 170s 8ms/step - loss: 4.7126 - accuracy: 0.6933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23b3ac3cfd0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(200, 12, activation='relu', input_shape=(5000, 12)))\n",
    "model.add(Conv1D(200, 12, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(100, 12, activation='relu'))\n",
    "model.add(Conv1D(100, 12, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(55, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_, y_train_, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4106/4106 [==============================] - ETA: 29 - ETA: 20 - ETA: 17 - ETA: 16 - ETA: 15 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 16s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.524983886852533, 0.6875304579734802]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_dev_, y_dev_, batch_size=32)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test = model.predict(x_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False,  True, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[4] > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## MLKNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = MLkNN(k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24106, 60000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ = x_train.reshape(24106, 60000)\n",
    "x_train_.shape\n",
    "x_train_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (10000, 60000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-4d5299f6c932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\skmultilearn\\adapt\\mlknn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prior_prob_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prior_prob_false\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;31m# Computing the posterior probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond_prob_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond_prob_false\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\skmultilearn\\adapt\\mlknn.py\u001b[0m in \u001b[0;36m_compute_cond\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         neighbors = [a[self.ignore_first_neighbours:] for a in\n\u001b[1;32m--> 172\u001b[1;33m                      self.knn_.kneighbors(X, self.k + self.ignore_first_neighbours, return_distance=False)]\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_instances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 delayed_query(\n\u001b[0;32m    453\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 454\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m             )\n\u001b[0;32m    456\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m--> 291\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\neighbors\\binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors.kd_tree.BinaryTree.query\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (10000, 60000) and data type float64"
     ]
    }
   ],
   "source": [
    "classifier.fit(x_train_[:10000], y_train[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a661a397939a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\skmultilearn\\adapt\\mlknn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlil_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'i8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         neighbors = [a[self.ignore_first_neighbours:] for a in\n\u001b[1;32m--> 238\u001b[1;33m                      self.knn_.kneighbors(X, self.k + self.ignore_first_neighbours, return_distance=False)]\n\u001b[0m\u001b[0;32m    239\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[0mdeltas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[0mquery_is_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[0mquery_is_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow+py3.6\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 539\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
